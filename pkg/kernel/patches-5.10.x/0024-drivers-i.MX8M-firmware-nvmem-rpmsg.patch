From 3d7d0763ce14ce78b9c26952201fc466f8252fd7 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Ren=C3=AA=20de=20Souza=20Pinto?= <rene@renesp.com.br>
Date: Thu, 19 Jan 2023 10:50:33 +0100
Subject: [PATCH 24/40] drivers: i.MX8M*: firmware, nvmem, rpmsg
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This commit squashes a series of commits taken from
git://git.phytec.de/linux-imx.

These commits add i.MX8M SoC specific drivers:
- Firmware
- nvmem
- rpmsg

The following original commits were cherry-picked:

0a3ed97521e9d nvmem: imx-ocotp: add support for the unaliged word count
122c4c5211ad5 MLK-24529 nvmem: ocotp: use high bus when programming/reloading fuse
f221b7e283e86 MLK-25246-5 nvmem: imx: i.MX8ULP nvmem ocotp driver
6f72fd5e63e05 LF-4523 nvmem: imx8ulp: fix the wrong position of the reserved 48 words
783d7ff5dcc4f firmware: imx: scu-pd: add SCU power domain for image subsystem
6691c86ebdfb5 firmware: imx: scu-pd: add VPU MU powe domains
d7f5b553653ac firmware: imx: scu-pd: add power domain for edma2
6df54eb90fbc1 imx: scu-pd: add audio power domains
e1e0699e77b6b firmware: imx: scu-pd: add mipi lvds1 power domains
707cf2202f41c firmware: imx: scu-pd: add multi states support
3a2e863884fd3 firmware: imx: increase scu timeout
929fc15f829f9 firmware: imx: scu-pd: do not power off console domain
3a43d2b1913b7 firmware: imx: scu-pd: do not power off console if no_console_suspend
985d9862118d4 firmware: imx: scu-pd: add dc video pd
4049ceda67670 firmware: imx: scu: intialization rx_size before sending cmd
c37166b20c6f1 firmware: imx: scu-pd: Add IRQSTEER wakeup support
3f800d0a16eef firmware: scu-pd: add pd for CM41 SS
7732aa7f3b232 firmware: imx: scu-pd: add the hsio pds
6fb6d225c7f37 soc: imx: imx-scu: Use SoC name as soc_id
46feb10228e70 firmware: imx: scu-pd: add lvds power domains
fca079d53e992 firmware: imx: scu-pd: add dc1 power domains
03db7ba486077 firmware: imx: scu-pd: change init level to subsys_initcall
bb08fa9c4f7c2 firmware: imx: scu: change init level to subsys_initcall_sync
a71fc942ffdb9 firmware: imx: make sure MU irq can wake up system from suspend mode
845e785960b45 firmware: imx: scu-pd: add the hdmi tx power domains
f2d162e97b59b imx: scu-pd: add audio power domains for imx8qm
ecd246903d44e imx: scu-pd: add vpu mu2 power domains for imx8qm
5524f860805f3 imx: scu-pd: add power domains for gpu1-pid
a5bde4192c47b MLKU-62 imx: scu-pd: add power domain for caam job rings
05d79ec73184b imx: scu-pd: Add power domains for mxc-jpeg
29a672136fae1 firmware: imx: pd: add power domain for emvsim
760cc700224cc firmware: imx: pd: add board level power domain
8631b6825f867 imx: scu-pd: add vpu-enc1 power domains for imx8qm
e49b25983b660 MLK-16005-2 soc: imx: scu: add the SW workaround for i.MX8QM TKT340553
914cdee64f1b1 firmware: imx: scu-pd: correct edma0 channel number
9b52103592194 MLK-22984 firmware: imx: imx-scu-irq: fix RCU complains after M4 partition reset
bfb4c738c7602 LF-202-1 firmware: imx: scu: use hvc for dom0
2021da42ab50a MLK-22992 firmware: imx: scu-pd: fix wu_num
110073fe0299b LF-824: fw: imx: seco_mu: Add driver for SECO
5ed94148e6227 LF-790 firmware: imx: rm: add imx_sc_rm_get_partition
623e555f9e596 LF-824: fw: imx: scu: Add missing RM APIs
586270b3ee241 LF-1383-03 soc: imx: add imx8dxl soc id
3f939bc19226c LF-824: fw: imx: Add power domain for MU of the SECO
e36a80ac9748c MLK-23346-1 firmware: imx: scu-pd: DXL Add second USB PHY power domain
e2968ec5b46d4 LF-824: fw: imx: scu: Add SECO APIs
0664eb9c07724 MLK-23418-5 firmware: imx: scu-pd: add Perf power domain in DB
490bce7ad7caa MLK-23421: fw: imx: seco_mu: Use fast IPC
a0e834af6fd83 SSI-87: firmware: imx: Add APIs required for secvio
bfdb1fd74c11b MLK-23674-3 fw: imx: seco_mu: get message header tags from dt
8444cc4b591fa HSM-267-1: fw: imx: seco_mu: Handle error code in mailbox rx callback
63ef4f270210d MLK-23635: fw: imx: seco_mu: Fix messages at boot
fbee30c0fd0fc LF-811-3: firmware: imx: add lcd-pll power domain
0da7fc7827d4d HSM-292 firmware: imx: seco_mu: Increase MAX_DATA_SIZE_PER_USER
9b222a3edc406 firmware: imx: Introduce imx_dsp_setup_channels
3430b28b390db firmware: imx: Save channel name for further use
b990dd05e2231 firmware: imx-dsp: Export functions to request/free channels
4aa92804832d6 MLK-24759: fw: imx: scu: rm: Fix Align imx sc msg structs to 4
b86a6dce4a546 MLK-24759: fw: imx: scu: rm: Fix name of some structures
249e85c63f870 MLK-24759: fw: imx: scu: seco: Fix Align imx sc msg structs to 4
b1f92b31423b5 MLK-24833-1 imx: scu-pd: add lpi2c4 power domain for imx8qm
18bf0bcf60a86 MLK-23674-1 imx: scu-pd: add power domain definition for V2X MU
52616181a0405 MLK-23403-1 Fix fail cat /sys/devices/soc0/soc_uid
43b5274ce65d3 MLK-24081-01: power: imx: Add hdmi rx power domain
e00b9cfd35ac6 MLK-25468: seco_mu: hook v2x reset event
b2dde8357b216 MLK-25246-2 firmware: imx: S400 MU AP domain client driver
d1db4d2a39592 MLK-25423-2 firmware: imx: register i.MX8ULP SoC device
9745b4a99760c MLK-25620 imx8ulp: soc: update imx8ulp soc device attribute
3bc399ee42d1b MLK25252: firmware: imx: register device users
8dc1b34e61ffd MLK25252: firmware: imx: added the character driver
d421e8fcef82a MLK25252: S4_MUAP: added support for image authentication
d3b45c1cb0878 LF4778 s400-api: code restructuring
a2200b05f4efb LF4777 s400-api: reading sentinel common fuses
20abf632a7a1f LF-4777 s400-api: restructure the s400-msg
af7effc22f443 LF-4778 sentnl-mu: file name changes
ab074f3945f9e LF-4778 sentnl-mu: file name changes
aa4c882e611f6 LF-4778 sentnl-mu: rename the structure
387a575683f8d LF-4776 sentnl-mu: added f_ops read-write & allcate IO buffer
994b497cc87f1 LF-1383-04 dt-bindings: firmware: imx: update the rsrc id to include the IDs of imx8dxl
c036f92d795c8 clk: imx6sx: support suspend/resume with FastMix off
eb0ee423956da imx busfreq: Add API header file
69a4933fd4c99 rpmsg: imx: add the initial imx rpmsg support
dca4eb99e5647 rpmsg: imx: extend the rpmsg support for imx8qm and so on
d08f787e4bc6b rpmsg: imx: bug fix and clean up the codes
3b3c92c7215d3 rpmsg: imx_rpmsg: add partition reset notify
27bea1137cce4 rpmsg: imx: enable the tx_block mechanism in the flow
5e852b3474996 LF-44 rpmsg: imx: add the rpmsg tty demo
1b0cec0c8f8fc rpmsg: imx: remove use of ioremap_nocache()
b2432a6607694 rpmsg: imx: include slab.h explicitly
5894fabc96748 rpmsg: Move structure rpmsg_ns_msg to header file
6c5ba6661b918 rpmsg: Turn name service into a stand alone driver
7c9a5a31bc275 LF-2108 rpmsg: imx: fix the pointer conversion loses bits issue
b5a2325ed467d rpmsg: char: Export eptdev create an destroy functions
86ab3fdbc97dc rpmsg: char: Rename rpmsg_char_init to rpmsg_chrdev_init
45e152da4de56 rpmsg: char: Use rpmsg_sendto to specify the message destination address
1cdf1c167f414 rpmsg: char: Return an error if device already open
8b42bbc184170 rpmsg: Move the rpmsg control device from rpmsg_char to rpmsg_ctrl
c84403f1797fa rpmsg: char: Introduce __rpmsg_chrdev_create_eptdev function
ae5e0442ec19a rpmsg: char: Add possibility to use default endpoint of the rpmsg device.
2cedc6bad941e rpmsg: char: Introduce the "rpmsg-raw" channel
997981d777bc4 LF-4261: rpmsg: char: Fix no mutex for multiple open
0ef3f6087a09c rpmsg: core: Add channel creation internal API
298e858c6ab8d rpmsg: Introduce rpmsg_create_default_ept function
d5ff947518a2c rpmsg: Introduce __rpmsg{16|32|64} types
cf3ae62cafd52 rpmsg: virtio: Move from virtio to rpmsg byte conversion
5894fabc96748 rpmsg: Move structure rpmsg_ns_msg to header file
2a8e7150ba8ab rpmsg: virtio: Rename rpmsg_create_channel
3101b61036aca rpmsg: virtio: Add rpmsg channel device ops
6c5ba6661b918 rpmsg: Turn name service into a stand alone driver
072b26a51c3d9 rpmsg: virtio: Register the rpmsg_char device
6a907c1e749e2 rpmsg: Update rpmsg_chrdev_register_device function
3b4f1f74a3d3b MLK-16005-2 arm64: tlb: add the SW workaround for i.MX8QM TKT340553
222deda02d077 LF-363 arm64: kernel: TKT340553 Errata workaround update for i.MX8QM

Signed-off-by: RenÃª de Souza Pinto <rene@renesp.com.br>
---
 arch/arm64/include/asm/tlbflush.h            |   42 +-
 arch/arm64/kernel/cpufeature.c               |   13 +
 arch/arm64/kernel/traps.c                    |   28 +-
 drivers/clk/imx/clk-imx6sx.c                 |   42 +
 drivers/firmware/imx/Kconfig                 |   21 +
 drivers/firmware/imx/Makefile                |    4 +-
 drivers/firmware/imx/imx-dsp.c               |   72 +-
 drivers/firmware/imx/imx-scu-irq.c           |   50 +-
 drivers/firmware/imx/imx-scu-soc.c           |   21 +-
 drivers/firmware/imx/imx-scu.c               |   76 +-
 drivers/firmware/imx/rm.c                    |  162 +++
 drivers/firmware/imx/scu-pd.c                |  214 +++-
 drivers/firmware/imx/seco.c                  |  249 ++++
 drivers/firmware/imx/seco_mu.c               | 1212 ++++++++++++++++++
 drivers/firmware/imx/sentnl_base_msg.c       |  141 ++
 drivers/firmware/imx/sentnl_mu.c             |  919 +++++++++++++
 drivers/firmware/imx/sentnl_mu.h             |  139 ++
 drivers/nvmem/Kconfig                        |   11 +
 drivers/nvmem/Makefile                       |    2 +
 drivers/nvmem/imx-ocotp-fsb-s400.c           |  204 +++
 drivers/nvmem/imx-ocotp.c                    |   34 +-
 drivers/rpmsg/Kconfig                        |   55 +
 drivers/rpmsg/Makefile                       |    5 +
 drivers/rpmsg/imx_rpmsg.c                    |  680 ++++++++++
 drivers/rpmsg/imx_rpmsg_pingpong.c           |  100 ++
 drivers/rpmsg/imx_rpmsg_tty.c                |  242 ++++
 drivers/rpmsg/qcom_glink_native.c            |   18 +-
 drivers/rpmsg/qcom_smd.c                     |   18 +-
 drivers/rpmsg/rpmsg_char.c                   |  249 ++--
 drivers/rpmsg/rpmsg_char.h                   |   51 +
 drivers/rpmsg/rpmsg_core.c                   |   95 ++
 drivers/rpmsg/rpmsg_ctrl.c                   |  215 ++++
 drivers/rpmsg/rpmsg_internal.h               |   18 +-
 drivers/rpmsg/rpmsg_ns.c                     |  126 ++
 drivers/rpmsg/virtio_rpmsg_bus.c             |  221 ++--
 include/dt-bindings/firmware/imx/rsrc.h      |    7 +
 include/linux/busfreq-imx.h                  |   77 ++
 include/linux/firmware/imx/dsp.h             |   10 +
 include/linux/firmware/imx/ipc.h             |    4 +-
 include/linux/firmware/imx/sci.h             |    7 +-
 include/linux/firmware/imx/seco_mu_ioctl.h   |   50 +
 include/linux/firmware/imx/sentnl_base_msg.h |   36 +
 include/linux/firmware/imx/sentnl_mu_ioctl.h |   51 +
 include/linux/firmware/imx/svc/rm.h          |   39 +
 include/linux/firmware/imx/svc/seco.h        |   77 ++
 include/linux/imx_rpmsg.h                    |   43 +
 include/linux/rpmsg.h                        |   64 +
 include/linux/rpmsg/byteorder.h              |   67 +
 include/linux/rpmsg/ns.h                     |   45 +
 include/soc/imx/gpc.h                        |    7 +
 include/soc/imx/src.h                        |    6 +
 include/uapi/linux/rpmsg_types.h             |   11 +
 52 files changed, 5988 insertions(+), 362 deletions(-)
 mode change 100644 => 100755 drivers/firmware/imx/scu-pd.c
 create mode 100644 drivers/firmware/imx/seco.c
 create mode 100644 drivers/firmware/imx/seco_mu.c
 create mode 100644 drivers/firmware/imx/sentnl_base_msg.c
 create mode 100644 drivers/firmware/imx/sentnl_mu.c
 create mode 100644 drivers/firmware/imx/sentnl_mu.h
 create mode 100644 drivers/nvmem/imx-ocotp-fsb-s400.c
 create mode 100644 drivers/rpmsg/imx_rpmsg.c
 create mode 100644 drivers/rpmsg/imx_rpmsg_pingpong.c
 create mode 100644 drivers/rpmsg/imx_rpmsg_tty.c
 create mode 100644 drivers/rpmsg/rpmsg_char.h
 create mode 100644 drivers/rpmsg/rpmsg_ctrl.c
 create mode 100644 drivers/rpmsg/rpmsg_ns.c
 create mode 100644 include/linux/busfreq-imx.h
 create mode 100644 include/linux/firmware/imx/seco_mu_ioctl.h
 create mode 100644 include/linux/firmware/imx/sentnl_base_msg.h
 create mode 100644 include/linux/firmware/imx/sentnl_mu_ioctl.h
 create mode 100644 include/linux/firmware/imx/svc/seco.h
 create mode 100644 include/linux/imx_rpmsg.h
 create mode 100644 include/linux/rpmsg/byteorder.h
 create mode 100644 include/linux/rpmsg/ns.h
 create mode 100644 include/soc/imx/gpc.h
 create mode 100644 include/soc/imx/src.h
 create mode 100644 include/uapi/linux/rpmsg_types.h

diff --git a/arch/arm64/include/asm/tlbflush.h b/arch/arm64/include/asm/tlbflush.h
index 36f02892e1df..57daf5b863a1 100644
--- a/arch/arm64/include/asm/tlbflush.h
+++ b/arch/arm64/include/asm/tlbflush.h
@@ -16,6 +16,8 @@
 #include <asm/cputype.h>
 #include <asm/mmu.h>
 
+extern bool TKT340553_SW_WORKAROUND;
+
 /*
  * Raw TLBI operations.
  *
@@ -249,8 +251,12 @@ static inline void flush_tlb_mm(struct mm_struct *mm)
 
 	dsb(ishst);
 	asid = __TLBI_VADDR(0, ASID(mm));
-	__tlbi(aside1is, asid);
-	__tlbi_user(aside1is, asid);
+	if (TKT340553_SW_WORKAROUND) {
+		__tlbi(vmalle1is);
+	} else {
+		__tlbi(aside1is, asid);
+		__tlbi_user(aside1is, asid);
+	}
 	dsb(ish);
 }
 
@@ -261,8 +267,12 @@ static inline void flush_tlb_page_nosync(struct vm_area_struct *vma,
 
 	dsb(ishst);
 	addr = __TLBI_VADDR(uaddr, ASID(vma->vm_mm));
-	__tlbi(vale1is, addr);
-	__tlbi_user(vale1is, addr);
+	if (TKT340553_SW_WORKAROUND) {
+		__tlbi(vmalle1is);
+	} else {
+		__tlbi(vale1is, addr);
+		__tlbi_user(vale1is, addr);
+	}
 }
 
 static inline void flush_tlb_page(struct vm_area_struct *vma,
@@ -286,6 +296,7 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 	int num = 0;
 	int scale = 0;
 	unsigned long asid, addr, pages;
+	unsigned long mask = (1 << 20) - 1;
 
 	start = round_down(start, stride);
 	end = round_up(end, stride);
@@ -306,6 +317,7 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 
 	dsb(ishst);
 	asid = ASID(vma->vm_mm);
+	mask <<= 24;
 
 	/*
 	 * When the CPU does not support TLB range operations, flush the TLB
@@ -329,7 +341,9 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 		if (!system_supports_tlb_range() ||
 		    pages % 2 == 1) {
 			addr = __TLBI_VADDR(start, asid);
-			if (last_level) {
+			if (TKT340553_SW_WORKAROUND) {
+				__tlbi(vmalle1is);
+			} else if (last_level) {
 				__tlbi_level(vale1is, addr, tlb_level);
 				__tlbi_user_level(vale1is, addr, tlb_level);
 			} else {
@@ -345,7 +359,9 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 		if (num >= 0) {
 			addr = __TLBI_VADDR_RANGE(start, asid, scale,
 						  num, tlb_level);
-			if (last_level) {
+			if (TKT340553_SW_WORKAROUND) {
+				__tlbi(vmalle1is);
+			} else if (last_level) {
 				__tlbi(rvale1is, addr);
 				__tlbi_user(rvale1is, addr);
 			} else {
@@ -357,6 +373,7 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 		}
 		scale++;
 	}
+
 	dsb(ish);
 }
 
@@ -384,8 +401,12 @@ static inline void flush_tlb_kernel_range(unsigned long start, unsigned long end
 	end = __TLBI_VADDR(end, 0);
 
 	dsb(ishst);
-	for (addr = start; addr < end; addr += 1 << (PAGE_SHIFT - 12))
-		__tlbi(vaale1is, addr);
+	for (addr = start; addr < end; addr += 1 << (PAGE_SHIFT - 12)) {
+		if (TKT340553_SW_WORKAROUND)
+			__tlbi(vmalle1is);
+		else
+			__tlbi(vaale1is, addr);
+	}
 	dsb(ish);
 	isb();
 }
@@ -399,7 +420,10 @@ static inline void __flush_tlb_kernel_pgtable(unsigned long kaddr)
 	unsigned long addr = __TLBI_VADDR(kaddr, 0);
 
 	dsb(ishst);
-	__tlbi(vaae1is, addr);
+	if (TKT340553_SW_WORKAROUND)
+		__tlbi(vmalle1is);
+	else
+		__tlbi(vaae1is, addr);
 	dsb(ish);
 	isb();
 }
diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c
index c9108ed40645..b7797c2c96ec 100644
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@ -823,9 +823,22 @@ init_cpu_hwcaps_indirect_list_from_array(const struct arm64_cpu_capabilities *ca
 	}
 }
 
+bool TKT340553_SW_WORKAROUND;
 static void __init init_cpu_hwcaps_indirect_list(void)
 {
 	init_cpu_hwcaps_indirect_list_from_array(arm64_features);
+#ifdef CONFIG_ARM64_WORKAROUND_CLEAN_CACHE
+#if	defined(CONFIG_ARM64_ERRATUM_826319) || \
+	defined(CONFIG_ARM64_ERRATUM_827319) || \
+	defined(CONFIG_ARM64_ERRATUM_824069)
+	if (TKT340553_SW_WORKAROUND) {
+		struct midr_range *midr_range_list =
+			(struct midr_range *)(arm64_errata[0].midr_range_list);
+
+		midr_range_list[0].rv_max = MIDR_CPU_VAR_REV(0, 4);
+	}
+#endif
+#endif
 	init_cpu_hwcaps_indirect_list_from_array(arm64_errata);
 }
 
diff --git a/arch/arm64/kernel/traps.c b/arch/arm64/kernel/traps.c
index 2059d8f43f55..3c2a03e19cc2 100644
--- a/arch/arm64/kernel/traps.c
+++ b/arch/arm64/kernel/traps.c
@@ -447,6 +447,29 @@ NOKPROBE_SYMBOL(do_ptrauth_fault);
 		uaccess_ttbr0_disable();			\
 	}
 
+#define __user_cache_maint_ivau(insn, address, res)			\
+	do {								\
+		if (address >= user_addr_max()) {			\
+			res = -EFAULT;					\
+		} else {						\
+			uaccess_ttbr0_enable();				\
+			asm volatile (					\
+				"1:	" insn "\n"			\
+				"	mov	%w0, #0\n"		\
+				"2:\n"					\
+				"	.pushsection .fixup,\"ax\"\n"	\
+				"	.align	2\n"			\
+				"3:	mov	%w0, %w2\n"		\
+				"	b	2b\n"			\
+				"	.popsection\n"			\
+				_ASM_EXTABLE(1b, 3b)			\
+				: "=r" (res)				\
+				: "r" (address), "i" (-EFAULT));	\
+			uaccess_ttbr0_disable();			\
+		}							\
+	} while (0)
+
+extern bool TKT340553_SW_WORKAROUND;
 static void user_cache_maint_handler(unsigned int esr, struct pt_regs *regs)
 {
 	unsigned long address;
@@ -473,7 +496,10 @@ static void user_cache_maint_handler(unsigned int esr, struct pt_regs *regs)
 		__user_cache_maint("dc civac", address, ret);
 		break;
 	case ESR_ELx_SYS64_ISS_CRM_IC_IVAU:	/* IC IVAU */
-		__user_cache_maint("ic ivau", address, ret);
+		if (TKT340553_SW_WORKAROUND)
+			__user_cache_maint_ivau("ic ialluis", address, ret);
+		else
+			__user_cache_maint("ic ivau", address, ret);
 		break;
 	default:
 		force_signal_inject(SIGILL, ILL_ILLOPC, regs->pc, 0);
diff --git a/drivers/clk/imx/clk-imx6sx.c b/drivers/clk/imx/clk-imx6sx.c
index fc1bd23d4583..f91b947fc106 100644
--- a/drivers/clk/imx/clk-imx6sx.c
+++ b/drivers/clk/imx/clk-imx6sx.c
@@ -15,6 +15,8 @@
 #include <linux/of_address.h>
 #include <linux/of_irq.h>
 #include <linux/types.h>
+#include <soc/imx/gpc.h>
+#include <soc/imx/src.h>
 
 #include "clk.h"
 
@@ -117,6 +119,46 @@ static u32 share_count_ssi3;
 static u32 share_count_sai1;
 static u32 share_count_sai2;
 
+static const int uart_clk_ids[] __initconst = {
+	IMX6SX_CLK_UART_IPG,
+	IMX6SX_CLK_UART_SERIAL,
+};
+
+static struct clk **uart_clks[ARRAY_SIZE(uart_clk_ids) + 1] __initdata;
+
+/*
+ * As IMX6SX_CLK_M4_PRE_SEL is NOT a glitchless MUX, so when
+ * M4 is trying to change its clk parent, need to ask A9 to
+ * help do it, and M4 must be hold in wfi. To avoid glitch
+ * occur, need to gate M4 clk first before switching its parent.
+ */
+void imx6sx_set_m4_highfreq(bool high_freq)
+{
+	static struct clk *m4_high_freq_sel;
+
+	imx_gpc_hold_m4_in_sleep();
+
+	clk_disable_unprepare(hws[IMX6SX_CLK_M4]->clk);
+	clk_set_parent(hws[IMX6SX_CLK_M4_SEL]->clk,
+		hws[IMX6SX_CLK_LDB_DI0]->clk);
+
+	if (high_freq) {
+		/* FIXME: m4_high_freq_sel possible used without intialization? */ 
+		clk_set_parent(hws[IMX6SX_CLK_M4_PRE_SEL]->clk,
+			m4_high_freq_sel);
+	} else {
+		m4_high_freq_sel = clk_get_parent(hws[IMX6SX_CLK_M4_PRE_SEL]->clk);
+		clk_set_parent(hws[IMX6SX_CLK_M4_PRE_SEL]->clk,
+			hws[IMX6SX_CLK_OSC]->clk);
+	}
+
+	clk_set_parent(hws[IMX6SX_CLK_M4_SEL]->clk,
+		       hws[IMX6SX_CLK_M4_PRE_SEL]->clk);
+	clk_prepare_enable(hws[IMX6SX_CLK_M4]->clk);
+
+	imx_gpc_release_m4_in_sleep();
+}
+
 static void __init imx6sx_clocks_init(struct device_node *ccm_node)
 {
 	struct device_node *np;
diff --git a/drivers/firmware/imx/Kconfig b/drivers/firmware/imx/Kconfig
index c027d99f2a59..b33f0330b6a9 100644
--- a/drivers/firmware/imx/Kconfig
+++ b/drivers/firmware/imx/Kconfig
@@ -28,3 +28,24 @@ config IMX_SCU_PD
 	depends on IMX_SCU
 	help
 	  The System Controller Firmware (SCFW) based power domain driver.
+
+config IMX_SECO_MU
+	tristate "i.MX Security Controller (SECO) support"
+	depends on IMX_SCU && IMX_MBOX
+
+	help
+	  It is possible to use APIs exposed by the SECO like HSM and SHE using the
+	  SAB protocol via the shared Messaging Unit. This driver exposes these
+	  interfaces via a set of file descriptors allowing to configure shared
+	  memory, send and receive messages.
+
+config IMX_SENTNL_MU
+	tristate "i.MX Embedded Security Element (SENTINEL) support."
+	depends on IMX_MBOX
+	default y if ARM64
+
+	help
+	  It is possible to use APIs exposed by the SENTINEL like base, HSM & SHE
+	  using the SAB protocol via the shared Messaging Unit. This driver exposes
+	  these interfaces via a set of file descriptors allowing to configure shared
+	  memory, send and receive messages.
diff --git a/drivers/firmware/imx/Makefile b/drivers/firmware/imx/Makefile
index b76acbade2a0..e52598bfce70 100644
--- a/drivers/firmware/imx/Makefile
+++ b/drivers/firmware/imx/Makefile
@@ -1,4 +1,6 @@
 # SPDX-License-Identifier: GPL-2.0
 obj-$(CONFIG_IMX_DSP)		+= imx-dsp.o
-obj-$(CONFIG_IMX_SCU)		+= imx-scu.o misc.o imx-scu-irq.o rm.o imx-scu-soc.o
+obj-$(CONFIG_IMX_SCU)		+= imx-scu.o misc.o imx-scu-irq.o rm.o imx-scu-soc.o seco.o
 obj-$(CONFIG_IMX_SCU_PD)	+= scu-pd.o
+obj-${CONFIG_IMX_SECO_MU}	+= seco_mu.o
+obj-${CONFIG_IMX_SENTNL_MU}	+= sentnl_mu.o sentnl_base_msg.o
diff --git a/drivers/firmware/imx/imx-dsp.c b/drivers/firmware/imx/imx-dsp.c
index 4265e9dbed84..a6c06d7476c3 100644
--- a/drivers/firmware/imx/imx-dsp.c
+++ b/drivers/firmware/imx/imx-dsp.c
@@ -60,22 +60,40 @@ static void imx_dsp_handle_rx(struct mbox_client *c, void *msg)
 	}
 }
 
-static int imx_dsp_probe(struct platform_device *pdev)
+struct mbox_chan *imx_dsp_request_channel(struct imx_dsp_ipc *dsp_ipc, int idx)
 {
-	struct device *dev = &pdev->dev;
-	struct imx_dsp_ipc *dsp_ipc;
+	struct imx_dsp_chan *dsp_chan;
+
+	if (idx >= DSP_MU_CHAN_NUM)
+		return ERR_PTR(-EINVAL);
+
+	dsp_chan = &dsp_ipc->chans[idx];
+	dsp_chan->ch = mbox_request_channel_byname(&dsp_chan->cl, dsp_chan->name);
+	return dsp_chan->ch;
+}
+EXPORT_SYMBOL(imx_dsp_request_channel);
+
+void imx_dsp_free_channel(struct imx_dsp_ipc *dsp_ipc, int idx)
+{
+	struct imx_dsp_chan *dsp_chan;
+
+	if (idx >= DSP_MU_CHAN_NUM)
+		return;
+
+	dsp_chan = &dsp_ipc->chans[idx];
+	mbox_free_channel(dsp_chan->ch);
+}
+EXPORT_SYMBOL(imx_dsp_free_channel);
+
+static int imx_dsp_setup_channels(struct imx_dsp_ipc *dsp_ipc)
+{
+	struct device *dev = dsp_ipc->dev;
 	struct imx_dsp_chan *dsp_chan;
 	struct mbox_client *cl;
 	char *chan_name;
 	int ret;
 	int i, j;
 
-	device_set_of_node_from_dev(&pdev->dev, pdev->dev.parent);
-
-	dsp_ipc = devm_kzalloc(dev, sizeof(*dsp_ipc), GFP_KERNEL);
-	if (!dsp_ipc)
-		return -ENOMEM;
-
 	for (i = 0; i < DSP_MU_CHAN_NUM; i++) {
 		if (i < 2)
 			chan_name = kasprintf(GFP_KERNEL, "txdb%d", i);
@@ -86,6 +104,7 @@ static int imx_dsp_probe(struct platform_device *pdev)
 			return -ENOMEM;
 
 		dsp_chan = &dsp_ipc->chans[i];
+		dsp_chan->name = chan_name;
 		cl = &dsp_chan->cl;
 		cl->dev = dev;
 		cl->tx_block = false;
@@ -104,27 +123,43 @@ static int imx_dsp_probe(struct platform_device *pdev)
 		}
 
 		dev_dbg(dev, "request mbox chan %s\n", chan_name);
-		/* chan_name is not used anymore by framework */
-		kfree(chan_name);
 	}
 
-	dsp_ipc->dev = dev;
-
-	dev_set_drvdata(dev, dsp_ipc);
-
-	dev_info(dev, "NXP i.MX DSP IPC initialized\n");
-
 	return 0;
 out:
-	kfree(chan_name);
 	for (j = 0; j < i; j++) {
 		dsp_chan = &dsp_ipc->chans[j];
 		mbox_free_channel(dsp_chan->ch);
+		kfree(dsp_chan->name);
 	}
 
 	return ret;
 }
 
+static int imx_dsp_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct imx_dsp_ipc *dsp_ipc;
+	int ret;
+
+	device_set_of_node_from_dev(&pdev->dev, pdev->dev.parent);
+
+	dsp_ipc = devm_kzalloc(dev, sizeof(*dsp_ipc), GFP_KERNEL);
+	if (!dsp_ipc)
+		return -ENOMEM;
+
+	dsp_ipc->dev = dev;
+	dev_set_drvdata(dev, dsp_ipc);
+
+	ret = imx_dsp_setup_channels(dsp_ipc);
+	if (ret < 0)
+		return ret;
+
+	dev_info(dev, "NXP i.MX DSP IPC initialized\n");
+
+	return 0;
+}
+
 static int imx_dsp_remove(struct platform_device *pdev)
 {
 	struct imx_dsp_chan *dsp_chan;
@@ -136,6 +171,7 @@ static int imx_dsp_remove(struct platform_device *pdev)
 	for (i = 0; i < DSP_MU_CHAN_NUM; i++) {
 		dsp_chan = &dsp_ipc->chans[i];
 		mbox_free_channel(dsp_chan->ch);
+		kfree(dsp_chan->name);
 	}
 
 	return 0;
diff --git a/drivers/firmware/imx/imx-scu-irq.c b/drivers/firmware/imx/imx-scu-irq.c
index d9dcc20945c6..cc081a6a1e64 100644
--- a/drivers/firmware/imx/imx-scu-irq.c
+++ b/drivers/firmware/imx/imx-scu-irq.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0+
 /*
- * Copyright 2019 NXP
+ * Copyright 2019-2020 NXP
  *
  * Implementation of the SCU IRQ functions using MU.
  *
@@ -14,7 +14,7 @@
 
 #define IMX_SC_IRQ_FUNC_ENABLE	1
 #define IMX_SC_IRQ_FUNC_STATUS	2
-#define IMX_SC_IRQ_NUM_GROUP	4
+#define IMX_SC_IRQ_NUM_GROUP	7
 
 static u32 mu_resource_id;
 
@@ -42,53 +42,42 @@ struct imx_sc_msg_irq_enable {
 
 static struct imx_sc_ipc *imx_sc_irq_ipc_handle;
 static struct work_struct imx_sc_irq_work;
-static ATOMIC_NOTIFIER_HEAD(imx_scu_irq_notifier_chain);
+static BLOCKING_NOTIFIER_HEAD(imx_scu_irq_notifier_chain);
 
 int imx_scu_irq_register_notifier(struct notifier_block *nb)
 {
-	return atomic_notifier_chain_register(
+	return blocking_notifier_chain_register(
 		&imx_scu_irq_notifier_chain, nb);
 }
 EXPORT_SYMBOL(imx_scu_irq_register_notifier);
 
 int imx_scu_irq_unregister_notifier(struct notifier_block *nb)
 {
-	return atomic_notifier_chain_unregister(
+	return blocking_notifier_chain_unregister(
 		&imx_scu_irq_notifier_chain, nb);
 }
 EXPORT_SYMBOL(imx_scu_irq_unregister_notifier);
 
 static int imx_scu_irq_notifier_call_chain(unsigned long status, u8 *group)
 {
-	return atomic_notifier_call_chain(&imx_scu_irq_notifier_chain,
+	return blocking_notifier_call_chain(&imx_scu_irq_notifier_chain,
 		status, (void *)group);
 }
 
 static void imx_scu_irq_work_handler(struct work_struct *work)
 {
-	struct imx_sc_msg_irq_get_status msg;
-	struct imx_sc_rpc_msg *hdr = &msg.hdr;
 	u32 irq_status;
 	int ret;
 	u8 i;
 
 	for (i = 0; i < IMX_SC_IRQ_NUM_GROUP; i++) {
-		hdr->ver = IMX_SC_RPC_VERSION;
-		hdr->svc = IMX_SC_RPC_SVC_IRQ;
-		hdr->func = IMX_SC_IRQ_FUNC_STATUS;
-		hdr->size = 2;
-
-		msg.data.req.resource = mu_resource_id;
-		msg.data.req.group = i;
-
-		ret = imx_scu_call_rpc(imx_sc_irq_ipc_handle, &msg, true);
+		ret = imx_scu_irq_get_status(i, &irq_status);
 		if (ret) {
 			pr_err("get irq group %d status failed, ret %d\n",
 			       i, ret);
 			return;
 		}
 
-		irq_status = msg.data.resp.status;
 		if (!irq_status)
 			continue;
 
@@ -97,6 +86,31 @@ static void imx_scu_irq_work_handler(struct work_struct *work)
 	}
 }
 
+int imx_scu_irq_get_status(u8 group, u32 *irq_status)
+{
+	struct imx_sc_msg_irq_get_status msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_IRQ;
+	hdr->func = IMX_SC_IRQ_FUNC_STATUS;
+	hdr->size = 2;
+
+	msg.data.req.resource = mu_resource_id;
+	msg.data.req.group = group;
+
+	ret = imx_scu_call_rpc(imx_sc_irq_ipc_handle, &msg, true);
+	if (ret)
+		return ret;
+
+	if (irq_status)
+		*irq_status = msg.data.resp.status;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_scu_irq_get_status);
+
 int imx_scu_irq_group_enable(u8 group, u32 mask, u8 enable)
 {
 	struct imx_sc_msg_irq_enable msg;
diff --git a/drivers/firmware/imx/imx-scu-soc.c b/drivers/firmware/imx/imx-scu-soc.c
index 2f32353de2c9..c8d14315d463 100644
--- a/drivers/firmware/imx/imx-scu-soc.c
+++ b/drivers/firmware/imx/imx-scu-soc.c
@@ -12,6 +12,8 @@
 
 static struct imx_sc_ipc *imx_sc_soc_ipc_handle;
 
+extern bool TKT340553_SW_WORKAROUND;
+
 struct imx_sc_msg_misc_get_soc_id {
 	struct imx_sc_rpc_msg hdr;
 	union {
@@ -35,18 +37,15 @@ static int imx_scu_soc_uid(u64 *soc_uid)
 {
 	struct imx_sc_msg_misc_get_soc_uid msg;
 	struct imx_sc_rpc_msg *hdr = &msg.hdr;
-	int ret;
+
+	memset(&msg, 0, sizeof(msg));
 
 	hdr->ver = IMX_SC_RPC_VERSION;
 	hdr->svc = IMX_SC_RPC_SVC_MISC;
 	hdr->func = IMX_SC_MISC_FUNC_UNIQUE_ID;
 	hdr->size = 1;
 
-	ret = imx_scu_call_rpc(imx_sc_soc_ipc_handle, &msg, true);
-	if (ret) {
-		pr_err("%s: get soc uid failed, ret %d\n", __func__, ret);
-		return ret;
-	}
+	imx_scu_call_rpc(imx_sc_soc_ipc_handle, &msg, true);
 
 	*soc_uid = msg.uid_high;
 	*soc_uid <<= 32;
@@ -113,9 +112,13 @@ int imx_scu_soc_init(struct device *dev)
 
 	/* format soc_id value passed from SCU firmware */
 	val = id & 0x1f;
-	soc_dev_attr->soc_id = devm_kasprintf(dev, GFP_KERNEL, "0x%x", val);
-	if (!soc_dev_attr->soc_id)
-		return -ENOMEM;
+	if (of_machine_is_compatible("fsl,imx8qm")) {
+		soc_dev_attr->soc_id = "i.MX8QM";
+		TKT340553_SW_WORKAROUND = true;
+	} else if (of_machine_is_compatible("fsl,imx8qxp"))
+		soc_dev_attr->soc_id = "i.MX8QXP";
+	else if (of_machine_is_compatible("fsl,imx8dxl"))
+		soc_dev_attr->soc_id = "i.MX8DXL";
 
 	/* format revision value passed from SCU firmware */
 	val = (id >> 5) & 0xf;
diff --git a/drivers/firmware/imx/imx-scu.c b/drivers/firmware/imx/imx-scu.c
index dca79caccd01..fd6de5771841 100644
--- a/drivers/firmware/imx/imx-scu.c
+++ b/drivers/firmware/imx/imx-scu.c
@@ -7,6 +7,7 @@
  *
  */
 
+#include <linux/arm-smccc.h>
 #include <linux/err.h>
 #include <linux/firmware/imx/ipc.h>
 #include <linux/firmware/imx/sci.h>
@@ -19,8 +20,11 @@
 #include <linux/of_platform.h>
 #include <linux/platform_device.h>
 
+#include <xen/xen.h>
+
+#define FSL_HVC_SC                      0xC6000000
 #define SCU_MU_CHAN_NUM		8
-#define MAX_RX_TIMEOUT		(msecs_to_jiffies(30))
+#define MAX_RX_TIMEOUT		(msecs_to_jiffies(3000))
 
 struct imx_sc_chan {
 	struct imx_sc_ipc *sc_ipc;
@@ -204,6 +208,7 @@ int imx_scu_call_rpc(struct imx_sc_ipc *sc_ipc, void *msg, bool have_resp)
 {
 	uint8_t saved_svc, saved_func;
 	struct imx_sc_rpc_msg *hdr;
+	struct arm_smccc_res res;
 	int ret;
 
 	if (WARN_ON(!sc_ipc || !msg))
@@ -218,33 +223,45 @@ int imx_scu_call_rpc(struct imx_sc_ipc *sc_ipc, void *msg, bool have_resp)
 		saved_func = ((struct imx_sc_rpc_msg *)msg)->func;
 	}
 	sc_ipc->count = 0;
-	ret = imx_scu_ipc_write(sc_ipc, msg);
-	if (ret < 0) {
-		dev_err(sc_ipc->dev, "RPC send msg failed: %d\n", ret);
-		goto out;
-	}
-
-	if (have_resp) {
-		if (!wait_for_completion_timeout(&sc_ipc->done,
-						 MAX_RX_TIMEOUT)) {
-			dev_err(sc_ipc->dev, "RPC send msg timeout\n");
-			mutex_unlock(&sc_ipc->lock);
-			return -ETIMEDOUT;
+	sc_ipc->rx_size = 0;
+	if (xen_initial_domain()) {
+		arm_smccc_hvc(FSL_HVC_SC, (uint64_t)msg, !have_resp, 0, 0, 0,
+			      0, 0, &res);
+		if (res.a0)
+			printk("Error FSL_HVC_SC %ld\n", res.a0);
+
+		ret = res.a0;
+
+	} else {
+		ret = imx_scu_ipc_write(sc_ipc, msg);
+		if (ret < 0) {
+			dev_err(sc_ipc->dev, "RPC send msg failed: %d\n", ret);
+			goto out;
 		}
 
-		/* response status is stored in hdr->func field */
-		hdr = msg;
-		ret = hdr->func;
-		/*
-		 * Some special SCU firmware APIs do NOT have return value
-		 * in hdr->func, but they do have response data, those special
-		 * APIs are defined as void function in SCU firmware, so they
-		 * should be treated as return success always.
-		 */
-		if ((saved_svc == IMX_SC_RPC_SVC_MISC) &&
-			(saved_func == IMX_SC_MISC_FUNC_UNIQUE_ID ||
-			 saved_func == IMX_SC_MISC_FUNC_GET_BUTTON_STATUS))
-			ret = 0;
+		if (have_resp) {
+			if (!wait_for_completion_timeout(&sc_ipc->done,
+							 MAX_RX_TIMEOUT)) {
+				dev_err(sc_ipc->dev, "RPC send msg timeout\n");
+				mutex_unlock(&sc_ipc->lock);
+				return -ETIMEDOUT;
+			}
+
+			/* response status is stored in hdr->func field */
+			hdr = msg;
+			ret = hdr->func;
+
+			/*
+			 * Some special SCU firmware APIs do NOT have return value
+			 * in hdr->func, but they do have response data, those special
+			 * APIs are defined as void function in SCU firmware, so they
+			 * should be treated as return success always.
+			 */
+			if ((saved_svc == IMX_SC_RPC_SVC_MISC) &&
+				(saved_func == IMX_SC_MISC_FUNC_UNIQUE_ID ||
+				 saved_func == IMX_SC_MISC_FUNC_GET_BUTTON_STATUS))
+				ret = 0;
+		}
 	}
 
 out:
@@ -354,7 +371,12 @@ static struct platform_driver imx_scu_driver = {
 	},
 	.probe = imx_scu_probe,
 };
-builtin_platform_driver(imx_scu_driver);
+
+static int __init imx_scu_driver_init(void)
+{
+	return platform_driver_register(&imx_scu_driver);
+}
+subsys_initcall_sync(imx_scu_driver_init);
 
 MODULE_AUTHOR("Dong Aisheng <aisheng.dong@nxp.com>");
 MODULE_DESCRIPTION("IMX SCU firmware protocol driver");
diff --git a/drivers/firmware/imx/rm.c b/drivers/firmware/imx/rm.c
index a12db6ff323b..6dd4db3861d7 100644
--- a/drivers/firmware/imx/rm.c
+++ b/drivers/firmware/imx/rm.c
@@ -13,6 +13,11 @@ struct imx_sc_msg_rm_rsrc_owned {
 	u16 resource;
 } __packed __aligned(4);
 
+struct imx_sc_msg_rm_pt {
+	struct imx_sc_rpc_msg hdr;
+	u8 val;
+} __packed __aligned(4);
+
 /*
  * This function check @resource is owned by current partition or not
  *
@@ -43,3 +48,160 @@ bool imx_sc_rm_is_resource_owned(struct imx_sc_ipc *ipc, u16 resource)
 	return hdr->func;
 }
 EXPORT_SYMBOL(imx_sc_rm_is_resource_owned);
+
+/*
+ * This function returns the current partition number
+ *
+ * @param[in]     ipc         IPC handle
+ * @param[out]    pt          holding the partition number
+ *
+ * @return Returns 0 for success and < 0 for errors.
+ */
+int imx_sc_rm_get_partition(struct imx_sc_ipc *ipc, u8 *pt)
+{
+	struct imx_sc_msg_rm_pt msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_PARTITION;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (pt != NULL)
+		*pt = msg.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_partition);
+
+struct imx_sc_msg_rm_find_memreg {
+	struct imx_sc_rpc_msg hdr;
+	union {
+		struct {
+			u32 add_start_hi;
+			u32 add_start_lo;
+			u32 add_end_hi;
+			u32 add_end_lo;
+		} req;
+		struct {
+			u8 val;
+		} resp;
+	} data;
+}  __packed __aligned(4);
+
+int imx_sc_rm_find_memreg(struct imx_sc_ipc *ipc, u8 *mr, u64 addr_start,
+			  u64 addr_end)
+{
+	struct imx_sc_msg_rm_find_memreg msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_FIND_MEMREG;
+	hdr->size = 5;
+
+	msg.data.req.add_start_hi = addr_start >> 32;
+	msg.data.req.add_start_lo = addr_start;
+	msg.data.req.add_end_hi = addr_end >> 32;
+	msg.data.req.add_end_lo = addr_end;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (mr)
+		*mr = msg.data.resp.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_find_memreg);
+
+struct imx_sc_msg_rm_get_resource_owner {
+	struct imx_sc_rpc_msg hdr;
+	union {
+		struct {
+			u16 resource;
+		} req;
+		struct {
+			u8 val;
+		} resp;
+	} data;
+} __packed __aligned(4);
+
+int imx_sc_rm_get_resource_owner(struct imx_sc_ipc *ipc, u16 resource, u8 *pt)
+{
+	struct imx_sc_msg_rm_get_resource_owner msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_RESOURCE_OWNER;
+	hdr->size = 2;
+
+	msg.data.req.resource = resource;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (pt)
+		*pt = msg.data.resp.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_resource_owner);
+
+struct imx_sc_msg_set_memreg_permissions {
+	struct imx_sc_rpc_msg hdr;
+	u8 mr;
+	u8 pt;
+	u8 perm;
+} __packed __aligned(4);
+
+int imx_sc_rm_set_memreg_permissions(struct imx_sc_ipc *ipc, u8 mr,
+				     u8 pt, u8 perm)
+{
+	struct imx_sc_msg_set_memreg_permissions msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_SET_MEMREG_PERMISSIONS;
+	hdr->size = 2;
+
+	msg.mr = mr;
+	msg.pt = pt;
+	msg.perm = perm;
+
+	return imx_scu_call_rpc(ipc, &msg, true);
+}
+EXPORT_SYMBOL(imx_sc_rm_set_memreg_permissions);
+
+int imx_sc_rm_get_did(struct imx_sc_ipc *ipc, u8 *did)
+{
+	struct imx_sc_rpc_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_DID;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret < 0)
+		return ret;
+
+	if (did)
+		*did = msg.func;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_did);
diff --git a/drivers/firmware/imx/scu-pd.c b/drivers/firmware/imx/scu-pd.c
old mode 100644
new mode 100755
index 946eea292b52..2328a9ed6740
--- a/drivers/firmware/imx/scu-pd.c
+++ b/drivers/firmware/imx/scu-pd.c
@@ -1,7 +1,7 @@
 // SPDX-License-Identifier: GPL-2.0+
 /*
  * Copyright (C) 2016 Freescale Semiconductor, Inc.
- * Copyright 2017-2018 NXP
+ * Copyright 2017-2018,2020 NXP
  *	Dong Aisheng <aisheng.dong@nxp.com>
  *
  * Implementation of the SCU based Power Domains
@@ -44,10 +44,13 @@
  *
  */
 
+#include <linux/arm-smccc.h>
 #include <dt-bindings/firmware/imx/rsrc.h>
+#include <linux/console.h>
 #include <linux/firmware/imx/sci.h>
 #include <linux/firmware/imx/svc/rm.h>
 #include <linux/io.h>
+#include <linux/irqchip/arm-gic-v3.h>
 #include <linux/module.h>
 #include <linux/of.h>
 #include <linux/of_address.h>
@@ -56,6 +59,17 @@
 #include <linux/pm.h>
 #include <linux/pm_domain.h>
 #include <linux/slab.h>
+#include <linux/syscore_ops.h>
+
+#define IMX_WU_MAX_IRQS	(((IMX_SC_R_LAST + 31) / 32 ) * 32 )
+
+#define IMX_SIP_WAKEUP_SRC              0xc2000009
+#define IMX_SIP_WAKEUP_SRC_SCU          0x1
+#define IMX_SIP_WAKEUP_SRC_IRQSTEER     0x2
+
+static u32 wu[IMX_WU_MAX_IRQS];
+static int wu_num;
+static void __iomem *gic_dist_base;
 
 /* SCU Power Mode Protocol definition */
 struct imx_sc_msg_req_set_resource_power_mode {
@@ -86,6 +100,8 @@ struct imx_sc_pd_soc {
 	u8 num_ranges;
 };
 
+int imx_con_rsrc;
+
 static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	/* LSIO SS */
 	{ "pwm", IMX_SC_R_PWM_0, 8, true, 0 },
@@ -99,24 +115,29 @@ static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	/* CONN SS */
 	{ "usb", IMX_SC_R_USB_0, 2, true, 0 },
 	{ "usb0phy", IMX_SC_R_USB_0_PHY, 1, false, 0 },
+	{ "usb1phy", IMX_SC_R_USB_1_PHY, 1, false, 0},
 	{ "usb2", IMX_SC_R_USB_2, 1, false, 0 },
 	{ "usb2phy", IMX_SC_R_USB_2_PHY, 1, false, 0 },
 	{ "sdhc", IMX_SC_R_SDHC_0, 3, true, 0 },
 	{ "enet", IMX_SC_R_ENET_0, 2, true, 0 },
 	{ "nand", IMX_SC_R_NAND, 1, false, 0 },
-	{ "mlb", IMX_SC_R_MLB_0, 1, true, 0 },
 
 	/* AUDIO SS */
 	{ "audio-pll0", IMX_SC_R_AUDIO_PLL_0, 1, false, 0 },
 	{ "audio-pll1", IMX_SC_R_AUDIO_PLL_1, 1, false, 0 },
 	{ "audio-clk-0", IMX_SC_R_AUDIO_CLK_0, 1, false, 0 },
 	{ "audio-clk-1", IMX_SC_R_AUDIO_CLK_1, 1, false, 0 },
-	{ "dma0-ch", IMX_SC_R_DMA_0_CH0, 16, true, 0 },
+	{ "mclk-out-0", IMX_SC_R_MCLK_OUT_0, 1, false, 0 },
+	{ "mclk-out-1", IMX_SC_R_MCLK_OUT_1, 1, false, 0 },
+	{ "dma0-ch", IMX_SC_R_DMA_0_CH0, 32, true, 0 },
 	{ "dma1-ch", IMX_SC_R_DMA_1_CH0, 16, true, 0 },
-	{ "dma2-ch", IMX_SC_R_DMA_2_CH0, 5, true, 0 },
+	{ "dma2-ch-0", IMX_SC_R_DMA_2_CH0, 5, true, 0 },
+	{ "dma2-ch-1", IMX_SC_R_DMA_2_CH5, 27, true, 0 },
+	{ "dma3-ch", IMX_SC_R_DMA_3_CH0, 32, true, 0 },
 	{ "asrc0", IMX_SC_R_ASRC_0, 1, false, 0 },
 	{ "asrc1", IMX_SC_R_ASRC_1, 1, false, 0 },
 	{ "esai0", IMX_SC_R_ESAI_0, 1, false, 0 },
+	{ "esai1", IMX_SC_R_ESAI_1, 1, false, 0 },
 	{ "spdif0", IMX_SC_R_SPDIF_0, 1, false, 0 },
 	{ "spdif1", IMX_SC_R_SPDIF_1, 1, false, 0 },
 	{ "sai", IMX_SC_R_SAI_0, 3, true, 0 },
@@ -133,11 +154,13 @@ static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	/* DMA SS */
 	{ "can", IMX_SC_R_CAN_0, 3, true, 0 },
 	{ "ftm", IMX_SC_R_FTM_0, 2, true, 0 },
-	{ "lpi2c", IMX_SC_R_I2C_0, 4, true, 0 },
+	{ "lpi2c", IMX_SC_R_I2C_0, 5, true, 0 },
 	{ "adc", IMX_SC_R_ADC_0, 1, true, 0 },
 	{ "lcd", IMX_SC_R_LCD_0, 1, true, 0 },
+	{ "lcd-pll", IMX_SC_R_ELCDIF_PLL, 1, true, 0 },
 	{ "lcd0-pwm", IMX_SC_R_LCD_0_PWM_0, 1, true, 0 },
-	{ "lpuart", IMX_SC_R_UART_0, 4, true, 0 },
+	{ "lpuart", IMX_SC_R_UART_0, 5, true, 0 },
+	{ "sim", IMX_SC_R_EMVSIM_0, 2, true, 0 },
 	{ "lpspi", IMX_SC_R_SPI_0, 4, true, 0 },
 	{ "irqstr_dsp", IMX_SC_R_IRQSTR_DSP, 1, false, 0 },
 
@@ -146,13 +169,22 @@ static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	{ "vpu-pid", IMX_SC_R_VPU_PID0, 8, true, 0 },
 	{ "vpu-dec0", IMX_SC_R_VPU_DEC_0, 1, false, 0 },
 	{ "vpu-enc0", IMX_SC_R_VPU_ENC_0, 1, false, 0 },
+	{ "vpu-enc1", IMX_SC_R_VPU_ENC_1, 1, false, 0 },
+	{ "vpu-mu0", IMX_SC_R_VPU_MU_0, 1, false, 0 },
+	{ "vpu-mu1", IMX_SC_R_VPU_MU_1, 1, false, 0 },
+	{ "vpu-mu2", IMX_SC_R_VPU_MU_2, 1, false, 0 },
 
 	/* GPU SS */
 	{ "gpu0-pid", IMX_SC_R_GPU_0_PID0, 4, true, 0 },
+	{ "gpu1-pid", IMX_SC_R_GPU_1_PID0, 4, true, 0 },
+
 
 	/* HSIO SS */
+	{ "pcie-a", IMX_SC_R_PCIE_A, 1, false, 0 },
+	{ "serdes-0", IMX_SC_R_SERDES_0, 1, false, 0 },
 	{ "pcie-b", IMX_SC_R_PCIE_B, 1, false, 0 },
 	{ "serdes-1", IMX_SC_R_SERDES_1, 1, false, 0 },
+	{ "sata-0", IMX_SC_R_SATA_0, 1, false, 0 },
 	{ "hsio-gpio", IMX_SC_R_HSIO_GPIO, 1, false, 0 },
 
 	/* MIPI SS */
@@ -160,12 +192,27 @@ static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	{ "mipi0-pwm0", IMX_SC_R_MIPI_0_PWM_0, 1, false, 0 },
 	{ "mipi0-i2c", IMX_SC_R_MIPI_0_I2C_0, 2, true, 0 },
 
+	{ "mipi1", IMX_SC_R_MIPI_1, 1, 0 },
+	{ "mipi1-pwm0", IMX_SC_R_MIPI_1_PWM_0, 1, 0 },
+	{ "mipi1-i2c", IMX_SC_R_MIPI_1_I2C_0, 2, 1 },
+
 	/* LVDS SS */
 	{ "lvds0", IMX_SC_R_LVDS_0, 1, false, 0 },
+	{ "lvds0-i2c0", IMX_SC_R_LVDS_0_I2C_0, 1, false, 0 },
+	{ "lvds0-pwm0", IMX_SC_R_LVDS_0_PWM_0, 1, false, 0 },
+
+	{ "lvds1", IMX_SC_R_LVDS_1, 1, false, 0 },
+	{ "lvds1-i2c0", IMX_SC_R_LVDS_1_I2C_0, 1, false, 0 },
+	{ "lvds1-pwm0", IMX_SC_R_LVDS_1_PWM_0, 1, false, 0 },
 
 	/* DC SS */
 	{ "dc0", IMX_SC_R_DC_0, 1, false, 0 },
 	{ "dc0-pll", IMX_SC_R_DC_0_PLL_0, 2, true, 0 },
+	{ "dc0-video", IMX_SC_R_DC_0_VIDEO0, 2, true, 0 },
+
+	{ "dc1", IMX_SC_R_DC_1, 1, false, 0 },
+	{ "dc1-pll", IMX_SC_R_DC_1_PLL_0, 2, true, 0 },
+	{ "dc1-video", IMX_SC_R_DC_1_VIDEO0, 2, true, 0 },
 
 	/* CM40 SS */
 	{ "cm40-i2c", IMX_SC_R_M4_0_I2C, 1, false, 0 },
@@ -180,6 +227,53 @@ static const struct imx_sc_pd_range imx8qxp_scu_pd_ranges[] = {
 	{ "cm41-pid", IMX_SC_R_M4_1_PID0, 5, true, 0},
 	{ "cm41-mu-a1", IMX_SC_R_M4_1_MU_1A, 1, false, 0},
 	{ "cm41-lpuart", IMX_SC_R_M4_1_UART, 1, false, 0},
+
+	/* SECO SS */
+	{ "seco_mu", IMX_SC_R_SECO_MU_2, 3, true, 2},
+
+	/* V2X SS */
+	{ "v2x_mu", IMX_SC_R_V2X_MU_0, 2, true, 0},
+	{ "v2x_mu", IMX_SC_R_V2X_MU_2, 1, true, 2},
+	{ "v2x_mu", IMX_SC_R_V2X_MU_3, 2, true, 3},
+
+	/* DB SS */
+	{ "perf", IMX_SC_R_PERF, 1, false, 0},
+
+	/* IMAGE SS */
+	{ "img-pdma", IMX_SC_R_ISI_CH0, 8, true, 0 },
+	{ "img-csi0", IMX_SC_R_CSI_0, 1, false, 0 },
+	{ "img-csi0-i2c0", IMX_SC_R_CSI_0_I2C_0, 1, false, 0 },
+	{ "img-csi0-pwm0", IMX_SC_R_CSI_0_PWM_0, 1, false, 0 },
+	{ "img-csi1", IMX_SC_R_CSI_1, 1, false, 0 },
+	{ "img-csi1-i2c0", IMX_SC_R_CSI_1_I2C_0, 1, false, 0 },
+	{ "img-csi1-pwm0", IMX_SC_R_CSI_1_PWM_0, 1, false, 0 },
+	{ "img-parallel", IMX_SC_R_PI_0, 1, false, 0 },
+	{ "img-parallel-i2c0", IMX_SC_R_PI_0_I2C_0, 1, false, 0 },
+	{ "img-parallel-pwm0", IMX_SC_R_PI_0_PWM_0, 2, true, 0 },
+	{ "img-parallel-pll", IMX_SC_R_PI_0_PLL, 1, false, 0 },
+	{ "img-jpegdec-mp", IMX_SC_R_MJPEG_DEC_MP, 1, false, 0 },
+	{ "img-jpegdec-s0", IMX_SC_R_MJPEG_DEC_S0, 4, true, 0 },
+	{ "img-jpegenc-mp", IMX_SC_R_MJPEG_ENC_MP, 1, false, 0 },
+	{ "img-jpegenc-s0", IMX_SC_R_MJPEG_ENC_S0, 4, true, 0 },
+
+	/* HDMI TX SS */
+	{ "hdmi-tx", IMX_SC_R_HDMI, 1, false, 0},
+	{ "hdmi-tx-i2s", IMX_SC_R_HDMI_I2S, 1, false, 0},
+	{ "hdmi-tx-i2c0", IMX_SC_R_HDMI_I2C_0, 1, false, 0},
+	{ "hdmi-tx-pll0", IMX_SC_R_HDMI_PLL_0, 1, false, 0},
+	{ "hdmi-tx-pll1", IMX_SC_R_HDMI_PLL_1, 1, false, 0},
+
+	/* HDMI RX SS */
+	{ "hdmi-rx", IMX_SC_R_HDMI_RX, 1, false, 0},
+	{ "hdmi-rx-pwm", IMX_SC_R_HDMI_RX_PWM_0, 1, false, 0},
+	{ "hdmi-rx-i2c0", IMX_SC_R_HDMI_RX_I2C_0, 1, false, 0},
+	{ "hdmi-rx-bypass", IMX_SC_R_HDMI_RX_BYPASS, 1, false, 0},
+
+	/* SECURITY SS */
+	{ "sec-jr", IMX_SC_R_CAAM_JR2, 2, true, 2},
+
+	/* BOARD SS */
+	{ "board", IMX_SC_R_BOARD_R0, 8, true, 0},
 };
 
 static const struct imx_sc_pd_soc imx8qxp_scu_pd = {
@@ -195,6 +289,73 @@ to_imx_sc_pd(struct generic_pm_domain *genpd)
 	return container_of(genpd, struct imx_sc_pm_domain, pd);
 }
 
+static int imx_pm_domains_suspend(void)
+{
+	struct arm_smccc_res res;
+	u32 offset;
+	int i;
+
+	for (i = 0; i < wu_num; i++) {
+		offset = GICD_ISENABLER + ((wu[i] + 32) / 32) * 4;
+		if (BIT(wu[i] % 32) & readl_relaxed(gic_dist_base + offset)) {
+			arm_smccc_smc(IMX_SIP_WAKEUP_SRC,
+				      IMX_SIP_WAKEUP_SRC_IRQSTEER,
+				      0, 0, 0, 0, 0, 0, &res);
+			return 0;
+		}
+	}
+
+	arm_smccc_smc(IMX_SIP_WAKEUP_SRC,
+		      IMX_SIP_WAKEUP_SRC_SCU,
+		      0, 0, 0, 0, 0, 0, &res);
+
+	return 0;
+}
+
+struct syscore_ops imx_pm_domains_syscore_ops = {
+	.suspend = imx_pm_domains_suspend,
+};
+
+static void imx_sc_pd_enable_irqsteer_wakeup(struct device_node *np)
+{
+	struct device_node *gic_node;
+	unsigned int i;
+
+	wu_num = of_property_count_u32_elems(np, "wakeup-irq");
+	if (wu_num <= 0) {
+		pr_warn("no irqsteer wakeup source supported!\n");
+		return;
+	}
+
+	gic_node = of_find_compatible_node(NULL, NULL, "arm,gic-v3");
+	WARN_ON(!gic_node);
+
+	gic_dist_base = of_iomap(gic_node, 0);
+	WARN_ON(!gic_dist_base);
+
+	for (i = 0; i < wu_num; i++)
+		WARN_ON(of_property_read_u32_index(np, "wakeup-irq", i, &wu[i]));
+
+	register_syscore_ops(&imx_pm_domains_syscore_ops);
+}
+
+static void imx_sc_pd_get_console_rsrc(void)
+{
+	struct of_phandle_args specs;
+	int ret;
+
+	if (!of_stdout)
+		return;
+
+	ret = of_parse_phandle_with_args(of_stdout, "power-domains",
+					 "#power-domain-cells",
+					 0, &specs);
+	if (ret)
+		return;
+
+	imx_con_rsrc = specs.args[0];
+}
+
 static int imx_sc_pd_power(struct generic_pm_domain *domain, bool power_on)
 {
 	struct imx_sc_msg_req_set_resource_power_mode msg;
@@ -210,7 +371,12 @@ static int imx_sc_pd_power(struct generic_pm_domain *domain, bool power_on)
 	hdr->size = 2;
 
 	msg.resource = pd->rsrc;
-	msg.mode = power_on ? IMX_SC_PM_PW_MODE_ON : IMX_SC_PM_PW_MODE_LP;
+	msg.mode = power_on ? IMX_SC_PM_PW_MODE_ON : pd->pd.state_idx ?
+		   IMX_SC_PM_PW_MODE_OFF : IMX_SC_PM_PW_MODE_LP;
+
+	/* keep uart console power on for no_console_suspend */
+        if (imx_con_rsrc == pd->rsrc && !console_suspend_enabled && !power_on)
+                return 0;
 
 	ret = imx_scu_call_rpc(pm_ipc_handle, &msg, true);
 	if (ret)
@@ -255,6 +421,8 @@ imx_scu_add_pm_domain(struct device *dev, int idx,
 		      const struct imx_sc_pd_range *pd_ranges)
 {
 	struct imx_sc_pm_domain *sc_pd;
+	struct genpd_power_state *states;
+	bool is_off = true;
 	int ret;
 
 	if (!imx_sc_rm_is_resource_owned(pm_ipc_handle, pd_ranges->rsrc + idx))
@@ -264,9 +432,23 @@ imx_scu_add_pm_domain(struct device *dev, int idx,
 	if (!sc_pd)
 		return ERR_PTR(-ENOMEM);
 
+	states = devm_kcalloc(dev, 2, sizeof(*states), GFP_KERNEL);
+	if (!states) {
+		devm_kfree(dev, sc_pd);
+		return ERR_PTR(-ENOMEM);
+	}
+
 	sc_pd->rsrc = pd_ranges->rsrc + idx;
 	sc_pd->pd.power_off = imx_sc_pd_power_off;
 	sc_pd->pd.power_on = imx_sc_pd_power_on;
+	sc_pd->pd.flags |= GENPD_FLAG_ACTIVE_WAKEUP;
+	states[0].power_off_latency_ns = 25000;
+	states[0].power_on_latency_ns =  25000;
+	states[1].power_off_latency_ns = 2500000;
+	states[1].power_on_latency_ns =  2500000;
+
+	sc_pd->pd.states = states;
+	sc_pd->pd.state_count = 2;
 
 	if (pd_ranges->postfix)
 		snprintf(sc_pd->name, sizeof(sc_pd->name),
@@ -276,20 +458,26 @@ imx_scu_add_pm_domain(struct device *dev, int idx,
 			 "%s", pd_ranges->name);
 
 	sc_pd->pd.name = sc_pd->name;
+	if (imx_con_rsrc == sc_pd->rsrc) {
+		sc_pd->pd.flags |= GENPD_FLAG_RPM_ALWAYS_ON;
+		is_off = false;
+	}
 
 	if (sc_pd->rsrc >= IMX_SC_R_LAST) {
 		dev_warn(dev, "invalid pd %s rsrc id %d found",
 			 sc_pd->name, sc_pd->rsrc);
 
 		devm_kfree(dev, sc_pd);
+		devm_kfree(dev, states);
 		return NULL;
 	}
 
-	ret = pm_genpd_init(&sc_pd->pd, NULL, true);
+	ret = pm_genpd_init(&sc_pd->pd, NULL, is_off);
 	if (ret) {
 		dev_warn(dev, "failed to init pd %s rsrc id %d",
 			 sc_pd->name, sc_pd->rsrc);
 		devm_kfree(dev, sc_pd);
+		devm_kfree(dev, states);
 		return NULL;
 	}
 
@@ -351,6 +539,9 @@ static int imx_sc_pd_probe(struct platform_device *pdev)
 	if (!pd_soc)
 		return -ENODEV;
 
+	imx_sc_pd_get_console_rsrc();
+	imx_sc_pd_enable_irqsteer_wakeup(pdev->dev.of_node);
+
 	return imx_scu_init_pm_domains(&pdev->dev, pd_soc);
 }
 
@@ -367,7 +558,12 @@ static struct platform_driver imx_sc_pd_driver = {
 	},
 	.probe = imx_sc_pd_probe,
 };
-builtin_platform_driver(imx_sc_pd_driver);
+
+static int __init imx_sc_pd_driver_init(void)
+{
+	return platform_driver_register(&imx_sc_pd_driver);
+}
+subsys_initcall(imx_sc_pd_driver_init);
 
 MODULE_AUTHOR("Dong Aisheng <aisheng.dong@nxp.com>");
 MODULE_DESCRIPTION("IMX SCU Power Domain driver");
diff --git a/drivers/firmware/imx/seco.c b/drivers/firmware/imx/seco.c
new file mode 100644
index 000000000000..18232c70053b
--- /dev/null
+++ b/drivers/firmware/imx/seco.c
@@ -0,0 +1,249 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2020 NXP
+ *
+ * File containing client-side RPC functions for the SECO service. These
+ * function are ported to clients that communicate to the SC.
+ */
+
+#include <linux/firmware/imx/sci.h>
+
+struct imx_sc_msg_seco_get_build_id {
+	struct imx_sc_rpc_msg hdr;
+	u32 version;
+	u32 commit;
+} __packed __aligned(4);
+
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit)
+{
+	struct imx_sc_msg_seco_get_build_id msg = {0};
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_SECO;
+	hdr->func = IMX_SC_SECO_FUNC_BUILD_INFO;
+	hdr->size = 1;
+
+	imx_scu_call_rpc(ipc, &msg, true);
+
+	if (version)
+		*version = msg.version;
+	if (commit)
+		*commit = msg.commit;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_build_info);
+
+struct imx_sc_msg_seco_sab_msg {
+	struct imx_sc_rpc_msg hdr;
+	u32 smsg_addr_hi;
+	u32 smsg_addr_lo;
+} __packed __aligned(4);
+
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr)
+{
+	struct imx_sc_msg_seco_sab_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_SECO;
+	hdr->func = IMX_SC_SECO_FUNC_SAB_MSG;
+	hdr->size = 3;
+
+	msg.smsg_addr_hi = smsg_addr >> 32;
+	msg.smsg_addr_lo = smsg_addr;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	return ret;
+}
+EXPORT_SYMBOL(imx_sc_seco_sab_msg);
+
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc)
+{
+	struct imx_sc_rpc_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_ENABLE;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_enable);
+
+struct imx_sc_msg_req_seco_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data0;
+	u32 data1;
+	u32 data2;
+	u32 data3;
+	u32 data4;
+	u8 id;
+	u8 access;
+	u8 size;
+} __packed __aligned(4);
+
+struct imx_sc_msg_resp_seco_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data0;
+	u32 data1;
+	u32 data2;
+	u32 data3;
+	u32 data4;
+} __packed __aligned(4);
+
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size)
+{
+	struct imx_sc_msg_req_seco_config msg;
+	struct imx_sc_msg_resp_seco_config *resp;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	if (!ipc)
+		return -EINVAL;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_CONFIG;
+	hdr->size = 7;
+
+	/* Check the pointers on data are valid and set it if doing a write */
+	switch (size) {
+	case 5:
+		if (data4) {
+			if (access)
+				msg.data4 = *data4;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 4:
+		if (data3) {
+			if (access)
+				msg.data3 = *data3;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 3:
+		if (data2) {
+			if (access)
+				msg.data2 = *data2;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 2:
+		if (data1) {
+			if (access)
+				msg.data1 = *data1;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 1:
+		if (data0) {
+			if (access)
+				msg.data0 = *data0;
+		} else {
+			return -EINVAL;
+		}
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	msg.id = id;
+	msg.access = access;
+	msg.size = size;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	resp = (struct imx_sc_msg_resp_seco_config *)&msg;
+
+	/* Pointers already checked so we just copy the data if reading */
+	if (!access)
+		switch (size) {
+		case 5:
+			*data4 = resp->data4;
+		fallthrough;
+		case 4:
+			*data3 = resp->data3;
+		fallthrough;
+		case 3:
+			*data2 = resp->data2;
+		fallthrough;
+		case 2:
+			*data1 = resp->data1;
+		fallthrough;
+		case 1:
+			*data0 = resp->data0;
+		}
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_config);
+
+struct imx_sc_msg_req_seco_dgo_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data;
+	u8 id;
+	u8 access;
+} __packed __aligned(4);
+
+struct imx_sc_msg_resp_seco_dgo_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data;
+} __packed __aligned(4);
+
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data)
+{
+	struct imx_sc_msg_req_seco_dgo_config msg;
+	struct imx_sc_msg_resp_seco_dgo_config *resp;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	if (!ipc)
+		return -EINVAL;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_DGO_CONFIG;
+	hdr->size = 3;
+
+	if (access) {
+		if (data)
+			msg.data = *data;
+		else
+			return -EINVAL;
+	}
+
+	msg.access = access;
+	msg.id = id;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	resp = (struct imx_sc_msg_resp_seco_dgo_config *)&msg;
+
+	if (!access && data)
+		*data = resp->data;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_dgo_config);
diff --git a/drivers/firmware/imx/seco_mu.c b/drivers/firmware/imx/seco_mu.c
new file mode 100644
index 000000000000..a6c8e06ccf52
--- /dev/null
+++ b/drivers/firmware/imx/seco_mu.c
@@ -0,0 +1,1212 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright 2019-2020 NXP
+ */
+
+/*
+ * This driver allows to send messages to the SECO using a shared mailbox. The
+ * messages must follow the protocol defined.
+ */
+
+/*
+ * Architecture of the driver:
+ *
+ *                                     Non-Secure           +   Secure
+ *                                                          |
+ *                                                          |
+ *                   +---------+      +-------------+       |
+ *                   |seco_mu.c+<---->+imx-mailbox.c|       |
+ *                   |         |      |  mailbox.c  +<-->+------+    +------+
+ *                   +---+-----+      +-------------+    | MU X +<-->+ SECO |
+ *                       |                               +------+    +------+
+ *                       +----------------+                 |
+ *                       |                |                 |
+ *                       v                v                 |
+ *                   logical           logical              |
+ *                   receiver          waiter               |
+ *                      +                 +                 |
+ *                      |                 |                 |
+ *                      |                 |                 |
+ *                      |            +----+------+          |
+ *                      |            |           |          |
+ *                      |            |           |          |
+ *               device_ctx     device_ctx     device_ctx   |
+ *                                                          |
+ *                 User 0        User 1       User Y        |
+ *                 +------+      +------+     +------+      |
+ *                 |misc.c|      |misc.c|     |misc.c|      |
+ * kernel space    +------+      +------+     +------+      |
+ *                                                          |
+ *  +------------------------------------------------------ |
+ *                     |             |           |          |
+ * userspace     /dev/seco_muXch0    |           |          |
+ *                          /dev/seco_muXch1     |          |
+ *                                        /dev/seco_muXchY  |
+ *                                                          |
+ *
+ * When a user sends a command to the seco, it registers its device_ctx as
+ * waiter of a response from SECO
+ *
+ * A user can be registered as receiver of command by the SECO.
+ *
+ * When a message is received, the driver select the device_ctx receiving the
+ * message depending on the tag in the message. It selects the device_ctx
+ * accordingly.
+ */
+
+#include <linux/dma-mapping.h>
+#include <linux/interrupt.h>
+#include <linux/miscdevice.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/uaccess.h>
+#include <linux/firmware/imx/sci.h>
+#include <dt-bindings/firmware/imx/rsrc.h>
+#include <linux/firmware/imx/seco_mu_ioctl.h>
+#include <linux/mailbox_client.h>
+
+#define MAX_RECV_SIZE 31
+#define MAX_RECV_SIZE_BYTES (MAX_RECV_SIZE * sizeof(u32))
+#define MAX_MESSAGE_SIZE 31
+#define MAX_MESSAGE_SIZE_BYTES (MAX_MESSAGE_SIZE * sizeof(u32))
+#define MESSAGE_SIZE(hdr) (((struct she_mu_hdr *)(&(hdr)))->size)
+#define MESSAGE_TAG(hdr) (((struct she_mu_hdr *)(&(hdr)))->tag)
+
+#define DEFAULT_MESSAGING_TAG_COMMAND           (0x17u)
+#define DEFAULT_MESSAGING_TAG_RESPONSE          (0xe1u)
+
+#define SECURE_RAM_BASE_ADDRESS	(0x31800000ULL)
+#define SECURE_RAM_BASE_ADDRESS_SCU	(0x20800000u)
+#define SECURE_RAM_SIZE	(0x10000ULL)
+
+#define SECO_MU_DEFAULT_MAX_USERS 4
+
+#define SECO_MU_INTERRUPT_INDEX	(0u)
+#define SECO_DEFAULT_MU_INDEX	(1u)
+#define SECO_DEFAULT_TZ		(0u)
+#define DEFAULT_DID		(0u)
+
+#define MAX_DATA_SIZE_PER_USER  (65 * 1024)
+
+#define SC_IRQ_V2X_RESET (1<<7)
+
+/* Header of the messages exchange with the SECO */
+struct she_mu_hdr {
+	u8 ver;
+	u8 size;
+	u8 command;
+	u8 tag;
+}  __packed;
+
+/* Status of a char device */
+enum mu_device_status_t {
+	MU_FREE,
+	MU_OPENED
+};
+
+struct seco_shared_mem {
+	dma_addr_t dma_addr;
+	u32 size;
+	u32 pos;
+	u8 *ptr;
+};
+
+struct seco_out_buffer_desc {
+	u8 *out_ptr;
+	u8 *out_usr_ptr;
+	u32 out_size;
+	struct list_head link;
+};
+
+/* Private struct for each char device instance. */
+struct seco_mu_device_ctx {
+	struct device *dev;
+	struct seco_mu_priv *mu_priv;
+	struct miscdevice miscdev;
+
+	enum mu_device_status_t status;
+	wait_queue_head_t wq;
+	struct semaphore fops_lock;
+
+	u32 pending_hdr;
+	struct list_head pending_out;
+
+	struct seco_shared_mem secure_mem;
+	struct seco_shared_mem non_secure_mem;
+
+	u32 temp_cmd[MAX_MESSAGE_SIZE];
+	u32 temp_resp[MAX_RECV_SIZE];
+	u32 temp_resp_size;
+	struct notifier_block scu_notify;
+	bool v2x_reset;
+};
+
+/* Private struct for seco MU driver. */
+struct seco_mu_priv {
+	struct seco_mu_device_ctx *cmd_receiver_dev;
+	struct seco_mu_device_ctx *waiting_rsp_dev;
+	/*
+	 * prevent parallel access to the MU registers
+	 * e.g. a user trying to send a command while the other one is
+	 * sending a response.
+	 */
+	struct mutex mu_lock;
+	/*
+	 * prevent a command to be sent on the MU while another one is still
+	 * processing. (response to a command is allowed)
+	 */
+	struct mutex mu_cmd_lock;
+	struct device *dev;
+	u32 seco_mu_id;
+	u8 cmd_tag;
+	u8 rsp_tag;
+
+	struct mbox_client cl;
+	struct mbox_chan *tx_chan;
+	struct mbox_chan *rx_chan;
+
+	struct imx_sc_ipc *ipc_scu;
+	u8 seco_part_owner;
+};
+
+/* macro to log operation of a misc device */
+#define miscdev_dbg(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_dbg((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+#define miscdev_info(p_miscdev, fmt, va_args...)                               \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_info((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name, \
+		##va_args);                                                    \
+	})
+
+#define miscdev_err(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_err((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+/* macro to log operation of a device context */
+#define devctx_dbg(p_devctx, fmt, va_args...) \
+	miscdev_dbg(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_info(p_devctx, fmt, va_args...) \
+	miscdev_info(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_err(p_devctx, fmt, va_args...) \
+	miscdev_err((&(p_devctx)->miscdev), fmt, ##va_args)
+
+#define IMX_SC_RM_PERM_FULL         7U	/* Full access */
+
+/* Give access to SECU to the memory we want to share */
+static int seco_mu_setup_seco_memory_access(struct seco_mu_device_ctx *dev_ctx,
+					    u64 addr, u32 len)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	int ret;
+	u8 mr;
+
+	ret = imx_sc_rm_find_memreg(priv->ipc_scu, &mr, addr, addr + len);
+	if (ret) {
+		devctx_err(dev_ctx, "Fail find memreg\n");
+		goto exit;
+	}
+
+	ret = imx_sc_rm_set_memreg_permissions(priv->ipc_scu, mr,
+					       priv->seco_part_owner,
+					       IMX_SC_RM_PERM_FULL);
+	if (ret) {
+		devctx_err(dev_ctx, "Fail set permission for resource\n");
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+/*
+ * File operations for user-space
+ */
+/* Open a char device. */
+static int seco_mu_fops_open(struct inode *nd, struct file *fp)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	int err;
+
+	/* Avoid race if opened at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* Authorize only 1 instance. */
+	if (dev_ctx->status != MU_FREE) {
+		err = -EBUSY;
+		goto exit;
+	}
+
+	/*
+	 * Allocate some memory for data exchanges with SECO.
+	 * This will be used for data not requiring secure memory.
+	 */
+	dev_ctx->non_secure_mem.ptr = dmam_alloc_coherent(dev_ctx->dev,
+					MAX_DATA_SIZE_PER_USER,
+					&dev_ctx->non_secure_mem.dma_addr,
+					GFP_KERNEL);
+	if (!dev_ctx->non_secure_mem.ptr) {
+		err = -ENOMEM;
+		devctx_err(dev_ctx, "Failed to map shared memory with SECO\n");
+		goto exit;
+	}
+
+	err = seco_mu_setup_seco_memory_access(dev_ctx,
+					       dev_ctx->non_secure_mem.dma_addr,
+					       MAX_DATA_SIZE_PER_USER);
+	if (err) {
+		err = -EPERM;
+		devctx_err(dev_ctx,
+			   "Failed to share access to shared memory\n");
+		goto free_coherent;
+	}
+
+	dev_ctx->non_secure_mem.size = MAX_DATA_SIZE_PER_USER;
+	dev_ctx->non_secure_mem.pos = 0;
+	dev_ctx->status = MU_OPENED;
+
+	dev_ctx->pending_hdr = 0;
+	dev_ctx->v2x_reset = 0;
+
+	goto exit;
+
+free_coherent:
+	dmam_free_coherent(dev_ctx->mu_priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Close a char device. */
+static int seco_mu_fops_close(struct inode *nd, struct file *fp)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	struct seco_out_buffer_desc *out_buf_desc;
+
+	/* Avoid race if closed at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* The device context has not been opened */
+	if (dev_ctx->status != MU_OPENED)
+		goto exit;
+
+	/* check if this device was registered as command receiver. */
+	if (mu_priv->cmd_receiver_dev == dev_ctx)
+		mu_priv->cmd_receiver_dev = NULL;
+
+	/* check if this device was registered as waiting response. */
+	if (mu_priv->waiting_rsp_dev == dev_ctx) {
+		mu_priv->waiting_rsp_dev = NULL;
+		mutex_unlock(&mu_priv->mu_cmd_lock);
+	}
+
+	/* Unmap secure memory shared buffer. */
+	if (dev_ctx->secure_mem.ptr)
+		devm_iounmap(dev_ctx->dev, dev_ctx->secure_mem.ptr);
+
+	dev_ctx->secure_mem.ptr = NULL;
+	dev_ctx->secure_mem.dma_addr = 0;
+	dev_ctx->secure_mem.size = 0;
+	dev_ctx->secure_mem.pos = 0;
+
+	/* Free non-secure shared buffer. */
+	dmam_free_coherent(dev_ctx->mu_priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+	dev_ctx->non_secure_mem.ptr = NULL;
+	dev_ctx->non_secure_mem.dma_addr = 0;
+	dev_ctx->non_secure_mem.size = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	while (!list_empty(&dev_ctx->pending_out)) {
+		out_buf_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						struct seco_out_buffer_desc,
+						link);
+		__list_del_entry(&out_buf_desc->link);
+		devm_kfree(dev_ctx->dev, out_buf_desc);
+	}
+
+	dev_ctx->status = MU_FREE;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return 0;
+}
+
+/* Write a message to the MU. */
+static ssize_t seco_mu_fops_write(struct file *fp, const char __user *buf,
+				  size_t size, loff_t *ppos)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	u32 nb_words = 0, header;
+	int err;
+
+	devctx_dbg(dev_ctx, "write from buf (%p)%ld, ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (size < sizeof(struct she_mu_hdr)) {
+		devctx_err(dev_ctx, "User buffer too small(%ld < %lu)\n", size,
+			   sizeof(struct she_mu_hdr));
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	if (size > MAX_MESSAGE_SIZE_BYTES) {
+		devctx_err(dev_ctx, "User buffer too big(%ld > %lu)\n", size,
+			   MAX_MESSAGE_SIZE_BYTES);
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	/* Copy data to buffer */
+	err = (int)copy_from_user(dev_ctx->temp_cmd, buf, size);
+	if (err) {
+		err = -EFAULT;
+		devctx_err(dev_ctx, "Fail copy message from user\n");
+		goto exit;
+	}
+
+	print_hex_dump_debug("from user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_cmd, size, false);
+
+	header = dev_ctx->temp_cmd[0];
+
+	/* Check the message is valid according to tags */
+	if (MESSAGE_TAG(header) == mu_priv->cmd_tag) {
+		/*
+		 * unlocked in seco_mu_receive_work_handler when the
+		 * response to this command is received.
+		 */
+		mutex_lock(&mu_priv->mu_cmd_lock);
+		mu_priv->waiting_rsp_dev = dev_ctx;
+	} else if (MESSAGE_TAG(header) == mu_priv->rsp_tag) {
+		/* Check the device context can send the command */
+		if (dev_ctx != mu_priv->cmd_receiver_dev) {
+			devctx_err(dev_ctx,
+				   "This channel is not configured to send response to SECO\n");
+			err = -EPERM;
+			goto exit;
+		}
+	} else {
+		devctx_err(dev_ctx, "The message does not have a valid TAG\n");
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/*
+	 * Check that the size passed as argument matches the size
+	 * carried in the message.
+	 */
+	nb_words = MESSAGE_SIZE(header);
+	if (nb_words * sizeof(u32) != size) {
+		devctx_err(dev_ctx, "User buffer too small\n");
+		goto exit;
+	}
+
+	mutex_lock(&mu_priv->mu_lock);
+
+	/* Send message */
+	devctx_dbg(dev_ctx, "sending message\n");
+	err = mbox_send_message(mu_priv->tx_chan, dev_ctx->temp_cmd);
+	if (err < 0) {
+		devctx_err(dev_ctx, "Failed to send message\n");
+		goto unlock;
+	}
+
+	err = nb_words * (u32)sizeof(u32);
+
+unlock:
+	mutex_unlock(&mu_priv->mu_lock);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/*
+ * Read a message from the MU.
+ * Blocking until a message is available.
+ */
+static ssize_t seco_mu_fops_read(struct file *fp, char __user *buf,
+				 size_t size, loff_t *ppos)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	u32 data_size = 0, size_to_copy = 0;
+	struct seco_out_buffer_desc *b_desc;
+	int err;
+
+	devctx_dbg(dev_ctx, "read to buf %p(%ld), ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (dev_ctx->v2x_reset) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/* Wait until the complete message is received on the MU. */
+	err = wait_event_interruptible(dev_ctx->wq, dev_ctx->pending_hdr != 0);
+	if (err) {
+		devctx_err(dev_ctx, "Interrupted by signal\n");
+		goto exit;
+	}
+
+	if (dev_ctx->v2x_reset) {
+		err = -EINVAL;
+		dev_ctx->v2x_reset = 0;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "%s %s\n", __func__,
+		   "message received, start transmit to user");
+
+	/* Check that the size passed as argument is larger than
+	 * the one carried in the message.
+	 */
+	data_size = dev_ctx->temp_resp_size * sizeof(u32);
+	size_to_copy = data_size;
+	if (size_to_copy > size) {
+		devctx_dbg(dev_ctx, "User buffer too small (%ld < %d)\n",
+			   size, size_to_copy);
+		size_to_copy = size;
+	}
+
+	/* We may need to copy the output data to user before
+	 * delivering the completion message.
+	 */
+	while (!list_empty(&dev_ctx->pending_out)) {
+		b_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						  struct seco_out_buffer_desc,
+						  link);
+		if (b_desc->out_usr_ptr && b_desc->out_ptr) {
+			devctx_dbg(dev_ctx, "Copy output data to user\n");
+			err = (int)copy_to_user(b_desc->out_usr_ptr,
+						b_desc->out_ptr,
+						b_desc->out_size);
+			if (err) {
+				devctx_err(dev_ctx,
+					   "Failed to copy output data to user\n");
+				err = -EFAULT;
+				goto exit;
+			}
+		}
+		__list_del_entry(&b_desc->link);
+		devm_kfree(dev_ctx->dev, b_desc);
+	}
+
+	/* Copy data from the buffer */
+	print_hex_dump_debug("to user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_resp, size_to_copy, false);
+	err = (int)copy_to_user(buf, dev_ctx->temp_resp, size_to_copy);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	err = size_to_copy;
+
+	/* free memory allocated on the shared buffers. */
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	dev_ctx->pending_hdr = 0;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Configure the shared memory according to user config */
+static int
+seco_mu_ioctl_shared_mem_cfg_handler(struct seco_mu_device_ctx *dev_ctx,
+				     unsigned long arg)
+{
+	struct seco_mu_ioctl_shared_mem_cfg cfg;
+	int err = -EINVAL;
+	u64 high_boundary;
+
+	/* Check if not already configured. */
+	if (dev_ctx->secure_mem.dma_addr != 0u) {
+		devctx_err(dev_ctx, "Shared memory not configured\n");
+		goto exit;
+	}
+
+	err = (int)copy_from_user(&cfg, (u8 *)arg,
+		sizeof(cfg));
+	if (err) {
+		devctx_err(dev_ctx, "Fail copy shared memory config to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "cfg offset: %u(%d)\n", cfg.base_offset, cfg.size);
+
+	high_boundary = cfg.base_offset;
+	if (high_boundary > SECURE_RAM_SIZE) {
+		devctx_err(dev_ctx, "base offset is over secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	high_boundary += cfg.size;
+	if (high_boundary > SECURE_RAM_SIZE) {
+		devctx_err(dev_ctx, "total memory is over secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	dev_ctx->secure_mem.dma_addr = (dma_addr_t)cfg.base_offset;
+	dev_ctx->secure_mem.size = cfg.size;
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->secure_mem.ptr = devm_ioremap(dev_ctx->dev,
+					(phys_addr_t)(SECURE_RAM_BASE_ADDRESS +
+					(u64)dev_ctx->secure_mem.dma_addr),
+					dev_ctx->secure_mem.size);
+	if (!dev_ctx->secure_mem.ptr) {
+		devctx_err(dev_ctx, "Failed to map secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/*
+ * Copy a buffer of daa to/from the user and return the address to use in
+ * messages
+ */
+static int seco_mu_ioctl_setup_iobuf_handler(struct seco_mu_device_ctx *dev_ctx,
+					     unsigned long arg)
+{
+	struct seco_out_buffer_desc *out_buf_desc;
+	struct seco_mu_ioctl_setup_iobuf io;
+	struct seco_shared_mem *shared_mem;
+	int err = -EINVAL;
+	u32 pos;
+
+	err = (int)copy_from_user(&io,
+		(u8 *)arg,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed copy iobuf config from user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "io [buf: %p(%d) flag: %x]\n",
+		   io.user_buf, io.length, io.flags);
+
+	if (io.length == 0 || !io.user_buf) {
+		/*
+		 * Accept NULL pointers since some buffers are optional
+		 * in SECO commands. In this case we should return 0 as
+		 * pointer to be embedded into the message.
+		 * Skip all data copy part of code below.
+		 */
+		io.seco_addr = 0;
+		goto copy;
+	}
+
+	/* Select the shared memory to be used for this buffer. */
+	if (io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) {
+		/* App requires to use secure memory for this buffer.*/
+		shared_mem = &dev_ctx->secure_mem;
+	} else {
+		/* No specific requirement for this buffer. */
+		shared_mem = &dev_ctx->non_secure_mem;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (io.length >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough space in shared memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+	shared_mem->pos += round_up(io.length, 8u);
+	io.seco_addr = (u64)shared_mem->dma_addr + pos;
+
+	if ((io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) &&
+	    !(io.flags & SECO_MU_IO_FLAGS_USE_SHORT_ADDR))
+		/*Add base address to get full address.*/
+		io.seco_addr += SECURE_RAM_BASE_ADDRESS_SCU;
+
+	if (io.flags & SECO_MU_IO_FLAGS_IS_INPUT) {
+		/*
+		 * buffer is input:
+		 * copy data from user space to this allocated buffer.
+		 */
+		err = (int)copy_from_user(shared_mem->ptr + pos, io.user_buf,
+					  io.length);
+		if (err) {
+			devctx_err(dev_ctx,
+				   "Failed copy data to shared memory\n");
+			err = -EFAULT;
+			goto exit;
+		}
+	} else {
+		/*
+		 * buffer is output:
+		 * add an entry in the "pending buffers" list so data
+		 * can be copied to user space when receiving SECO
+		 * response.
+		 */
+		out_buf_desc = devm_kmalloc(dev_ctx->dev, sizeof(*out_buf_desc),
+					    GFP_KERNEL);
+		if (!out_buf_desc) {
+			err = -ENOMEM;
+			devctx_err(dev_ctx,
+				   "Failed allocating mem for pending buffer\n"
+				   );
+			goto exit;
+		}
+
+		out_buf_desc->out_ptr = shared_mem->ptr + pos;
+		out_buf_desc->out_usr_ptr = io.user_buf;
+		out_buf_desc->out_size = io.length;
+		list_add_tail(&out_buf_desc->link, &dev_ctx->pending_out);
+	}
+
+copy:
+	/* Provide the seco address to user space only if success. */
+	err = (int)copy_to_user((u8 *)arg, &io,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy iobuff setup to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/* Retrieve info about the MU */
+static int seco_mu_ioctl_get_mu_info_handler(struct seco_mu_device_ctx *dev_ctx,
+					     unsigned long arg)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct seco_mu_ioctl_get_mu_info info;
+	int err = -EINVAL;
+
+	info.seco_mu_idx = (u8)priv->seco_mu_id;
+	info.interrupt_idx = SECO_MU_INTERRUPT_INDEX;
+	info.tz = SECO_DEFAULT_TZ;
+
+	err = imx_sc_rm_get_did(priv->ipc_scu, &info.did);
+	if (err) {
+		devctx_err(dev_ctx, "Get did failed\n");
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx,
+		   "info [mu_idx: %d, irq_idx: %d, tz: 0x%x, did: 0x%x]\n",
+		   info.seco_mu_idx, info.interrupt_idx, info.tz, info.did);
+
+	err = (int)copy_to_user((u8 *)arg, &info,
+		sizeof(info));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy mu info to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+static int seco_mu_ioctl_signed_msg_handler(struct seco_mu_device_ctx *dev_ctx,
+					    unsigned long arg)
+{
+	struct seco_shared_mem *shared_mem = &dev_ctx->non_secure_mem;
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct seco_mu_ioctl_signed_message msg;
+	int err = -EINVAL;
+	u64 addr;
+	u32 pos;
+
+	err = (int)copy_from_user(&msg,
+		(u8 *)arg,
+		sizeof(msg));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy from user: %d\n", err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (msg.msg_size >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough mem: %d left, %d required\n",
+			   shared_mem->size - shared_mem->pos, msg.msg_size);
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+
+	/* get physical address from the pos */
+	addr = (u64)shared_mem->dma_addr + pos;
+
+	/* copy signed message from user space to this allocated buffer */
+	err = (int)copy_from_user(shared_mem->ptr + pos, msg.message,
+				  msg.msg_size);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to signed message from user: %d\n",
+			   err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+	/* Send the message to SECO through SCU */
+	msg.error_code = imx_sc_seco_sab_msg(priv->ipc_scu, addr);
+
+	err = (int)copy_to_user((u8 *)arg, &msg,
+		sizeof(msg));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user: %d\n", err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/* IOCTL entry point of a char device */
+static long seco_mu_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	int err = -EINVAL;
+
+	/* Prevent race during change of device context */
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	switch (cmd) {
+	case SECO_MU_IOCTL_ENABLE_CMD_RCV:
+		if (!mu_priv->cmd_receiver_dev) {
+			devctx_dbg(dev_ctx, "setting as receiver\n");
+			mu_priv->cmd_receiver_dev = dev_ctx;
+			err = 0;
+		};
+		break;
+	case SECO_MU_IOCTL_SHARED_BUF_CFG:
+		err = seco_mu_ioctl_shared_mem_cfg_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_SETUP_IOBUF:
+		err = seco_mu_ioctl_setup_iobuf_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_GET_MU_INFO:
+		err = seco_mu_ioctl_get_mu_info_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_SIGNED_MESSAGE:
+		err = seco_mu_ioctl_signed_msg_handler(dev_ctx, arg);
+		break;
+	default:
+		err = -EINVAL;
+		devctx_dbg(dev_ctx, "IOCTL %.8x not supported\n", cmd);
+	}
+
+	up(&dev_ctx->fops_lock);
+	return (long)err;
+}
+
+/*
+ * Callback called by mailbox FW when data are received
+ */
+static void seco_mu_rx_callback(struct mbox_client *c, void *msg)
+{
+	struct device *dev = c->dev;
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	struct seco_mu_device_ctx *dev_ctx;
+	bool is_response = false;
+	int msg_size;
+	u32 header;
+
+	dev_dbg(dev, "Message received on mailbox\n");
+
+	/* The function can be called with NULL msg */
+	if (!msg) {
+		dev_err(dev, "Message is invalid\n");
+		return;
+	}
+
+	if (IS_ERR(msg)) {
+		dev_err(dev, "Error during reception of message: %ld\n",
+			PTR_ERR(msg));
+		return;
+	}
+
+	header = *(u32 *)msg;
+
+	dev_dbg(dev, "Selecting device\n");
+
+	/* Incoming command: wake up the receiver if any. */
+	if (MESSAGE_TAG(header) == priv->cmd_tag) {
+		dev_dbg(dev, "Selecting cmd receiver\n");
+		dev_ctx = priv->cmd_receiver_dev;
+	} else if (MESSAGE_TAG(header) == priv->rsp_tag) {
+		dev_dbg(dev, "Selecting rsp waiter\n");
+		dev_ctx = priv->waiting_rsp_dev;
+		is_response = true;
+	} else {
+		dev_err(dev, "Failed to select a device for message: %.8x\n",
+			header);
+		return;
+	}
+
+	if (!dev_ctx) {
+		dev_err(dev, "No device context selected for message: %.8x\n",
+			header);
+		return;
+	}
+
+	/* Init reception */
+	msg_size = MESSAGE_SIZE(header);
+	if (msg_size > MAX_RECV_SIZE) {
+		devctx_err(dev_ctx, "Message is too big (%d > %d)", msg_size,
+			   MAX_RECV_SIZE);
+		return;
+	}
+
+	memcpy(dev_ctx->temp_resp, msg, msg_size * sizeof(u32));
+	dev_ctx->temp_resp_size = msg_size;
+
+	/* Allow user to read */
+	dev_ctx->pending_hdr = dev_ctx->temp_resp[0];
+	wake_up_interruptible(&dev_ctx->wq);
+
+	if (is_response) {
+		/* Allow user to send new command */
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+}
+
+#define SECO_FW_VER_FEAT_MASK		(0x0000FFF0u)
+#define SECO_FW_VER_FEAT_SHIFT		(0x04u)
+#define SECO_FW_VER_FEAT_MIN_ALL_MU	(0x04u)
+
+/*
+ * Get SECO FW version and check if it supports receiving commands on all MUs
+ * The version is retrieved through SCU since this is the only communication
+ * channel to SECO always present.
+ */
+static int seco_mu_check_all_mu_supported(struct device *dev)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	u32 seco_ver;
+	int ret;
+
+	ret = imx_sc_seco_build_info(priv->ipc_scu, &seco_ver, NULL);
+	if (ret) {
+		dev_err(dev, "failed to retrieve SECO build info\n");
+		goto exit;
+	}
+
+	if (((seco_ver & SECO_FW_VER_FEAT_MASK) >> SECO_FW_VER_FEAT_SHIFT)
+		< SECO_FW_VER_FEAT_MIN_ALL_MU) {
+		dev_err(dev, "current SECO FW do not support MU with Linux\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+/* Char driver setup */
+static const struct file_operations seco_mu_fops = {
+	.open		= seco_mu_fops_open,
+	.owner		= THIS_MODULE,
+	.read		= seco_mu_fops_read,
+	.release	= seco_mu_fops_close,
+	.write		= seco_mu_fops_write,
+	.unlocked_ioctl = seco_mu_ioctl,
+};
+
+/* interface for managed res to free a mailbox channel */
+static void if_mbox_free_channel(void *mbox_chan)
+{
+	mbox_free_channel(mbox_chan);
+}
+
+/* interface for managed res to unregister a char device */
+static void if_misc_deregister(void *miscdevice)
+{
+	misc_deregister(miscdevice);
+}
+
+static int seco_mu_request_channel(struct device *dev,
+				   struct mbox_chan **chan,
+				   const char *name)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	struct mbox_chan *t_chan;
+	int ret = 0;
+
+	t_chan = mbox_request_channel_byname(&priv->cl, name);
+	if (IS_ERR(t_chan)) {
+		ret = PTR_ERR(t_chan);
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev,
+				"Failed to request chan %s ret %d\n", name,
+				ret);
+		goto exit;
+	}
+
+	ret = devm_add_action(dev, if_mbox_free_channel, t_chan);
+	if (ret) {
+		dev_err(dev, "failed to add devm removal of mbox %s\n", name);
+		goto exit;
+	}
+
+	*chan = t_chan;
+
+exit:
+	return ret;
+}
+
+static int imx_sc_v2x_reset_notify(struct notifier_block *nb,
+                                      unsigned long event, void *group)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(nb,
+					struct seco_mu_device_ctx, scu_notify);
+
+	if (!(event & SC_IRQ_V2X_RESET))
+		return 0;
+
+	dev_ctx->v2x_reset = true;
+
+	wake_up_interruptible(&dev_ctx->wq);
+	return 0;
+}
+/* Driver probe.*/
+static int seco_mu_probe(struct platform_device *pdev)
+{
+	struct seco_mu_device_ctx *dev_ctx;
+	struct device *dev = &pdev->dev;
+	struct seco_mu_priv *priv;
+	struct device_node *np;
+	int max_nb_users = 0;
+	char *devname;
+	int ret;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv) {
+		ret = -ENOMEM;
+		dev_err(dev, "Fail allocate mem for private data\n");
+		goto exit;
+	}
+	priv->dev = dev;
+	dev_set_drvdata(dev, priv);
+
+	/*
+	 * Get the address of MU to be used for communication with the SCU
+	 */
+	np = pdev->dev.of_node;
+	if (!np) {
+		dev_err(dev, "Cannot find MU User entry in device tree\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+	ret = imx_scu_get_handle(&priv->ipc_scu);
+	if (ret) {
+		dev_err(dev, "Fail to retrieve IPC handle\n");
+		goto exit;
+	}
+
+	ret = imx_sc_rm_get_resource_owner(priv->ipc_scu, IMX_SC_R_SECO,
+					   &priv->seco_part_owner);
+	if (ret) {
+		dev_err(dev, "Fail get owner of SECO resource\n");
+		goto exit;
+	}
+
+	ret = seco_mu_check_all_mu_supported(dev);
+	if (ret) {
+		dev_err(dev, "Fail seco_mu_check_all_mu_supported\n");
+		goto exit;
+	}
+
+	/* Initialize the mutex. */
+	mutex_init(&priv->mu_cmd_lock);
+	mutex_init(&priv->mu_lock);
+
+	priv->cmd_receiver_dev = NULL;
+	priv->waiting_rsp_dev = NULL;
+
+	ret = of_property_read_u32(np, "fsl,seco_mu_id", &priv->seco_mu_id);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_id", __func__);
+		priv->seco_mu_id = SECO_DEFAULT_MU_INDEX;
+	}
+
+	ret = of_property_read_u32(np, "fsl,seco_max_users", &max_nb_users);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_max_user", __func__);
+		max_nb_users = SECO_MU_DEFAULT_MAX_USERS;
+	}
+
+	ret = of_property_read_u8(np, "fsl,cmd_tag", &priv->cmd_tag);
+	if (ret)
+		priv->cmd_tag = DEFAULT_MESSAGING_TAG_COMMAND;
+
+	ret = of_property_read_u8(np, "fsl,rsp_tag", &priv->rsp_tag);
+	if (ret)
+		priv->rsp_tag = DEFAULT_MESSAGING_TAG_RESPONSE;
+
+	/* Mailbox client configuration */
+	priv->cl.dev = dev;
+	priv->cl.knows_txdone = true;
+	priv->cl.rx_callback = seco_mu_rx_callback;
+
+	ret = seco_mu_request_channel(dev, &priv->tx_chan, "txdb");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request txdb channel\n");
+
+		goto exit;
+	}
+
+	ret = seco_mu_request_channel(dev, &priv->rx_chan, "rxdb");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request rxdb channel\n");
+
+		goto exit;
+	}
+
+	/* Create users */
+	for (i = 0; i < max_nb_users; i++) {
+		dev_ctx = devm_kzalloc(dev, sizeof(*dev_ctx), GFP_KERNEL);
+		if (!dev_ctx) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for device context\n");
+			goto exit;
+		}
+
+		dev_ctx->dev = dev;
+		dev_ctx->status = MU_FREE;
+		dev_ctx->mu_priv = priv;
+		/* Default value invalid for an header. */
+		init_waitqueue_head(&dev_ctx->wq);
+
+		INIT_LIST_HEAD(&dev_ctx->pending_out);
+		sema_init(&dev_ctx->fops_lock, 1);
+
+		devname = devm_kasprintf(dev, GFP_KERNEL, "seco_mu%d_ch%d",
+					 priv->seco_mu_id, i);
+		if (!devname) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for misc dev name\n");
+			goto exit;
+		}
+
+		dev_ctx->miscdev.name = devname;
+		dev_ctx->miscdev.minor	= MISC_DYNAMIC_MINOR;
+		dev_ctx->miscdev.fops = &seco_mu_fops;
+		dev_ctx->miscdev.parent = dev;
+		ret = misc_register(&dev_ctx->miscdev);
+		if (ret) {
+			dev_err(dev, "failed to register misc device %d\n",
+				ret);
+			goto exit;
+		}
+
+		ret = devm_add_action(dev, if_misc_deregister,
+				      &dev_ctx->miscdev);
+
+		dev_ctx->scu_notify.notifier_call = imx_sc_v2x_reset_notify;
+
+		ret = imx_scu_irq_register_notifier(&dev_ctx->scu_notify);
+		if (ret) {
+			dev_err(&pdev->dev, "v2x reqister scu notifier failed.\n");
+			return ret;
+		}
+
+		if (ret)
+			dev_warn(dev,
+				 "failed to add managed removal of miscdev\n");
+	}
+
+	ret = imx_scu_irq_group_enable(IMX_SC_IRQ_GROUP_WAKE,
+					SC_IRQ_V2X_RESET, true);
+	if (ret) {
+		dev_warn(&pdev->dev, "v2x Enable irq failed.\n");
+		return ret;
+	}
+
+exit:
+	return ret;
+}
+
+static const struct of_device_id seco_mu_match[] = {
+	{
+		.compatible = "fsl,imx-seco-mu",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, seco_mu_match);
+
+static struct platform_driver seco_mu_driver = {
+	.driver = {
+		.name = "seco_mu",
+		.of_match_table = seco_mu_match,
+	},
+	.probe       = seco_mu_probe,
+};
+
+module_platform_driver(seco_mu_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("IMX Seco MU");
+MODULE_AUTHOR("NXP");
diff --git a/drivers/firmware/imx/sentnl_base_msg.c b/drivers/firmware/imx/sentnl_base_msg.c
new file mode 100644
index 000000000000..6a10336859a2
--- /dev/null
+++ b/drivers/firmware/imx/sentnl_base_msg.c
@@ -0,0 +1,141 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Pankaj <pankaj.gupta@nxp.com>
+	   Alice Guo <alice.guo@nxp.com>
+ */
+
+#include <linux/types.h>
+#include <linux/completion.h>
+#include <linux/mailbox_client.h>
+
+#include <linux/firmware/imx/sentnl_base_msg.h>
+#include <linux/firmware/imx/sentnl_mu_ioctl.h>
+
+#include "sentnl_mu.h"
+
+/* Fill a command message header with a given command ID and length in bytes. */
+static int plat_fill_cmd_msg_hdr(struct mu_hdr *hdr, uint8_t cmd, uint32_t len)
+{
+	struct sentnl_mu_priv *priv = NULL;
+	int err = 0;
+
+	err = get_sentnl_mu_priv(&priv);
+	if (err) {
+		pr_err("Error: iMX Sentinel MU is not probed successfully.\n");
+		return err;
+	}
+	hdr->tag = priv->cmd_tag;
+	hdr->ver = MESSAGING_VERSION_6;
+	hdr->command = cmd;
+	hdr->size = (uint8_t)(len / sizeof(uint32_t));
+
+	return err;
+}
+
+static int imx_sentnl_msg_send_rcv(struct sentnl_mu_priv *priv)
+{
+	unsigned int wait;
+	int err = 0;
+
+	mutex_lock(&priv->mu_cmd_lock);
+	mutex_lock(&priv->mu_lock);
+
+	err = mbox_send_message(priv->tx_chan, &priv->tx_msg);
+	if (err < 0) {
+		pr_err("Error: mbox_send_message failure.\n");
+		mutex_unlock(&priv->mu_lock);
+		return err;
+	}
+	mutex_unlock(&priv->mu_lock);
+
+	wait = msecs_to_jiffies(1000);
+	if (!wait_for_completion_timeout(&priv->done, wait)) {
+		mutex_unlock(&priv->mu_cmd_lock);
+		pr_err("Error: wait_for_completion timed out.\n");
+		return -ETIMEDOUT;
+	}
+
+	/* As part of func sentnl_mu_rx_callback() execution,
+	 * response will copied to sentnl_msg->rsp_msg.
+	 *
+	 * Lock: (mutex_unlock(&sentnl_mu_priv->mu_cmd_lock),
+	 * will be unlocked if it is a response.
+	 */
+	return err;
+}
+
+static int read_otp_uniq_id(struct sentnl_mu_priv *priv, u32 *value)
+{
+	unsigned int tag, command, size, ver, status;
+
+	tag = MSG_TAG(priv->rx_msg.header);
+	command = MSG_COMMAND(priv->rx_msg.header);
+	size = MSG_SIZE(priv->rx_msg.header);
+	ver = MSG_VER(priv->rx_msg.header);
+	status = RES_STATUS(priv->rx_msg.data[0]);
+
+	if (tag == 0xe1 && command == SENTNL_READ_FUSE_REQ &&
+	    size == 0x07 && ver == SENTNL_VERSION && status == SENTNL_SUCCESS_IND) {
+		value[0] = priv->rx_msg.data[1];
+		value[1] = priv->rx_msg.data[2];
+		value[2] = priv->rx_msg.data[3];
+		value[3] = priv->rx_msg.data[4];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int read_fuse_word(struct sentnl_mu_priv *priv, u32 *value)
+{
+	unsigned int tag, command, size, ver, status;
+
+	tag = MSG_TAG(priv->rx_msg.header);
+	command = MSG_COMMAND(priv->rx_msg.header);
+	size = MSG_SIZE(priv->rx_msg.header);
+	ver = MSG_VER(priv->rx_msg.header);
+	status = RES_STATUS(priv->rx_msg.data[0]);
+
+	if (tag == 0xe1 && command == SENTNL_READ_FUSE_REQ &&
+	    size == 0x03 && ver == 0x06 && status == SENTNL_SUCCESS_IND) {
+		value[0] = priv->rx_msg.data[1];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+int read_common_fuse(uint16_t fuse_id, u32 *value)
+{
+	struct sentnl_mu_priv *priv = NULL;
+	int err = 0;
+
+	err = get_sentnl_mu_priv(&priv);
+	if (err) {
+		pr_err("Error: iMX Sentinel MU is not probed successfully.\n");
+		return err;
+	}
+	err = plat_fill_cmd_msg_hdr((struct mu_hdr *)&priv->tx_msg.header, SENTNL_READ_FUSE_REQ, 8);
+	if (err) {
+		pr_err("Error: plat_fill_cmd_msg_hdr failed.\n");
+		return err;
+	}
+
+	priv->tx_msg.data[0] = fuse_id;
+	err = imx_sentnl_msg_send_rcv(priv);
+	if (err < 0)
+		return err;
+
+	switch (fuse_id) {
+	case OTP_UNIQ_ID:
+		err = read_otp_uniq_id(priv, value);
+		break;
+	default:
+		err = read_fuse_word(priv, value);
+		break;
+	}
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(read_common_fuse);
diff --git a/drivers/firmware/imx/sentnl_mu.c b/drivers/firmware/imx/sentnl_mu.c
new file mode 100644
index 000000000000..c96b2ab2bd0b
--- /dev/null
+++ b/drivers/firmware/imx/sentnl_mu.c
@@ -0,0 +1,919 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Alice Guo <alice.guo@nxp.com>
+ */
+
+#include <asm/cacheflush.h>
+
+#include <linux/dma-mapping.h>
+#include <linux/completion.h>
+#include <linux/dev_printk.h>
+#include <linux/errno.h>
+#include <linux/export.h>
+#include <linux/firmware/imx/sentnl_base_msg.h>
+#include <linux/firmware/imx/sentnl_mu_ioctl.h>
+#include <linux/io.h>
+#include <linux/init.h>
+#include <linux/mailbox_client.h>
+#include <linux/miscdevice.h>
+#include <linux/mod_devicetable.h>
+#include <linux/module.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/sys_soc.h>
+
+#include "sentnl_mu.h"
+
+struct sentnl_mu_priv *sentnl_priv_export;
+
+int get_sentnl_mu_priv(struct sentnl_mu_priv **export)
+{
+	if (!sentnl_priv_export)
+		return -EPROBE_DEFER;
+
+	*export = sentnl_priv_export;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(get_sentnl_mu_priv);
+
+
+/*
+ * Callback called by mailbox FW when data are received
+ */
+static void sentnl_mu_rx_callback(struct mbox_client *c, void *msg)
+{
+	struct device *dev = c->dev;
+	struct sentnl_mu_priv *priv = dev_get_drvdata(dev);
+	struct sentnl_mu_device_ctx *dev_ctx;
+	bool is_response = false;
+	int msg_size;
+	struct mu_hdr header;
+
+	dev_dbg(dev, "Message received on mailbox\n");
+
+	/* The function can be called with NULL msg */
+	if (!msg) {
+		dev_err(dev, "Message is invalid\n");
+		return;
+	}
+
+	if (IS_ERR(msg)) {
+		dev_err(dev, "Error during reception of message: %ld\n",
+				PTR_ERR(msg));
+		return;
+	}
+
+	header.tag = ((u8 *)msg)[3];
+	header.command = ((u8 *)msg)[2];
+	header.size = ((u8 *)msg)[1];
+	header.ver = ((u8 *)msg)[0];
+
+	dev_dbg(dev, "Selecting device\n");
+
+	/* Incoming command: wake up the receiver if any. */
+	if (header.tag == priv->cmd_tag) {
+		dev_dbg(dev, "Selecting cmd receiver\n");
+		dev_ctx = priv->cmd_receiver_dev;
+	} else if (header.tag == priv->rsp_tag) {
+		if (priv->waiting_rsp_dev) {
+			dev_dbg(dev, "Selecting rsp waiter\n");
+			dev_ctx = priv->waiting_rsp_dev;
+			is_response = true;
+		} else {
+			/* Reading the Sentinel response
+			 * to the command sent by other
+			 * linux kernel services.
+			 */
+			spin_lock(&priv->lock);
+			priv->rx_msg = *(struct sentnl_api_msg *)msg;
+			complete(&priv->done);
+			spin_unlock(&priv->lock);
+			mutex_unlock(&priv->mu_cmd_lock);
+			return;
+		}
+	} else {
+		dev_err(dev, "Failed to select a device for message: %.8x\n",
+				*((u32 *) &header));
+		return;
+	}
+
+	if (!dev_ctx) {
+		dev_err(dev, "No device context selected for message: %.8x\n",
+				*((u32 *)&header));
+		return;
+	}
+	/* Init reception */
+	msg_size = header.size;
+	if (msg_size > MAX_RECV_SIZE) {
+		devctx_err(dev_ctx, "Message is too big (%d > %d)", msg_size,
+				MAX_RECV_SIZE);
+		return;
+	}
+
+	memcpy(dev_ctx->temp_resp, msg, msg_size * sizeof(u32));
+	dev_ctx->temp_resp_size = msg_size;
+
+	/* Allow user to read */
+	dev_ctx->pending_hdr = dev_ctx->temp_resp[0];
+	wake_up_interruptible(&dev_ctx->wq);
+
+	if (is_response) {
+		/* Allow user to send new command */
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+}
+
+struct device *imx_soc_device_register(void)
+{
+	struct soc_device_attribute *attr;
+	struct soc_device *dev;
+	u32 v[4];
+	int err;
+
+	err = read_common_fuse(OTP_UNIQ_ID, v);
+	if (err)
+		return NULL;
+
+	attr = kzalloc(sizeof(*attr), GFP_KERNEL);
+	if (!attr)
+		return NULL;
+
+	err = of_property_read_string(of_root, "model", &attr->machine);
+	if (err) {
+		kfree(attr);
+		return NULL;
+	}
+	attr->family = kasprintf(GFP_KERNEL, "Freescale i.MX");
+	attr->revision = kasprintf(GFP_KERNEL, "1.0");
+	attr->serial_number = kasprintf(GFP_KERNEL, "%016llX", (u64)v[3] << 32 | v[0]);
+	attr->soc_id = kasprintf(GFP_KERNEL, "i.MX8ULP");
+
+	dev = soc_device_register(attr);
+	if (IS_ERR(dev)) {
+		kfree(attr->soc_id);
+		kfree(attr->serial_number);
+		kfree(attr->revision);
+		kfree(attr->family);
+		kfree(attr->machine);
+		kfree(attr);
+		return ERR_CAST(dev);
+	}
+
+	return soc_device_to_device(dev);
+}
+
+/*
+ * File operations for user-space
+ */
+
+/* Write a message to the MU. */
+static ssize_t sentnl_mu_fops_write(struct file *fp, const char __user *buf,
+				  size_t size, loff_t *ppos)
+{
+	struct sentnl_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					   struct sentnl_mu_device_ctx, miscdev);
+	struct sentnl_mu_priv *sentnl_mu_priv = dev_ctx->priv;
+	u32 nb_words = 0;
+	struct mu_hdr header;
+	int err;
+
+	devctx_dbg(dev_ctx, "write from buf (%p)%ld, ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (size < 4) {//sizeof(struct she_mu_hdr)) {
+		devctx_err(dev_ctx, "User buffer too small(%ld < %x)\n", size, 0x4);
+		//devctx_err(dev_ctx, "User buffer too small(%ld < %lu)\n", size, ()0x4);
+			  // sizeof(struct she_mu_hdr));
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	if (size > MAX_MESSAGE_SIZE_BYTES) {
+		devctx_err(dev_ctx, "User buffer too big(%ld > %lu)\n", size,
+			   MAX_MESSAGE_SIZE_BYTES);
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	/* Copy data to buffer */
+	err = (int)copy_from_user(dev_ctx->temp_cmd, buf, size);
+	if (err) {
+		err = -EFAULT;
+		devctx_err(dev_ctx, "Fail copy message from user\n");
+		goto exit;
+	}
+
+	print_hex_dump_debug("from user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_cmd, size, false);
+
+	header = *((struct mu_hdr *) (&dev_ctx->temp_cmd[0]));
+
+	/* Check the message is valid according to tags */
+	if (header.tag == sentnl_mu_priv->cmd_tag) {
+		/*
+		 * unlocked in sentnl_mu_receive_work_handler when the
+		 * response to this command is received.
+		 */
+		mutex_lock(&sentnl_mu_priv->mu_cmd_lock);
+		sentnl_mu_priv->waiting_rsp_dev = dev_ctx;
+	} else if (header.tag == sentnl_mu_priv->rsp_tag) {
+		/* Check the device context can send the command */
+		if (dev_ctx != sentnl_mu_priv->cmd_receiver_dev) {
+			devctx_err(dev_ctx,
+				   "This channel is not configured to send response to SECO\n");
+			err = -EPERM;
+			goto exit;
+		}
+	} else {
+		devctx_err(dev_ctx, "The message does not have a valid TAG\n");
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/*
+	 * Check that the size passed as argument matches the size
+	 * carried in the message.
+	 */
+	nb_words = header.size;
+	if (nb_words * sizeof(u32) != size) {
+		devctx_err(dev_ctx, "User buffer too small\n");
+		goto exit;
+	}
+
+	mutex_lock(&sentnl_mu_priv->mu_lock);
+
+	/* Send message */
+	devctx_dbg(dev_ctx, "sending message\n");
+	err = mbox_send_message(sentnl_mu_priv->tx_chan, dev_ctx->temp_cmd);
+	if (err < 0) {
+		devctx_err(dev_ctx, "Failed to send message\n");
+		goto unlock;
+	}
+
+	err = nb_words * (u32)sizeof(u32);
+
+unlock:
+	mutex_unlock(&sentnl_mu_priv->mu_lock);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/*
+ * Read a message from the MU.
+ * Blocking until a message is available.
+ */
+static ssize_t sentnl_mu_fops_read(struct file *fp, char __user *buf,
+				 size_t size, loff_t *ppos)
+{
+	struct sentnl_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					   struct sentnl_mu_device_ctx, miscdev);
+	u32 data_size = 0, size_to_copy = 0;
+	struct sentnl_obuf_desc *b_desc;
+	int err;
+
+	devctx_dbg(dev_ctx, "read to buf %p(%ld), ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/* Wait until the complete message is received on the MU. */
+	err = wait_event_interruptible(dev_ctx->wq, dev_ctx->pending_hdr != 0);
+	if (err) {
+		devctx_err(dev_ctx, "Interrupted by signal\n");
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "%s %s\n", __func__,
+		   "message received, start transmit to user");
+
+	/* Check that the size passed as argument is larger than
+	 * the one carried in the message.
+	 */
+	data_size = dev_ctx->temp_resp_size * sizeof(u32);
+	size_to_copy = data_size;
+	if (size_to_copy > size) {
+		devctx_dbg(dev_ctx, "User buffer too small (%ld < %d)\n",
+			   size, size_to_copy);
+		size_to_copy = size;
+	}
+
+	/* We may need to copy the output data to user before
+	 * delivering the completion message.
+	 */
+	while (!list_empty(&dev_ctx->pending_out)) {
+		b_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						  struct sentnl_obuf_desc,
+						  link);
+		if (b_desc->out_usr_ptr && b_desc->out_ptr) {
+			devctx_dbg(dev_ctx, "Copy output data to user\n");
+			err = (int)copy_to_user(b_desc->out_usr_ptr,
+						b_desc->out_ptr,
+						b_desc->out_size);
+			if (err) {
+				devctx_err(dev_ctx,
+					   "Failed to copy output data to user\n");
+				err = -EFAULT;
+				goto exit;
+			}
+		}
+		__list_del_entry(&b_desc->link);
+		devm_kfree(dev_ctx->dev, b_desc);
+	}
+
+	/* Copy data from the buffer */
+	print_hex_dump_debug("to user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_resp, size_to_copy, false);
+	err = (int)copy_to_user(buf, dev_ctx->temp_resp, size_to_copy);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	err = size_to_copy;
+
+	/* free memory allocated on the shared buffers. */
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	dev_ctx->pending_hdr = 0;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Give access to Sentinel, to the memory we want to share */
+static int sentnl_mu_setup_sentnl_mem_access(struct sentnl_mu_device_ctx *dev_ctx,
+					     u64 addr, u32 len)
+{
+	/* Assuming Sentinel has access to all the memory regions */
+	int ret = 0;
+
+	if (ret) {
+		devctx_err(dev_ctx, "Fail find memreg\n");
+		goto exit;
+	}
+
+	if (ret) {
+		devctx_err(dev_ctx, "Fail set permission for resource\n");
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+static int sentnl_mu_ioctl_get_mu_info(struct sentnl_mu_device_ctx *dev_ctx,
+				  unsigned long arg)
+{
+	struct sentnl_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct sentnl_mu_ioctl_get_mu_info info;
+	int err = -EINVAL;
+
+	info.sentnl_mu_id = (u8)priv->sentnl_mu_id;
+	info.interrupt_idx = 0;
+	info.tz = 0;
+	info.did = 0x7;
+
+	devctx_dbg(dev_ctx,
+		   "info [mu_idx: %d, irq_idx: %d, tz: 0x%x, did: 0x%x]\n",
+		   info.sentnl_mu_id, info.interrupt_idx, info.tz, info.did);
+
+	err = (int)copy_to_user((u8 *)arg, &info,
+		sizeof(info));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy mu info to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/*
+ * Copy a buffer of daa to/from the user and return the address to use in
+ * messages
+ */
+static int sentnl_mu_ioctl_setup_iobuf_handler(struct sentnl_mu_device_ctx *dev_ctx,
+					       unsigned long arg)
+{
+	struct sentnl_obuf_desc *out_buf_desc;
+	struct sentnl_mu_ioctl_setup_iobuf io = {0};
+	struct sentnl_shared_mem *shared_mem;
+	int err = -EINVAL;
+	u32 pos;
+
+	err = (int)copy_from_user(&io,
+		(u8 *)arg,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed copy iobuf config from user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "io [buf: %p(%d) flag: %x]\n",
+		   io.user_buf, io.length, io.flags);
+
+	if (io.length == 0 || !io.user_buf) {
+		/*
+		 * Accept NULL pointers since some buffers are optional
+		 * in SECO commands. In this case we should return 0 as
+		 * pointer to be embedded into the message.
+		 * Skip all data copy part of code below.
+		 */
+		io.sentnl_addr = 0;
+		goto copy;
+	}
+
+	/* Select the shared memory to be used for this buffer. */
+	if (io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) {
+		/* App requires to use secure memory for this buffer.*/
+		devctx_err(dev_ctx, "Failed allocate SEC MEM memory\n");
+		err = -EFAULT;
+		goto exit;
+	} else {
+		/* No specific requirement for this buffer. */
+		shared_mem = &dev_ctx->non_secure_mem;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (io.length >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough space in shared memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+	shared_mem->pos += round_up(io.length, 8u);
+	io.sentnl_addr = (u64)shared_mem->dma_addr + pos;
+
+	if ((io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) &&
+	    !(io.flags & SECO_MU_IO_FLAGS_USE_SHORT_ADDR)) {
+		/*Add base address to get full address.*/
+		devctx_err(dev_ctx, "Failed allocate SEC MEM memory\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	if (io.flags & SECO_MU_IO_FLAGS_IS_INPUT) {
+		/*
+		 * buffer is input:
+		 * copy data from user space to this allocated buffer.
+		 */
+		err = (int)copy_from_user(shared_mem->ptr + pos, io.user_buf,
+					  io.length);
+		if (err) {
+			devctx_err(dev_ctx,
+				   "Failed copy data to shared memory\n");
+			err = -EFAULT;
+			goto exit;
+		}
+	} else {
+		/*
+		 * buffer is output:
+		 * add an entry in the "pending buffers" list so data
+		 * can be copied to user space when receiving SECO
+		 * response.
+		 */
+		out_buf_desc = devm_kmalloc(dev_ctx->dev, sizeof(*out_buf_desc),
+					    GFP_KERNEL);
+		if (!out_buf_desc) {
+			err = -ENOMEM;
+			devctx_err(dev_ctx,
+				   "Failed allocating mem for pending buffer\n"
+				   );
+			goto exit;
+		}
+
+		out_buf_desc->out_ptr = shared_mem->ptr + pos;
+		out_buf_desc->out_usr_ptr = io.user_buf;
+		out_buf_desc->out_size = io.length;
+		list_add_tail(&out_buf_desc->link, &dev_ctx->pending_out);
+	}
+
+copy:
+	/* Provide the sentinel address to user space only if success. */
+	err = (int)copy_to_user((u8 *)arg, &io,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy iobuff setup to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+exit:
+	return err;
+}
+
+
+
+/* Open a char device. */
+static int sentnl_mu_fops_open(struct inode *nd, struct file *fp)
+{
+	struct sentnl_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+							    struct sentnl_mu_device_ctx,
+							    miscdev);
+	int err;
+
+	/* Avoid race if opened at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* Authorize only 1 instance. */
+	if (dev_ctx->status != MU_FREE) {
+		err = -EBUSY;
+		goto exit;
+	}
+
+	/*
+	 * Allocate some memory for data exchanges with S40x.
+	 * This will be used for data not requiring secure memory.
+	 */
+	dev_ctx->non_secure_mem.ptr = dmam_alloc_coherent(dev_ctx->dev,
+					MAX_DATA_SIZE_PER_USER,
+					&dev_ctx->non_secure_mem.dma_addr,
+					GFP_KERNEL);
+	if (!dev_ctx->non_secure_mem.ptr) {
+		err = -ENOMEM;
+		devctx_err(dev_ctx, "Failed to map shared memory with S40x\n");
+		goto exit;
+	}
+
+	err = sentnl_mu_setup_sentnl_mem_access(dev_ctx,
+						dev_ctx->non_secure_mem.dma_addr,
+						MAX_DATA_SIZE_PER_USER);
+	if (err) {
+		err = -EPERM;
+		devctx_err(dev_ctx,
+			   "Failed to share access to shared memory\n");
+		goto free_coherent;
+	}
+
+	dev_ctx->non_secure_mem.size = MAX_DATA_SIZE_PER_USER;
+	dev_ctx->non_secure_mem.pos = 0;
+	dev_ctx->status = MU_OPENED;
+
+	dev_ctx->pending_hdr = 0;
+
+	goto exit;
+
+free_coherent:
+	dmam_free_coherent(dev_ctx->priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Close a char device. */
+static int sentnl_mu_fops_close(struct inode *nd, struct file *fp)
+{
+	struct sentnl_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct sentnl_mu_device_ctx, miscdev);
+	struct sentnl_mu_priv *priv = dev_ctx->priv;
+	struct sentnl_obuf_desc *out_buf_desc;
+
+	/* Avoid race if closed at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* The device context has not been opened */
+	if (dev_ctx->status != MU_OPENED)
+		goto exit;
+
+	/* check if this device was registered as command receiver. */
+	if (priv->cmd_receiver_dev == dev_ctx)
+		priv->cmd_receiver_dev = NULL;
+
+	/* check if this device was registered as waiting response. */
+	if (priv->waiting_rsp_dev == dev_ctx) {
+		priv->waiting_rsp_dev = NULL;
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+
+	/* Unmap secure memory shared buffer. */
+	if (dev_ctx->secure_mem.ptr)
+		devm_iounmap(dev_ctx->dev, dev_ctx->secure_mem.ptr);
+
+	dev_ctx->secure_mem.ptr = NULL;
+	dev_ctx->secure_mem.dma_addr = 0;
+	dev_ctx->secure_mem.size = 0;
+	dev_ctx->secure_mem.pos = 0;
+
+	/* Free non-secure shared buffer. */
+	dmam_free_coherent(dev_ctx->priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+	dev_ctx->non_secure_mem.ptr = NULL;
+	dev_ctx->non_secure_mem.dma_addr = 0;
+	dev_ctx->non_secure_mem.size = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	while (!list_empty(&dev_ctx->pending_out)) {
+		out_buf_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						struct sentnl_obuf_desc,
+						link);
+		__list_del_entry(&out_buf_desc->link);
+		devm_kfree(dev_ctx->dev, out_buf_desc);
+	}
+
+	dev_ctx->status = MU_FREE;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return 0;
+}
+
+/* IOCTL entry point of a char device */
+static long sentnl_mu_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
+{
+	struct sentnl_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+							    struct sentnl_mu_device_ctx,
+							    miscdev);
+	struct sentnl_mu_priv *sentnl_mu_priv = dev_ctx->priv;
+	int err = -EINVAL;
+
+	/* Prevent race during change of device context */
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	switch (cmd) {
+	case SENTNL_MU_IOCTL_ENABLE_CMD_RCV:
+		if (!sentnl_mu_priv->cmd_receiver_dev) {
+			sentnl_mu_priv->cmd_receiver_dev = dev_ctx;
+			err = 0;
+		};
+		break;
+	case SENTNL_MU_IOCTL_GET_MU_INFO:
+		err = sentnl_mu_ioctl_get_mu_info(dev_ctx, arg);
+		break;
+	case SENTNL_MU_IOCTL_SHARED_BUF_CFG:
+		devctx_err(dev_ctx, "SENTNL_MU_IOCTL_SHARED_BUF_CFG not supported [0x%x].\n", err);
+		break;
+	case SENTNL_MU_IOCTL_SETUP_IOBUF:
+		err = sentnl_mu_ioctl_setup_iobuf_handler(dev_ctx, arg);
+		break;
+	case SENTNL_MU_IOCTL_SIGNED_MESSAGE:
+		devctx_err(dev_ctx, "SENTNL_MU_IOCTL_SIGNED_MESSAGE not supported [0x%x].\n", err);
+		break;
+	default:
+		err = -EINVAL;
+		devctx_dbg(dev_ctx, "IOCTL %.8x not supported\n", cmd);
+	}
+
+	up(&dev_ctx->fops_lock);
+	return (long)err;
+}
+
+/* Char driver setup */
+static const struct file_operations sentnl_mu_fops = {
+	.open		= sentnl_mu_fops_open,
+	.owner		= THIS_MODULE,
+	.release	= sentnl_mu_fops_close,
+	.unlocked_ioctl = sentnl_mu_ioctl,
+	.read		= sentnl_mu_fops_read,
+	.write		= sentnl_mu_fops_write,
+};
+
+/* interface for managed res to free a mailbox channel */
+static void if_mbox_free_channel(void *mbox_chan)
+{
+	mbox_free_channel(mbox_chan);
+}
+
+/* interface for managed res to unregister a char device */
+static void if_misc_deregister(void *miscdevice)
+{
+	misc_deregister(miscdevice);
+}
+
+static int sentnl_mu_request_channel(struct device *dev,
+				 struct mbox_chan **chan,
+				 struct mbox_client *cl,
+				 const char *name)
+{
+	struct mbox_chan *t_chan;
+	int ret = 0;
+
+	t_chan = mbox_request_channel_byname(cl, name);
+	if (IS_ERR(t_chan)) {
+		ret = PTR_ERR(t_chan);
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev,
+				"Failed to request chan %s ret %d\n", name,
+				ret);
+		goto exit;
+	}
+
+	ret = devm_add_action(dev, if_mbox_free_channel, t_chan);
+	if (ret) {
+		dev_err(dev, "failed to add devm removal of mbox %s\n", name);
+		goto exit;
+	}
+
+	*chan = t_chan;
+
+exit:
+	return ret;
+}
+
+static int sentnl_mu_probe(struct platform_device *pdev)
+{
+	struct sentnl_mu_device_ctx *dev_ctx;
+	struct device *dev = &pdev->dev;
+	struct sentnl_mu_priv *priv;
+	struct device_node *np;
+	int max_nb_users = 0;
+	char *devname;
+	struct device *soc;
+	int ret;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv) {
+		ret = -ENOMEM;
+		dev_err(dev, "Fail allocate mem for private data\n");
+		goto exit;
+	}
+	priv->dev = dev;
+	dev_set_drvdata(dev, priv);
+
+	/*
+	 * Get the address of MU to be used for communication with the SCU
+	 */
+	np = pdev->dev.of_node;
+	if (!np) {
+		dev_err(dev, "Cannot find MU User entry in device tree\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+	/* Initialize the mutex. */
+	mutex_init(&priv->mu_cmd_lock);
+	mutex_init(&priv->mu_lock);
+
+	/* TBD */
+	priv->cmd_receiver_dev = NULL;
+	priv->waiting_rsp_dev = NULL;
+
+	ret = of_property_read_u32(np, "fsl,sentnl_mu_id", &priv->sentnl_mu_id);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_id", __func__);
+		priv->sentnl_mu_id = S4_DEFAULT_MUAP_INDEX;
+	}
+
+	ret = of_property_read_u32(np, "fsl,sentnl_mu_max_users", &max_nb_users);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_max_user", __func__);
+		max_nb_users = S4_MUAP_DEFAULT_MAX_USERS;
+	}
+
+	ret = of_property_read_u8(np, "fsl,cmd_tag", &priv->cmd_tag);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read cmd_tag", __func__);
+		priv->cmd_tag = DEFAULT_MESSAGING_TAG_COMMAND;
+	}
+
+	ret = of_property_read_u8(np, "fsl,rsp_tag", &priv->rsp_tag);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read rsp_tag", __func__);
+		priv->rsp_tag = DEFAULT_MESSAGING_TAG_RESPONSE;
+	}
+
+	/* Mailbox client configuration */
+	priv->sentnl_mb_cl.dev		= dev;
+	priv->sentnl_mb_cl.tx_block	= false;
+	priv->sentnl_mb_cl.knows_txdone	= true;
+	priv->sentnl_mb_cl.rx_callback	= sentnl_mu_rx_callback;
+
+	ret = sentnl_mu_request_channel(dev, &priv->tx_chan, &priv->sentnl_mb_cl, "tx");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request tx channel\n");
+
+		goto exit;
+	}
+
+	ret = sentnl_mu_request_channel(dev, &priv->rx_chan, &priv->sentnl_mb_cl, "rx");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request rx channel\n");
+
+		goto exit;
+	}
+
+	/* Create users */
+	for (i = 0; i < max_nb_users; i++) {
+		dev_ctx = devm_kzalloc(dev, sizeof(*dev_ctx), GFP_KERNEL);
+		if (!dev_ctx) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for device context\n");
+			goto exit;
+		}
+
+		dev_ctx->dev = dev;
+		dev_ctx->status = MU_FREE;
+		dev_ctx->priv = priv;
+		/* Default value invalid for an header. */
+		init_waitqueue_head(&dev_ctx->wq);
+
+		INIT_LIST_HEAD(&dev_ctx->pending_out);
+		sema_init(&dev_ctx->fops_lock, 1);
+
+		devname = devm_kasprintf(dev, GFP_KERNEL, "sentnl_mu%d_ch%d",
+					 priv->sentnl_mu_id, i);
+		if (!devname) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for misc dev name\n");
+			goto exit;
+		}
+
+		dev_ctx->miscdev.name = devname;
+		dev_ctx->miscdev.minor = MISC_DYNAMIC_MINOR;
+		dev_ctx->miscdev.fops = &sentnl_mu_fops;
+		dev_ctx->miscdev.parent = dev;
+		ret = misc_register(&dev_ctx->miscdev);
+		if (ret) {
+			dev_err(dev, "failed to register misc device %d\n",
+				ret);
+			goto exit;
+		}
+
+		ret = devm_add_action(dev, if_misc_deregister,
+				      &dev_ctx->miscdev);
+
+	}
+
+	init_completion(&priv->done);
+	spin_lock_init(&priv->lock);
+
+	sentnl_priv_export = priv;
+
+	soc = imx_soc_device_register();
+	if (IS_ERR(soc)) {
+		pr_err("failed to register SoC device: %ld\n", PTR_ERR(soc));
+		return PTR_ERR(soc);
+	}
+
+	dev_set_drvdata(dev, priv);
+	return devm_of_platform_populate(dev);
+
+exit:
+	return ret;
+}
+
+static int sentnl_mu_remove(struct platform_device *pdev)
+{
+	struct sentnl_mu_priv *priv;
+
+	priv = dev_get_drvdata(&pdev->dev);
+	mbox_free_channel(priv->tx_chan);
+	mbox_free_channel(priv->rx_chan);
+
+	return 0;
+}
+
+static const struct of_device_id sentnl_mu_match[] = {
+	{ .compatible = "fsl,imx-sentinel", },
+	{},
+};
+
+static struct platform_driver sentnl_mu_driver = {
+	.driver = {
+		.name = "fsl-sentinel-mu",
+		.of_match_table = sentnl_mu_match,
+	},
+	.probe = sentnl_mu_probe,
+	.remove = sentnl_mu_remove,
+};
+module_platform_driver(sentnl_mu_driver);
+
+MODULE_AUTHOR("Pankaj Gupta <pankaj.gupta@nxp.com>");
+MODULE_DESCRIPTION("Sentinel Baseline, HSM and SHE API(s)");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/firmware/imx/sentnl_mu.h b/drivers/firmware/imx/sentnl_mu.h
new file mode 100644
index 000000000000..3f5a4488effa
--- /dev/null
+++ b/drivers/firmware/imx/sentnl_mu.h
@@ -0,0 +1,139 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2021 NXP
+ */
+
+#ifndef SENTNL_MU_H
+#define SENTNL_MU_H
+
+#include <linux/miscdevice.h>
+#include <linux/semaphore.h>
+
+/* macro to log operation of a misc device */
+#define miscdev_dbg(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_dbg((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+#define miscdev_info(p_miscdev, fmt, va_args...)                               \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_info((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name, \
+		##va_args);                                                    \
+	})
+
+#define miscdev_err(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_err((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+/* macro to log operation of a device context */
+#define devctx_dbg(p_devctx, fmt, va_args...) \
+	miscdev_dbg(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_info(p_devctx, fmt, va_args...) \
+	miscdev_info(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_err(p_devctx, fmt, va_args...) \
+	miscdev_err((&(p_devctx)->miscdev), fmt, ##va_args)
+
+#define MSG_TAG(x)			(((x) & 0xff000000) >> 24)
+#define MSG_COMMAND(x)			(((x) & 0x00ff0000) >> 16)
+#define MSG_SIZE(x)			(((x) & 0x0000ff00) >> 8)
+#define MSG_VER(x)			((x) & 0x000000ff)
+#define RES_STATUS(x)			((x) & 0x000000ff)
+#define MAX_DATA_SIZE_PER_USER		(65 * 1024)
+#define S4_DEFAULT_MUAP_INDEX		(2)
+#define S4_MUAP_DEFAULT_MAX_USERS	(4)
+
+#define DEFAULT_MESSAGING_TAG_COMMAND           (0x17u)
+#define DEFAULT_MESSAGING_TAG_RESPONSE          (0xe1u)
+
+#define SECO_MU_IO_FLAGS_IS_INPUT	(0x01u)
+#define SECO_MU_IO_FLAGS_USE_SEC_MEM	(0x02u)
+#define SECO_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+struct sentnl_obuf_desc {
+	u8 *out_ptr;
+	u8 *out_usr_ptr;
+	u32 out_size;
+	struct list_head link;
+};
+
+/* Status of a char device */
+enum mu_device_status_t {
+	MU_FREE,
+	MU_OPENED
+};
+
+struct sentnl_shared_mem {
+	dma_addr_t dma_addr;
+	u32 size;
+	u32 pos;
+	u8 *ptr;
+};
+
+/* Private struct for each char device instance. */
+struct sentnl_mu_device_ctx {
+	struct device *dev;
+	struct sentnl_mu_priv *priv;
+	struct miscdevice miscdev;
+
+	enum mu_device_status_t status;
+	wait_queue_head_t wq;
+	struct semaphore fops_lock;
+
+	u32 pending_hdr;
+	struct list_head pending_out;
+
+	struct sentnl_shared_mem secure_mem;
+	struct sentnl_shared_mem non_secure_mem;
+
+	u32 temp_cmd[MAX_MESSAGE_SIZE];
+	u32 temp_resp[MAX_RECV_SIZE];
+	u32 temp_resp_size;
+	struct notifier_block sentnl_notify;
+};
+
+/* Header of the messages exchange with the SENTINEL */
+struct mu_hdr {
+	u8 ver;
+	u8 size;
+	u8 command;
+	u8 tag;
+}  __packed;
+
+struct sentnl_api_msg {
+	u32 header; /* u8 Tag; u8 Command; u8 Size; u8 Ver; */
+	u32 data[SENTNL_MSG_DATA_NUM];
+};
+
+struct sentnl_mu_priv {
+	struct sentnl_mu_device_ctx *cmd_receiver_dev;
+	struct sentnl_mu_device_ctx *waiting_rsp_dev;
+	/*
+	 * prevent parallel access to the MU registers
+	 * e.g. a user trying to send a command while the other one is
+	 * sending a response.
+	 */
+	struct mutex mu_lock;
+	/*
+	 * prevent a command to be sent on the MU while another one is still
+	 * processing. (response to a command is allowed)
+	 */
+	struct mutex mu_cmd_lock;
+	struct device *dev;
+	u32 sentnl_mu_id;
+	u8 cmd_tag;
+	u8 rsp_tag;
+
+	struct mbox_client sentnl_mb_cl;
+	struct mbox_chan *tx_chan, *rx_chan;
+	struct sentnl_api_msg tx_msg, rx_msg;
+	struct completion done;
+	spinlock_t lock;
+};
+
+int get_sentnl_mu_priv(struct sentnl_mu_priv **export);
+#endif
diff --git a/drivers/nvmem/Kconfig b/drivers/nvmem/Kconfig
index 954d3b4a52ab..6436e34e4e0a 100644
--- a/drivers/nvmem/Kconfig
+++ b/drivers/nvmem/Kconfig
@@ -270,4 +270,15 @@ config SPRD_EFUSE
 	  This driver can also be built as a module. If so, the module
 	  will be called nvmem-sprd-efuse.
 
+config NVMEM_IMX_OCOTP_FSB_S400
+	tristate "i.MX FSB/S400-API ocotp fuse box support"
+	depends on IMX_SENTNL_MU
+	default y
+	help
+	  This is a driver for the ocotp fuse box which can be accessed by
+	  FSB and S400-API.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called nvmem-imx-ocotp-fsb-s400.
+
 endif
diff --git a/drivers/nvmem/Makefile b/drivers/nvmem/Makefile
index a7c377218341..e97f1fb7da09 100644
--- a/drivers/nvmem/Makefile
+++ b/drivers/nvmem/Makefile
@@ -55,3 +55,5 @@ obj-$(CONFIG_NVMEM_ZYNQMP)	+= nvmem_zynqmp_nvmem.o
 nvmem_zynqmp_nvmem-y		:= zynqmp_nvmem.o
 obj-$(CONFIG_SPRD_EFUSE)	+= nvmem_sprd_efuse.o
 nvmem_sprd_efuse-y		:= sprd-efuse.o
+obj-$(CONFIG_NVMEM_IMX_OCOTP_FSB_S400) += nvmem-imx-ocotp-fsb-s400.o
+nvmem-imx-ocotp-fsb-s400-y		:= imx-ocotp-fsb-s400.o
diff --git a/drivers/nvmem/imx-ocotp-fsb-s400.c b/drivers/nvmem/imx-ocotp-fsb-s400.c
new file mode 100644
index 000000000000..4b5741208c45
--- /dev/null
+++ b/drivers/nvmem/imx-ocotp-fsb-s400.c
@@ -0,0 +1,204 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Alice Guo <alice.guo@nxp.com>
+ */
+
+#include <linux/dev_printk.h>
+#include <linux/errno.h>
+#include <linux/firmware/imx/sentnl_base_msg.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/nvmem-provider.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+
+#define LOCK_CFG	0x01
+#define ECID		0x02
+#define UNIQ_ID		0x07
+#define OTFAD_CFG	0x17
+
+struct bank_2_reg {
+	unsigned int bank;
+	unsigned int reg;
+	bool flag;
+};
+
+static const struct bank_2_reg fsb_bank_reg[] = {
+	{ 3, 0 },
+	{ 4, 8 },
+	{ 5, 64 },
+	{ 6, 72 },
+	{ 8, 80, true },
+	{ 24, 84, true },
+	{ 26, 88, true },
+	{ 27, 92, true },
+	{ 28, 96 },
+	{ 29, 104 },
+	{ 30, 112 },
+	{ 31, 120 },
+	{ 37, 128 },
+	{ 38, 136 },
+	{ 39, 144 },
+	{ 40, 152 },
+	{ 41, 160 },
+	{ 42, 168 },
+	{ 43, 176 },
+	{ 44, 184 },
+	{ 45, 192 },
+	{ 46, 200 },
+};
+
+struct imx_fsb_s400_fuse {
+	void __iomem *regs;
+	struct nvmem_config config;
+	struct mutex lock;
+};
+
+static int read_words_via_s400_api(u32 *buf, unsigned int fuse_base)
+{
+	unsigned int i;
+	int err = 0;
+
+	for (i = 0; i < 8; i++) {
+		err = read_common_fuse(fuse_base + i, buf + i);
+	}
+
+	return err;
+}
+
+static int read_words_via_fsb(void __iomem *regs, unsigned int bank, u32 *buf)
+{
+	unsigned int i;
+	unsigned int reg_id = UINT_MAX;
+	unsigned int size = ARRAY_SIZE(fsb_bank_reg);
+
+	for (i = 0; i < size; i++) {
+		if (fsb_bank_reg[i].bank == bank) {
+			reg_id = fsb_bank_reg[i].reg;
+			break;
+		}
+	}
+
+	if (reg_id != UINT_MAX) {
+		size = fsb_bank_reg[i].flag ? 4 : 8;
+
+		for (i = 0; i < size; i++) {
+			*buf = readl_relaxed(regs + (reg_id + i) * 4);
+			buf = buf + 1;
+		}
+	}
+
+	return 0;
+}
+
+static int fsb_s400_fuse_read(void *priv, unsigned int offset, void *val,
+			      size_t bytes)
+{
+	struct imx_fsb_s400_fuse *fuse = priv;
+	unsigned int num_bytes, bank;
+	u32 *buf;
+	int err;
+
+	num_bytes = round_up(2048, 4);
+	buf = kzalloc(num_bytes, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	err = -EINVAL;
+
+	mutex_lock(&fuse->lock);
+	for (bank = 0; bank < 63; bank++) {
+		switch (bank) {
+		case 0:
+			break;
+		case LOCK_CFG:
+			err = read_words_via_s400_api(&buf[8], 8);
+			if (err)
+				goto ret;
+			break;
+		case ECID:
+			err = read_words_via_s400_api(&buf[16], 16);
+			if (err)
+				goto ret;
+			break;
+		case UNIQ_ID:
+			err = read_common_fuse(OTP_UNIQ_ID, &buf[56]);
+			if (err)
+				goto ret;
+			break;
+		case OTFAD_CFG:
+			err = read_common_fuse(OTFAD_CONFIG, &buf[184]);
+			if (err)
+				goto ret;
+			break;
+		default:
+			err = read_words_via_fsb(fuse->regs + 0x800, bank, &buf[bank * 8]);
+			break;
+		}
+	}
+
+	memcpy(val, (u8 *)(buf + offset), bytes);
+
+ret:
+	kfree(buf);
+	mutex_unlock(&fuse->lock);
+
+	return err;
+}
+
+static int imx_fsb_s400_fuse_probe(struct platform_device *pdev)
+{
+	struct imx_fsb_s400_fuse *fuse;
+	struct nvmem_device *nvmem;
+
+	fuse = devm_kzalloc(&pdev->dev, sizeof(*fuse), GFP_KERNEL);
+	if (!fuse)
+		return -ENOMEM;
+
+	fuse->regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(fuse->regs))
+		return PTR_ERR(fuse->regs);
+
+	fuse->config.dev = &pdev->dev;
+	fuse->config.name = "fsb_s400_fuse";
+	fuse->config.id = NVMEM_DEVID_AUTO;
+	fuse->config.owner = THIS_MODULE;
+	fuse->config.size = 2048; /* 64 Banks */
+	fuse->config.reg_read = fsb_s400_fuse_read;
+	fuse->config.priv = fuse;
+
+	nvmem = devm_nvmem_register(&pdev->dev, &fuse->config);
+	if (IS_ERR(nvmem)) {
+		dev_err(&pdev->dev, "failed to register fuse nvmem device\n");
+		return PTR_ERR(nvmem);
+	}
+
+	mutex_init(&fuse->lock);
+
+	dev_dbg(&pdev->dev, "fuse nvmem device registered successfully\n");
+
+	return 0;
+}
+
+static const struct of_device_id imx_fsb_s400_fuse_match[] = {
+	{ .compatible = "fsl,imx8ulp-ocotp", },
+	{},
+};
+
+static struct platform_driver imx_fsb_s400_fuse_driver = {
+	.driver = {
+		.name = "fsl-ocotp-fsb-s400",
+		.of_match_table = imx_fsb_s400_fuse_match,
+	},
+	.probe = imx_fsb_s400_fuse_probe,
+};
+module_platform_driver(imx_fsb_s400_fuse_driver);
+
+MODULE_AUTHOR("Alice Guo <alice.guo@nxp.com>");
+MODULE_DESCRIPTION("i.MX FSB/S400-API ocotp fuse box driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/nvmem/imx-ocotp.c b/drivers/nvmem/imx-ocotp.c
index 7a1ebd6fd08b..e9fe26561ec5 100644
--- a/drivers/nvmem/imx-ocotp.c
+++ b/drivers/nvmem/imx-ocotp.c
@@ -4,6 +4,8 @@
  *
  * Copyright (c) 2015 Pengutronix, Philipp Zabel <p.zabel@pengutronix.de>
  *
+ * Copyright 2019 NXP
+ *
  * Based on the barebox ocotp driver,
  * Copyright (c) 2010 Baruch Siach <baruch@tkos.co.il>,
  *	Orex Computed Radiography
@@ -12,6 +14,7 @@
  * Copyright (C) 2010-2013 Freescale Semiconductor, Inc
  */
 
+#include <linux/busfreq-imx.h>
 #include <linux/clk.h>
 #include <linux/device.h>
 #include <linux/io.h>
@@ -158,22 +161,29 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 {
 	struct ocotp_priv *priv = context;
 	unsigned int count;
-	u32 *buf = val;
+	u8 *buf, *p;
 	int i, ret;
-	u32 index;
+	u32 index, num_bytes;
 
 	index = offset >> 2;
-	count = bytes >> 2;
+	num_bytes = round_up((offset % 4) + bytes, 4);
+	count = num_bytes >> 2;
 
 	if (count > (priv->params->nregs - index))
 		count = priv->params->nregs - index;
 
 	mutex_lock(&ocotp_mutex);
 
+	p = kzalloc(num_bytes, GFP_KERNEL);
+	if (!p)
+		return -ENOMEM;
+	buf = p;
+
 	ret = clk_prepare_enable(priv->clk);
 	if (ret < 0) {
 		mutex_unlock(&ocotp_mutex);
 		dev_err(priv->dev, "failed to prepare/enable ocotp clk\n");
+		kfree(p);
 		return ret;
 	}
 
@@ -184,7 +194,7 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 	}
 
 	for (i = index; i < (index + count); i++) {
-		*buf++ = readl(priv->base + IMX_OCOTP_OFFSET_B0W0 +
+		*(u32 *)buf = readl(priv->base + IMX_OCOTP_OFFSET_B0W0 +
 			       i * IMX_OCOTP_OFFSET_PER_WORD);
 
 		/* 47.3.1.2
@@ -193,13 +203,21 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 		 * software before any new write, read or reload access can be
 		 * issued
 		 */
-		if (*(buf - 1) == IMX_OCOTP_READ_LOCKED_VAL)
+		if (*((u32*)buf) == IMX_OCOTP_READ_LOCKED_VAL)
 			imx_ocotp_clr_err_if_set(priv);
+
+		buf += 4;
 	}
 
+	index = offset % 4;
+	memcpy(val, &p[index], bytes);
+
 read_end:
 	clk_disable_unprepare(priv->clk);
 	mutex_unlock(&ocotp_mutex);
+
+	kfree(p);
+
 	return ret;
 }
 
@@ -301,6 +319,8 @@ static int imx_ocotp_write(void *context, unsigned int offset, void *val,
 		return ret;
 	}
 
+	request_bus_freq(BUS_FREQ_HIGH);
+
 	/* Setup the write timing values */
 	priv->params->set_timing(priv);
 
@@ -438,6 +458,8 @@ static int imx_ocotp_write(void *context, unsigned int offset, void *val,
 		dev_err(priv->dev, "timeout during shadow register reload\n");
 
 write_end:
+	release_bus_freq(BUS_FREQ_HIGH);
+
 	clk_disable_unprepare(priv->clk);
 	mutex_unlock(&ocotp_mutex);
 	return ret < 0 ? ret : bytes;
@@ -447,7 +469,7 @@ static struct nvmem_config imx_ocotp_nvmem_config = {
 	.name = "imx-ocotp",
 	.read_only = false,
 	.word_size = 4,
-	.stride = 4,
+	.stride = 1,
 	.reg_read = imx_ocotp_read,
 	.reg_write = imx_ocotp_write,
 };
diff --git a/drivers/rpmsg/Kconfig b/drivers/rpmsg/Kconfig
index f96716893c2a..6f68e9557245 100644
--- a/drivers/rpmsg/Kconfig
+++ b/drivers/rpmsg/Kconfig
@@ -10,11 +10,28 @@ config RPMSG_CHAR
 	tristate "RPMSG device interface"
 	depends on RPMSG
 	depends on NET
+	select RPMSG_CTRL
 	help
 	  Say Y here to export rpmsg endpoints as device files, usually found
 	  in /dev. They make it possible for user-space programs to send and
 	  receive rpmsg packets.
 
+config RPMSG_CTRL
+	tristate "RPMSG control interface"
+	depends on RPMSG
+	help
+	  Say Y here to enable the support of the /dev/rpmsg_ctrlX API. This API
+	  allows user-space programs to create endpoints with specific service name,
+	  source and destination addresses.
+
+config RPMSG_NS
+	tristate "RPMSG name service announcement"
+	depends on RPMSG
+	help
+	  Say Y here to enable the support of the name service announcement
+	  channel that probes the associated RPMsg device on remote endpoint
+	  service announcement.
+
 config RPMSG_MTK_SCP
 	tristate "MediaTek SCP"
 	depends on MTK_SCP
@@ -62,6 +79,44 @@ config RPMSG_VIRTIO
 	tristate "Virtio RPMSG bus driver"
 	depends on HAS_DMA
 	select RPMSG
+	select RPMSG_NS
 	select VIRTIO
 
+config HAVE_IMX_RPMSG
+	bool "IMX RPMSG driver on the AMP SOCs"
+	default y
+	depends on IMX_MBOX
+	select RPMSG_VIRTIO
+	help
+	  Say y here to enable support for the iMX Rpmsg Driver	providing
+	  communication channels to remote processors in iMX asymmetric
+	  multiprocessing (AMP) platforms.
+
+	  Especially, it is mandatory required when the partition reset is
+	  required on some iMX AMP platforms.
+
+config IMX_RPMSG_PINGPONG
+	tristate "IMX RPMSG pingpong driver -- loadable modules only"
+	default m
+	depends on HAVE_IMX_RPMSG && m
+	help
+	  One 32bit unsigned int data transactions demoe between the A core
+	  and the remote M core on the iMX AMP platforms.
+
+	  Only the module mode is supported here, the demo would be kicked off
+	  immediately when this module is insmoded.
+
+config IMX_RPMSG_TTY
+	tristate "IMX RPMSG tty driver -- loadable modules only"
+	default m
+	depends on HAVE_IMX_RPMSG && m
+	help
+	  Demostrate the string transmission from A core to the remote M core
+	  on the iMX AMP platforms.
+
+	  Only the module mode is supported here. The according device node
+	  would be created after this module is insmoded. the demo would be
+	  executed by the command "echo <string> > <accordingly node>", thus
+	  remote M core would receive the string.
+
 endmenu
diff --git a/drivers/rpmsg/Makefile b/drivers/rpmsg/Makefile
index ffe932ef6050..7c4ee52e92c4 100644
--- a/drivers/rpmsg/Makefile
+++ b/drivers/rpmsg/Makefile
@@ -1,6 +1,8 @@
 # SPDX-License-Identifier: GPL-2.0
 obj-$(CONFIG_RPMSG)		+= rpmsg_core.o
 obj-$(CONFIG_RPMSG_CHAR)	+= rpmsg_char.o
+obj-$(CONFIG_RPMSG_CTRL)	+= rpmsg_ctrl.o
+obj-$(CONFIG_RPMSG_NS)		+= rpmsg_ns.o
 obj-$(CONFIG_RPMSG_MTK_SCP)	+= mtk_rpmsg.o
 qcom_glink-objs			:= qcom_glink_native.o qcom_glink_ssr.o
 obj-$(CONFIG_RPMSG_QCOM_GLINK) += qcom_glink.o
@@ -8,3 +10,6 @@ obj-$(CONFIG_RPMSG_QCOM_GLINK_RPM) += qcom_glink_rpm.o
 obj-$(CONFIG_RPMSG_QCOM_GLINK_SMEM) += qcom_glink_smem.o
 obj-$(CONFIG_RPMSG_QCOM_SMD)	+= qcom_smd.o
 obj-$(CONFIG_RPMSG_VIRTIO)	+= virtio_rpmsg_bus.o
+obj-$(CONFIG_HAVE_IMX_RPMSG)	+= imx_rpmsg.o
+obj-$(CONFIG_IMX_RPMSG_PINGPONG)	+= imx_rpmsg_pingpong.o
+obj-$(CONFIG_IMX_RPMSG_TTY)	+= imx_rpmsg_tty.o
diff --git a/drivers/rpmsg/imx_rpmsg.c b/drivers/rpmsg/imx_rpmsg.c
new file mode 100644
index 000000000000..504010fec1e7
--- /dev/null
+++ b/drivers/rpmsg/imx_rpmsg.c
@@ -0,0 +1,680 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ */
+
+#include <linux/slab.h>
+#include <linux/circ_buf.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#ifdef CONFIG_IMX_SCU
+#include <linux/firmware/imx/sci.h>
+#endif
+#include <linux/init.h>
+#include <linux/mailbox_client.h>
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/of_device.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/platform_device.h>
+#include <linux/virtio_config.h>
+#include <linux/virtio_ids.h>
+#include <linux/virtio_ring.h>
+#include <linux/imx_rpmsg.h>
+#include "rpmsg_internal.h"
+
+enum imx_rpmsg_variants {
+	IMX8QM,
+	IMX8QXP,
+	IMX8MQ,
+	IMX8MM,
+	IMX7ULP,
+	IMX7D,
+	IMX6SX,
+};
+
+struct imx_virdev {
+	struct virtio_device vdev;
+	unsigned int vring[2];
+	struct virtqueue *vq[2];
+	int base_vq_id;
+	int num_of_vqs;
+	struct imx_rpmsg_vproc *rpdev;
+};
+
+struct imx_rpmsg_vproc {
+	struct mbox_client cl;
+	struct mbox_client cl_rxdb;
+	struct mbox_chan *tx_ch;
+	struct mbox_chan *rx_ch;
+	struct mbox_chan *rxdb_ch;
+	enum imx_rpmsg_variants variant;
+	int vdev_nums;
+	int first_notify;
+	u32 flags;
+#define MAX_VDEV_NUMS  8
+	struct imx_virdev *ivdev[MAX_VDEV_NUMS];
+	struct delayed_work rpmsg_work;
+	struct circ_buf rx_buffer;
+	spinlock_t mu_lock;
+	u32 mub_partition;
+	struct notifier_block proc_nb;
+	struct platform_device *pdev;
+};
+
+#define SC_IRQ_GROUP_REBOOTED   5U      /* Partition reboot complete */
+
+/*
+ * The time consumption by remote ready is less than 1ms in the
+ * evaluation. Set the max wait timeout as 50ms here.
+ */
+#define REMOTE_READY_WAIT_MAX_RETRIES	500
+
+#define RPMSG_NUM_BUFS		(512)
+#define RPMSG_BUF_SIZE		(512)
+#define RPMSG_BUFS_SPACE	(RPMSG_NUM_BUFS * RPMSG_BUF_SIZE)
+#define RPMSG_VRING_ALIGN	(4096)
+#define RPMSG_RING_SIZE	((DIV_ROUND_UP(vring_size(RPMSG_NUM_BUFS / 2, \
+				RPMSG_VRING_ALIGN), PAGE_SIZE)) * PAGE_SIZE)
+
+#define to_imx_virdev(vd) container_of(vd, struct imx_virdev, vdev)
+
+/*
+ * 1: indicated that remote processor is ready from re-initialization.
+ * Clear this bit after the RPMSG restore is finished at master side.
+ */
+#define REMOTE_IS_READY			BIT(0)
+/* 1: Use reserved memory region as DMA pool */
+#define SPECIFIC_DMA_POOL		BIT(1)
+
+struct imx_rpmsg_vq_info {
+	__u16 num;	/* number of entries in the virtio_ring */
+	__u16 vq_id;	/* a globaly unique index of this virtqueue */
+	__u32 mmsg;	/* the mailbox msg transferred on the virtqueue */
+	void *addr;	/* address where we mapped the virtio ring */
+	struct imx_rpmsg_vproc *rpdev;
+};
+
+static u64 imx_rpmsg_get_features(struct virtio_device *vdev)
+{
+	/* VIRTIO_RPMSG_F_NS has been made private */
+	return 1 << 0;
+}
+
+static int imx_rpmsg_finalize_features(struct virtio_device *vdev)
+{
+	/* Give virtio_ring a chance to accept features */
+	vring_transport_features(vdev);
+	return 0;
+}
+
+/* kick the remote processor, and let it know which virtqueue to poke at */
+static bool imx_rpmsg_notify(struct virtqueue *vq)
+{
+	int ret;
+	struct imx_rpmsg_vq_info *rpvq = vq->priv;
+	struct imx_rpmsg_vproc *rpdev = rpvq->rpdev;
+
+	rpvq->mmsg = rpvq->vq_id << 16;
+	/*
+	 * Send the index of the triggered virtqueue as the mu payload.
+	 * Use the timeout MU send message here.
+	 * Since that M4 core may not be loaded, and the first MSG may
+	 * not be handled by M4 when multi-vdev is enabled.
+	 * To make sure that the message wound't be discarded when M4
+	 * is running normally or in the suspend mode. Only use
+	 * the timeout mechanism by the first notify when the vdev is
+	 * registered.
+	 * ~14ms is required by M4 ready to process the MU message from
+	 * cold boot. Set the wait time 20ms here.
+	 */
+	if (unlikely(rpdev->first_notify > 0)) {
+		rpdev->first_notify--;
+		rpdev->cl.tx_tout = 20;
+		ret = mbox_send_message(rpdev->tx_ch, &rpvq->mmsg);
+		if (ret < 0)
+			return false;
+	} else {
+		rpdev->cl.tx_tout = 0;
+		ret = mbox_send_message(rpdev->tx_ch, &rpvq->mmsg);
+		if (ret < 0)
+			return false;
+	}
+
+	return true;
+}
+
+static struct virtqueue *rp_find_vq(struct virtio_device *vdev,
+				    unsigned int index,
+				    void (*callback)(struct virtqueue *vq),
+				    const char *name,
+				    bool ctx)
+{
+	struct imx_virdev *virdev = to_imx_virdev(vdev);
+	struct imx_rpmsg_vproc *rpdev = virdev->rpdev;
+	struct platform_device *pdev = rpdev->pdev;
+	struct device *dev = &pdev->dev;
+	struct imx_rpmsg_vq_info *rpvq;
+	struct virtqueue *vq;
+	int err;
+
+	rpvq = kmalloc(sizeof(*rpvq), GFP_KERNEL);
+	if (!rpvq)
+		return ERR_PTR(-ENOMEM);
+
+	/* ioremap'ing normal memory, so we cast away sparse's complaints */
+	rpvq->addr = (__force void *) ioremap(virdev->vring[index],
+							RPMSG_RING_SIZE);
+	if (!rpvq->addr) {
+		err = -ENOMEM;
+		goto free_rpvq;
+	}
+
+	memset_io(rpvq->addr, 0, RPMSG_RING_SIZE);
+
+	dev_dbg(dev, "vring%d: phys 0x%x, virt 0x%p\n",
+			index, virdev->vring[index], rpvq->addr);
+
+	vq = vring_new_virtqueue(index, RPMSG_NUM_BUFS / 2, RPMSG_VRING_ALIGN,
+			vdev, true, ctx,
+			rpvq->addr,
+			imx_rpmsg_notify, callback,
+			name);
+	if (!vq) {
+		dev_err(dev, "vring_new_virtqueue failed\n");
+		err = -ENOMEM;
+		goto unmap_vring;
+	}
+
+	virdev->vq[index] = vq;
+	vq->priv = rpvq;
+	/* system-wide unique id for this virtqueue */
+	rpvq->vq_id = virdev->base_vq_id + index;
+	rpvq->rpdev = rpdev;
+
+	return vq;
+
+unmap_vring:
+	/* iounmap normal memory, so make sparse happy */
+	iounmap((__force void __iomem *) rpvq->addr);
+free_rpvq:
+	kfree(rpvq);
+	return ERR_PTR(err);
+}
+
+static void imx_rpmsg_del_vqs(struct virtio_device *vdev)
+{
+	struct virtqueue *vq, *n;
+
+	list_for_each_entry_safe(vq, n, &vdev->vqs, list) {
+		struct imx_rpmsg_vq_info *rpvq = vq->priv;
+
+		iounmap(rpvq->addr);
+		vring_del_virtqueue(vq);
+		kfree(rpvq);
+	}
+}
+
+static int imx_rpmsg_find_vqs(struct virtio_device *vdev, unsigned int nvqs,
+		       struct virtqueue *vqs[],
+		       vq_callback_t *callbacks[],
+		       const char * const names[],
+		       const bool *ctx,
+		       struct irq_affinity *desc)
+{
+	struct imx_virdev *virdev = to_imx_virdev(vdev);
+	int i, err;
+
+	/* we maintain two virtqueues per remote processor (for RX and TX) */
+	if (nvqs != 2)
+		return -EINVAL;
+
+	for (i = 0; i < nvqs; ++i) {
+		vqs[i] = rp_find_vq(vdev, i, callbacks[i], names[i],
+				ctx ? ctx[i] : false);
+		if (IS_ERR(vqs[i])) {
+			err = PTR_ERR(vqs[i]);
+			goto error;
+		}
+	}
+
+	virdev->num_of_vqs = nvqs;
+	return 0;
+
+error:
+	imx_rpmsg_del_vqs(vdev);
+	return err;
+}
+
+static void imx_rpmsg_reset(struct virtio_device *vdev)
+{
+	dev_dbg(&vdev->dev, "reset !\n");
+}
+
+static u8 imx_rpmsg_get_status(struct virtio_device *vdev)
+{
+	return 0;
+}
+
+static void imx_rpmsg_set_status(struct virtio_device *vdev, u8 status)
+{
+	dev_dbg(&vdev->dev, "%s new status: %d\n", __func__, status);
+}
+
+static void imx_rpmsg_vproc_release(struct device *dev)
+{
+	/* this handler is provided so driver core doesn't yell at us */
+}
+
+static struct virtio_config_ops imx_rpmsg_config_ops = {
+	.get_features	= imx_rpmsg_get_features,
+	.finalize_features = imx_rpmsg_finalize_features,
+	.find_vqs	= imx_rpmsg_find_vqs,
+	.del_vqs	= imx_rpmsg_del_vqs,
+	.reset		= imx_rpmsg_reset,
+	.set_status	= imx_rpmsg_set_status,
+	.get_status	= imx_rpmsg_get_status,
+};
+
+static const struct of_device_id imx_rpmsg_dt_ids[] = {
+	{ .compatible = "fsl,imx8qm-rpmsg", .data = (void *)IMX8QM, },
+	{ .compatible = "fsl,imx8qxp-rpmsg", .data = (void *)IMX8QXP, },
+	{ .compatible = "fsl,imx8mq-rpmsg", .data = (void *)IMX8MQ, },
+	{ .compatible = "fsl,imx8mm-rpmsg", .data = (void *)IMX8MM, },
+	{ .compatible = "fsl,imx7ulp-rpmsg", .data = (void *)IMX7ULP, },
+	{ .compatible = "fsl,imx7d-rpmsg", .data = (void *)IMX7D, },
+	{ .compatible = "fsl,imx6sx-rpmsg", .data = (void *)IMX6SX, },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, imx_rpmsg_dt_ids);
+
+static int set_vring_phy_buf(struct platform_device *pdev,
+		       struct imx_rpmsg_vproc *rpdev, int vdev_nums)
+{
+	struct resource *res;
+	resource_size_t size;
+	unsigned int start, end;
+	int i, ret = 0;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res) {
+		size = resource_size(res);
+		start = res->start;
+		end = res->start + size;
+		for (i = 0; i < vdev_nums; i++) {
+			rpdev->ivdev[i] = kzalloc(sizeof(struct imx_virdev),
+							GFP_KERNEL);
+			if (!rpdev->ivdev[i])
+				return -ENOMEM;
+
+			rpdev->ivdev[i]->vring[0] = start;
+			rpdev->ivdev[i]->vring[1] = start + 0x8000;
+			start += 0x10000;
+			if (start > end) {
+				dev_err(&pdev->dev,
+					"Too small memory size %x!\n",
+					(u32)size);
+				ret = -EINVAL;
+				break;
+			}
+		}
+	} else {
+		return -ENOMEM;
+	}
+
+	return ret;
+}
+
+static void rpmsg_work_handler(struct work_struct *work)
+{
+	u32 message;
+	unsigned long flags;
+	struct imx_virdev *virdev;
+	struct delayed_work *dwork = to_delayed_work(work);
+	struct imx_rpmsg_vproc *rpdev = container_of(dwork,
+			struct imx_rpmsg_vproc, rpmsg_work);
+	struct circ_buf *cb = &rpdev->rx_buffer;
+	struct platform_device *pdev = rpdev->pdev;
+	struct device *dev = &pdev->dev;
+
+	spin_lock_irqsave(&rpdev->mu_lock, flags);
+	/* handle all incoming mu message */
+	while (CIRC_CNT(cb->head, cb->tail, PAGE_SIZE)) {
+		message = cb->buf[cb->tail];
+		message |= (cb->buf[cb->tail + 1] << 8);
+		message |= (cb->buf[cb->tail + 2] << 16);
+		message |= (cb->buf[cb->tail + 3] << 24);
+		spin_unlock_irqrestore(&rpdev->mu_lock, flags);
+		virdev = rpdev->ivdev[(message >> 16) / 2];
+
+		dev_dbg(dev, "%s msg: 0x%x\n", __func__, message);
+		message = message >> 16;
+		message -= virdev->base_vq_id;
+
+		/*
+		 * Currently both PENDING_MSG and explicit-virtqueue-index
+		 * messaging are supported.
+		 * Whatever approach is taken, at this point message contains
+		 * the index of the vring which was just triggered.
+		 */
+		if (message  < virdev->num_of_vqs)
+			vring_interrupt(message, virdev->vq[message]);
+		spin_lock_irqsave(&rpdev->mu_lock, flags);
+		cb->tail = CIRC_ADD(cb->tail, PAGE_SIZE, 4);
+	}
+	spin_unlock_irqrestore(&rpdev->mu_lock, flags);
+}
+
+#ifdef CONFIG_IMX_SCU
+void imx_rpmsg_restore(struct imx_rpmsg_vproc *rpdev)
+{
+	int i;
+	int vdev_nums = rpdev->vdev_nums;
+
+	for (i = 0; i < vdev_nums; i++) {
+		unregister_virtio_device(&rpdev->ivdev[i]->vdev);
+		kfree(rpdev->ivdev[i]);
+	}
+
+	/* Make a double check that remote processor is ready or not */
+	for (i = 0; i < REMOTE_READY_WAIT_MAX_RETRIES; i++) {
+		if (rpdev->flags & REMOTE_IS_READY)
+			break;
+		udelay(100);
+	}
+	if (unlikely((rpdev->flags & REMOTE_IS_READY) == 0)) {
+		pr_info("Wait for remote ready timeout, use first_notify.\n");
+		/*
+		 * In order to make the codes to be robust and back compatible.
+		 * When wait remote ready timeout, re-initialize the
+		 * first_notify to send the first kick-off message when
+		 * register the vdev.
+		 */
+		rpdev->first_notify = rpdev->vdev_nums;
+	}
+
+	/* Allocate and setup ivdev again to register virtio devices */
+	if (set_vring_phy_buf(rpdev->pdev, rpdev, rpdev->vdev_nums))
+		pr_err("No vring buffer.\n");
+
+	for (i = 0; i < vdev_nums; i++) {
+		rpdev->ivdev[i]->vdev.id.device = VIRTIO_ID_RPMSG;
+		rpdev->ivdev[i]->vdev.config = &imx_rpmsg_config_ops;
+		rpdev->ivdev[i]->vdev.dev.parent = &rpdev->pdev->dev;
+		rpdev->ivdev[i]->vdev.dev.release = imx_rpmsg_vproc_release;
+		rpdev->ivdev[i]->base_vq_id = i * 2;
+		rpdev->ivdev[i]->rpdev = rpdev;
+
+		if (register_virtio_device(&rpdev->ivdev[i]->vdev))
+			pr_err("%s failed to register rpdev.\n", __func__);
+	}
+}
+
+static int imx_rpmsg_partition_notify(struct notifier_block *nb,
+				      unsigned long event, void *group)
+{
+	struct imx_rpmsg_vproc *rpdev;
+
+	rpdev = container_of(nb, struct imx_rpmsg_vproc, proc_nb);
+
+	/* Ignore other irqs */
+	if (!((event & BIT(rpdev->mub_partition)) &&
+		(*(u8 *)group == SC_IRQ_GROUP_REBOOTED)))
+		return 0;
+
+	imx_rpmsg_restore(rpdev);
+	pr_info("Patition%d reset!\n", rpdev->mub_partition);
+
+	return 0;
+}
+#endif
+
+static void imx_rpmsg_rxdb_callback(struct mbox_client *c, void *msg)
+{
+	unsigned long flags;
+	struct imx_rpmsg_vproc *rpdev = container_of(c,
+			struct imx_rpmsg_vproc, cl);
+
+	spin_lock_irqsave(&rpdev->mu_lock, flags);
+	rpdev->flags |= REMOTE_IS_READY;
+	spin_unlock_irqrestore(&rpdev->mu_lock, flags);
+}
+
+static int imx_rpmsg_rxdb_channel_init(struct imx_rpmsg_vproc *rpdev)
+{
+	struct platform_device *pdev = rpdev->pdev;
+	struct device *dev = &pdev->dev;
+	struct mbox_client *cl;
+	int ret = 0;
+
+	cl = &rpdev->cl_rxdb;
+	cl->dev = dev;
+	cl->rx_callback = imx_rpmsg_rxdb_callback;
+
+	/*
+	 * RX door bell is used to receive the ready signal from remote
+	 * after the partition reset of A core.
+	 */
+	rpdev->rxdb_ch = mbox_request_channel_byname(cl, "rxdb");
+	if (IS_ERR(rpdev->rxdb_ch)) {
+		ret = PTR_ERR(rpdev->rxdb_ch);
+		dev_dbg(cl->dev, "failed to request mbox chan rxdb, ret %d\n",
+			ret);
+		return ret;
+	}
+
+	return ret;
+}
+
+static void imx_rpmsg_rx_callback(struct mbox_client *c, void *msg)
+{
+	int buf_space;
+	u32 *data = msg;
+	struct imx_rpmsg_vproc *rpdev = container_of(c,
+			struct imx_rpmsg_vproc, cl);
+	struct circ_buf *cb = &rpdev->rx_buffer;
+
+	spin_lock(&rpdev->mu_lock);
+	buf_space = CIRC_SPACE(cb->head, cb->tail, PAGE_SIZE);
+	if (unlikely(!buf_space)) {
+		dev_err(c->dev, "RPMSG RX overflow!\n");
+		spin_unlock(&rpdev->mu_lock);
+		return;
+	}
+	cb->buf[cb->head] = (u8) *data;
+	cb->buf[cb->head + 1] = (u8) (*data >> 8);
+	cb->buf[cb->head + 2] = (u8) (*data >> 16);
+	cb->buf[cb->head + 3] = (u8) (*data >> 24);
+	cb->head = CIRC_ADD(cb->head, PAGE_SIZE, 4);
+	spin_unlock(&rpdev->mu_lock);
+
+	schedule_delayed_work(&(rpdev->rpmsg_work), 0);
+}
+
+static int imx_rpmsg_xtr_channel_init(struct imx_rpmsg_vproc *rpdev)
+{
+	struct platform_device *pdev = rpdev->pdev;
+	struct device *dev = &pdev->dev;
+	struct mbox_client *cl;
+	int ret = 0;
+
+	cl = &rpdev->cl;
+	cl->dev = dev;
+	cl->tx_block = true;
+	cl->tx_tout = 20;
+	cl->knows_txdone = false;
+	cl->rx_callback = imx_rpmsg_rx_callback;
+
+	rpdev->tx_ch = mbox_request_channel_byname(cl, "tx");
+	if (IS_ERR(rpdev->tx_ch)) {
+		ret = PTR_ERR(rpdev->tx_ch);
+		dev_dbg(cl->dev, "failed to request mbox tx chan, ret %d\n",
+			ret);
+		goto err_out;
+	}
+	rpdev->rx_ch = mbox_request_channel_byname(cl, "rx");
+	if (IS_ERR(rpdev->rx_ch)) {
+		ret = PTR_ERR(rpdev->rx_ch);
+		dev_dbg(cl->dev, "failed to request mbox rx chan, ret %d\n",
+			ret);
+		goto err_out;
+	}
+
+	return ret;
+
+err_out:
+	if (!IS_ERR(rpdev->tx_ch))
+		mbox_free_channel(rpdev->tx_ch);
+	if (!IS_ERR(rpdev->rx_ch))
+		mbox_free_channel(rpdev->rx_ch);
+
+	return ret;
+}
+
+static int imx_rpmsg_probe(struct platform_device *pdev)
+{
+	int j, ret = 0;
+	unsigned long variant;
+	char *buf;
+	struct device *dev = &pdev->dev;
+	struct device_node *np = pdev->dev.of_node;
+	struct imx_rpmsg_vproc *rpdev;
+
+	buf = devm_kzalloc(dev, PAGE_SIZE, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	rpdev = devm_kzalloc(dev, sizeof(*rpdev), GFP_KERNEL);
+	if (!rpdev)
+		return -ENOMEM;
+
+	rpdev->pdev = pdev;
+#ifdef CONFIG_IMX_SCU
+	rpdev->proc_nb.notifier_call = imx_rpmsg_partition_notify;
+#endif
+	variant = (uintptr_t)of_device_get_match_data(dev);
+	rpdev->variant = (enum imx_rpmsg_variants)variant;
+	rpdev->rx_buffer.buf = buf;
+	rpdev->rx_buffer.head = 0;
+	rpdev->rx_buffer.tail = 0;
+
+	/* Initialize the RX/TX channels. */
+	ret = imx_rpmsg_xtr_channel_init(rpdev);
+	if (ret)
+		return ret;
+
+	spin_lock_init(&rpdev->mu_lock);
+	INIT_DELAYED_WORK(&(rpdev->rpmsg_work), rpmsg_work_handler);
+	ret = of_property_read_u32(np, "vdev-nums", &rpdev->vdev_nums);
+	if (ret)
+		rpdev->vdev_nums = 1;
+	if (rpdev->vdev_nums > MAX_VDEV_NUMS) {
+		dev_err(dev, "vdev-nums exceed the max %d\n", MAX_VDEV_NUMS);
+		ret = -EINVAL;
+		goto err_chl;
+	}
+	rpdev->first_notify = rpdev->vdev_nums;
+
+	ret = set_vring_phy_buf(pdev, rpdev, rpdev->vdev_nums);
+	if (ret) {
+		dev_err(dev, "No vring buffer.\n");
+		ret = -ENOMEM;
+		goto err_chl;
+	}
+	if (of_reserved_mem_device_init(dev)) {
+		dev_dbg(dev, "dev doesn't have specific DMA pool.\n");
+		rpdev->flags &= (~SPECIFIC_DMA_POOL);
+	} else {
+		rpdev->flags |= SPECIFIC_DMA_POOL;
+	}
+
+	for (j = 0; j < rpdev->vdev_nums; j++) {
+		dev_dbg(dev, "%s rpdev vdev%d: vring0 0x%x, vring1 0x%x\n",
+			 __func__, rpdev->vdev_nums,
+			 rpdev->ivdev[j]->vring[0],
+			 rpdev->ivdev[j]->vring[1]);
+		rpdev->ivdev[j]->vdev.id.device = VIRTIO_ID_RPMSG;
+		rpdev->ivdev[j]->vdev.config = &imx_rpmsg_config_ops;
+		rpdev->ivdev[j]->vdev.dev.parent = &pdev->dev;
+		rpdev->ivdev[j]->vdev.dev.release = imx_rpmsg_vproc_release;
+		rpdev->ivdev[j]->base_vq_id = j * 2;
+		rpdev->ivdev[j]->rpdev = rpdev;
+
+		ret = register_virtio_device(&rpdev->ivdev[j]->vdev);
+		if (ret) {
+			dev_err(dev, "%s failed to register rpdev: %d\n",
+					__func__, ret);
+			goto err_out;
+		}
+	}
+	/* Initialize the RX doorbell channel. */
+	ret = imx_rpmsg_rxdb_channel_init(rpdev);
+	if (ret)
+		goto err_out;
+
+	platform_set_drvdata(pdev, rpdev);
+
+#ifdef CONFIG_IMX_SCU
+	if (rpdev->variant == IMX8QXP || rpdev->variant == IMX8QM) {
+		/* Get muB partition id and enable irq in SCFW then */
+		if (of_property_read_u32(np, "mub-partition",
+					&rpdev->mub_partition))
+			rpdev->mub_partition = 3; /* default partition 3 */
+
+		ret = imx_scu_irq_group_enable(SC_IRQ_GROUP_REBOOTED,
+					      BIT(rpdev->mub_partition),
+					      true);
+		if (ret) {
+			dev_warn(&pdev->dev, "Enable irq failed.\n");
+			return ret;
+		}
+
+		ret = imx_scu_irq_register_notifier(&rpdev->proc_nb);
+		if (ret) {
+			imx_scu_irq_group_enable(SC_IRQ_GROUP_REBOOTED,
+						BIT(rpdev->mub_partition),
+						false);
+			dev_warn(&pdev->dev, "reqister scu notifier failed.\n");
+			return ret;
+		}
+	}
+#endif
+
+	return ret;
+
+err_out:
+	if (rpdev->flags & SPECIFIC_DMA_POOL)
+		of_reserved_mem_device_release(dev);
+err_chl:
+	if (!IS_ERR(rpdev->tx_ch))
+		mbox_free_channel(rpdev->tx_ch);
+	if (!IS_ERR(rpdev->rx_ch))
+		mbox_free_channel(rpdev->rx_ch);
+	return ret;
+}
+
+static struct platform_driver imx_rpmsg_driver = {
+	.driver = {
+		   .owner = THIS_MODULE,
+		   .name = "imx-rpmsg",
+		   .of_match_table = imx_rpmsg_dt_ids,
+		   },
+	.probe = imx_rpmsg_probe,
+};
+
+static int __init imx_rpmsg_init(void)
+{
+	int ret;
+
+	ret = platform_driver_register(&imx_rpmsg_driver);
+	if (ret)
+		pr_err("Unable to initialize rpmsg driver\n");
+	else
+		pr_info("imx rpmsg driver is registered.\n");
+
+	return ret;
+}
+
+MODULE_DESCRIPTION("iMX remote processor messaging virtio device");
+MODULE_LICENSE("GPL v2");
+arch_initcall(imx_rpmsg_init);
diff --git a/drivers/rpmsg/imx_rpmsg_pingpong.c b/drivers/rpmsg/imx_rpmsg_pingpong.c
new file mode 100644
index 000000000000..77ffe2510ae6
--- /dev/null
+++ b/drivers/rpmsg/imx_rpmsg_pingpong.c
@@ -0,0 +1,100 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/virtio.h>
+#include <linux/rpmsg.h>
+
+#define MSG		"hello world!"
+
+static int rpmsg_pingpong_cb(struct rpmsg_device *rpdev, void *data, int len,
+						void *priv, u32 src)
+{
+	int err;
+	unsigned int rpmsg_pingpong;
+
+	/* reply */
+	rpmsg_pingpong = *(unsigned int *)data;
+	pr_info("get %d (src: 0x%x)\n", rpmsg_pingpong, src);
+
+	/* pingpongs should not live forever */
+	if (rpmsg_pingpong > 100) {
+		dev_info(&rpdev->dev, "goodbye!\n");
+		return 0;
+	}
+	rpmsg_pingpong++;
+	err = rpmsg_sendto(rpdev->ept, (void *)(&rpmsg_pingpong), 4, src);
+
+	if (err)
+		dev_err(&rpdev->dev, "rpmsg_send failed: %d\n", err);
+
+	return err;
+}
+
+static int rpmsg_pingpong_probe(struct rpmsg_device *rpdev)
+{
+	int err;
+	unsigned int rpmsg_pingpong;
+
+	dev_info(&rpdev->dev, "new channel: 0x%x -> 0x%x!\n",
+			rpdev->src, rpdev->dst);
+
+	/*
+	 * send a message to our remote processor, and tell remote
+	 * processor about this channel
+	 */
+	err = rpmsg_send(rpdev->ept, MSG, strlen(MSG));
+	if (err) {
+		dev_err(&rpdev->dev, "rpmsg_send failed: %d\n", err);
+		return err;
+	}
+
+	rpmsg_pingpong = 0;
+	err = rpmsg_sendto(rpdev->ept, (void *)(&rpmsg_pingpong),
+			   4, rpdev->dst);
+	if (err) {
+		dev_err(&rpdev->dev, "rpmsg_send failed: %d\n", err);
+		return err;
+	}
+
+	return 0;
+}
+
+static void rpmsg_pingpong_remove(struct rpmsg_device *rpdev)
+{
+	dev_info(&rpdev->dev, "rpmsg pingpong driver is removed\n");
+}
+
+static struct rpmsg_device_id rpmsg_driver_pingpong_id_table[] = {
+	{ .name	= "rpmsg-openamp-demo-channel" },
+	{ .name	= "rpmsg-openamp-demo-channel-1" },
+	{ },
+};
+
+static struct rpmsg_driver rpmsg_pingpong_driver = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= rpmsg_driver_pingpong_id_table,
+	.probe		= rpmsg_pingpong_probe,
+	.callback	= rpmsg_pingpong_cb,
+	.remove		= rpmsg_pingpong_remove,
+};
+
+static int __init init(void)
+{
+	return register_rpmsg_driver(&rpmsg_pingpong_driver);
+}
+
+static void __exit fini(void)
+{
+	unregister_rpmsg_driver(&rpmsg_pingpong_driver);
+}
+module_init(init);
+module_exit(fini);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("iMX virtio remote processor messaging pingpong driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/rpmsg/imx_rpmsg_tty.c b/drivers/rpmsg/imx_rpmsg_tty.c
new file mode 100644
index 000000000000..7092be2eacd4
--- /dev/null
+++ b/drivers/rpmsg/imx_rpmsg_tty.c
@@ -0,0 +1,242 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ */
+
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/rpmsg.h>
+#include <linux/tty.h>
+#include <linux/tty_driver.h>
+#include <linux/tty_flip.h>
+#include <linux/virtio.h>
+
+/* this needs to be less then (RPMSG_BUF_SIZE - sizeof(struct rpmsg_hdr)) */
+#define RPMSG_MAX_SIZE		256
+#define MSG		"hello world!"
+
+/*
+ * struct rpmsgtty_port - Wrapper struct for imx rpmsg tty port.
+ * @port:		TTY port data
+ */
+struct rpmsgtty_port {
+	struct tty_port		port;
+	spinlock_t		rx_lock;
+	struct rpmsg_device	*rpdev;
+	struct tty_driver	*rpmsgtty_driver;
+};
+
+static int rpmsg_tty_cb(struct rpmsg_device *rpdev, void *data, int len,
+						void *priv, u32 src)
+{
+	int space;
+	unsigned char *cbuf;
+	struct rpmsgtty_port *cport = dev_get_drvdata(&rpdev->dev);
+
+	/* flush the recv-ed none-zero data to tty node */
+	if (len == 0)
+		return 0;
+
+	dev_dbg(&rpdev->dev, "msg(<- src 0x%x) len %d\n", src, len);
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+			data, len,  true);
+
+	spin_lock_bh(&cport->rx_lock);
+	space = tty_prepare_flip_string(&cport->port, &cbuf, len);
+	if (space <= 0) {
+		dev_err(&rpdev->dev, "No memory for tty_prepare_flip_string\n");
+		spin_unlock_bh(&cport->rx_lock);
+		return -ENOMEM;
+	}
+
+	memcpy(cbuf, data, len);
+	tty_flip_buffer_push(&cport->port);
+	spin_unlock_bh(&cport->rx_lock);
+
+	return 0;
+}
+
+static struct tty_port_operations  rpmsgtty_port_ops = { };
+
+static int rpmsgtty_install(struct tty_driver *driver, struct tty_struct *tty)
+{
+	struct rpmsgtty_port *cport = driver->driver_state;
+
+	return tty_port_install(&cport->port, driver, tty);
+}
+
+static int rpmsgtty_open(struct tty_struct *tty, struct file *filp)
+{
+	return tty_port_open(tty->port, tty, filp);
+}
+
+static void rpmsgtty_close(struct tty_struct *tty, struct file *filp)
+{
+	return tty_port_close(tty->port, tty, filp);
+}
+
+static int rpmsgtty_write(struct tty_struct *tty, const unsigned char *buf,
+			 int total)
+{
+	int count, ret = 0;
+	const unsigned char *tbuf;
+	struct rpmsgtty_port *rptty_port = container_of(tty->port,
+			struct rpmsgtty_port, port);
+	struct rpmsg_device *rpdev = rptty_port->rpdev;
+
+	if (buf == NULL) {
+		pr_err("buf shouldn't be null.\n");
+		return -ENOMEM;
+	}
+
+	count = total;
+	tbuf = buf;
+	do {
+		/* send a message to our remote processor */
+		ret = rpmsg_send(rpdev->ept, (void *)tbuf,
+			count > RPMSG_MAX_SIZE ? RPMSG_MAX_SIZE : count);
+		if (ret) {
+			dev_err(&rpdev->dev, "rpmsg_send failed: %d\n", ret);
+			return ret;
+		}
+
+		if (count > RPMSG_MAX_SIZE) {
+			count -= RPMSG_MAX_SIZE;
+			tbuf += RPMSG_MAX_SIZE;
+		} else {
+			count = 0;
+		}
+	} while (count > 0);
+
+	return total;
+}
+
+static int rpmsgtty_write_room(struct tty_struct *tty)
+{
+	/* report the space in the rpmsg buffer */
+	return RPMSG_MAX_SIZE;
+}
+
+static const struct tty_operations imxrpmsgtty_ops = {
+	.install		= rpmsgtty_install,
+	.open			= rpmsgtty_open,
+	.close			= rpmsgtty_close,
+	.write			= rpmsgtty_write,
+	.write_room		= rpmsgtty_write_room,
+};
+
+static int rpmsg_tty_probe(struct rpmsg_device *rpdev)
+{
+	int ret;
+	struct rpmsgtty_port *cport;
+	struct tty_driver *rpmsgtty_driver;
+
+	dev_info(&rpdev->dev, "new channel: 0x%x -> 0x%x!\n",
+			rpdev->src, rpdev->dst);
+
+	cport = devm_kzalloc(&rpdev->dev, sizeof(*cport), GFP_KERNEL);
+	if (!cport)
+		return -ENOMEM;
+
+	rpmsgtty_driver = tty_alloc_driver(1, TTY_DRIVER_UNNUMBERED_NODE);
+	if (IS_ERR(rpmsgtty_driver)) {
+		kfree(cport);
+		return PTR_ERR(rpmsgtty_driver);
+	}
+
+	rpmsgtty_driver->driver_name = "rpmsg_tty";
+	rpmsgtty_driver->name = kasprintf(GFP_KERNEL, "ttyRPMSG%d", rpdev->dst);
+	rpmsgtty_driver->major = UNNAMED_MAJOR;
+	rpmsgtty_driver->minor_start = 0;
+	rpmsgtty_driver->type = TTY_DRIVER_TYPE_CONSOLE;
+	rpmsgtty_driver->init_termios = tty_std_termios;
+
+	tty_set_operations(rpmsgtty_driver, &imxrpmsgtty_ops);
+
+	tty_port_init(&cport->port);
+	cport->port.ops = &rpmsgtty_port_ops;
+	spin_lock_init(&cport->rx_lock);
+	cport->port.low_latency = cport->port.flags | ASYNC_LOW_LATENCY;
+	cport->rpdev = rpdev;
+	dev_set_drvdata(&rpdev->dev, cport);
+	rpmsgtty_driver->driver_state = cport;
+	cport->rpmsgtty_driver = rpmsgtty_driver;
+
+	ret = tty_register_driver(cport->rpmsgtty_driver);
+	if (ret < 0) {
+		pr_err("Couldn't install rpmsg tty driver: ret %d\n", ret);
+		goto error1;
+	} else {
+		pr_info("Install rpmsg tty driver!\n");
+	}
+
+	/*
+	 * send a message to our remote processor, and tell remote
+	 * processor about this channel
+	 */
+	ret = rpmsg_send(rpdev->ept, MSG, strlen(MSG));
+	if (ret) {
+		dev_err(&rpdev->dev, "rpmsg_send failed: %d\n", ret);
+		goto error;
+	}
+
+	return 0;
+
+error:
+	tty_unregister_driver(cport->rpmsgtty_driver);
+error1:
+	put_tty_driver(cport->rpmsgtty_driver);
+	tty_port_destroy(&cport->port);
+	cport->rpmsgtty_driver = NULL;
+	kfree(cport);
+
+	return ret;
+}
+
+static void rpmsg_tty_remove(struct rpmsg_device *rpdev)
+{
+	struct rpmsgtty_port *cport = dev_get_drvdata(&rpdev->dev);
+
+	dev_info(&rpdev->dev, "rpmsg tty driver is removed\n");
+
+	tty_unregister_driver(cport->rpmsgtty_driver);
+	kfree(cport->rpmsgtty_driver->name);
+	put_tty_driver(cport->rpmsgtty_driver);
+	tty_port_destroy(&cport->port);
+	cport->rpmsgtty_driver = NULL;
+}
+
+static struct rpmsg_device_id rpmsg_driver_tty_id_table[] = {
+	{ .name	= "rpmsg-virtual-tty-channel-1" },
+	{ .name	= "rpmsg-virtual-tty-channel" },
+	{ .name = "rpmsg-openamp-demo-channel" },
+	{ },
+};
+
+static struct rpmsg_driver rpmsg_tty_driver = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= rpmsg_driver_tty_id_table,
+	.probe		= rpmsg_tty_probe,
+	.callback	= rpmsg_tty_cb,
+	.remove		= rpmsg_tty_remove,
+};
+
+static int __init init(void)
+{
+	return register_rpmsg_driver(&rpmsg_tty_driver);
+}
+
+static void __exit fini(void)
+{
+	unregister_rpmsg_driver(&rpmsg_tty_driver);
+}
+module_init(init);
+module_exit(fini);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("iMX virtio remote processor messaging tty driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/rpmsg/qcom_glink_native.c b/drivers/rpmsg/qcom_glink_native.c
index 4840886532ff..7d7e809800ec 100644
--- a/drivers/rpmsg/qcom_glink_native.c
+++ b/drivers/rpmsg/qcom_glink_native.c
@@ -1333,6 +1333,20 @@ static int qcom_glink_trysend(struct rpmsg_endpoint *ept, void *data, int len)
 	return __qcom_glink_send(channel, data, len, false);
 }
 
+static int qcom_glink_sendto(struct rpmsg_endpoint *ept, void *data, int len, u32 dst)
+{
+	struct glink_channel *channel = to_glink_channel(ept);
+
+	return __qcom_glink_send(channel, data, len, true);
+}
+
+static int qcom_glink_trysendto(struct rpmsg_endpoint *ept, void *data, int len, u32 dst)
+{
+	struct glink_channel *channel = to_glink_channel(ept);
+
+	return __qcom_glink_send(channel, data, len, false);
+}
+
 /*
  * Finds the device_node for the glink child interested in this channel.
  */
@@ -1365,7 +1379,9 @@ static const struct rpmsg_device_ops glink_device_ops = {
 static const struct rpmsg_endpoint_ops glink_endpoint_ops = {
 	.destroy_ept = qcom_glink_destroy_ept,
 	.send = qcom_glink_send,
+	.sendto = qcom_glink_sendto,
 	.trysend = qcom_glink_trysend,
+	.trysendto = qcom_glink_trysendto,
 };
 
 static void qcom_glink_rpdev_release(struct device *dev)
@@ -1626,7 +1642,7 @@ static int qcom_glink_create_chrdev(struct qcom_glink *glink)
 	rpdev->dev.parent = glink->dev;
 	rpdev->dev.release = qcom_glink_device_release;
 
-	return rpmsg_chrdev_register_device(rpdev);
+	return rpmsg_ctrldev_register_device(rpdev);
 }
 
 struct qcom_glink *qcom_glink_native_probe(struct device *dev,
diff --git a/drivers/rpmsg/qcom_smd.c b/drivers/rpmsg/qcom_smd.c
index 19903de6268d..d223e438d17c 100644
--- a/drivers/rpmsg/qcom_smd.c
+++ b/drivers/rpmsg/qcom_smd.c
@@ -974,6 +974,20 @@ static int qcom_smd_trysend(struct rpmsg_endpoint *ept, void *data, int len)
 	return __qcom_smd_send(qsept->qsch, data, len, false);
 }
 
+static int qcom_smd_sendto(struct rpmsg_endpoint *ept, void *data, int len, u32 dst)
+{
+	struct qcom_smd_endpoint *qsept = to_smd_endpoint(ept);
+
+	return __qcom_smd_send(qsept->qsch, data, len, true);
+}
+
+static int qcom_smd_trysendto(struct rpmsg_endpoint *ept, void *data, int len, u32 dst)
+{
+	struct qcom_smd_endpoint *qsept = to_smd_endpoint(ept);
+
+	return __qcom_smd_send(qsept->qsch, data, len, false);
+}
+
 static __poll_t qcom_smd_poll(struct rpmsg_endpoint *ept,
 				  struct file *filp, poll_table *wait)
 {
@@ -1038,7 +1052,9 @@ static const struct rpmsg_device_ops qcom_smd_device_ops = {
 static const struct rpmsg_endpoint_ops qcom_smd_endpoint_ops = {
 	.destroy_ept = qcom_smd_destroy_ept,
 	.send = qcom_smd_send,
+	.sendto = qcom_smd_sendto,
 	.trysend = qcom_smd_trysend,
+	.trysendto = qcom_smd_trysendto,
 	.poll = qcom_smd_poll,
 };
 
@@ -1097,7 +1113,7 @@ static int qcom_smd_create_chrdev(struct qcom_smd_edge *edge)
 	qsdev->rpdev.dev.parent = &edge->dev;
 	qsdev->rpdev.dev.release = qcom_smd_release_device;
 
-	return rpmsg_chrdev_register_device(&qsdev->rpdev);
+	return rpmsg_ctrldev_register_device(&qsdev->rpdev);
 }
 
 /*
diff --git a/drivers/rpmsg/rpmsg_char.c b/drivers/rpmsg/rpmsg_char.c
index be90d77c5168..9588ac83a506 100644
--- a/drivers/rpmsg/rpmsg_char.c
+++ b/drivers/rpmsg/rpmsg_char.c
@@ -1,5 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0
 /*
+ * Copyright (C) 2021, STMicroelectronics
  * Copyright (c) 2016, Linaro Ltd.
  * Copyright (c) 2012, Michal Simek <monstr@monstr.eu>
  * Copyright (c) 2012, PetaLogix
@@ -22,35 +23,19 @@
 #include <linux/uaccess.h>
 #include <uapi/linux/rpmsg.h>
 
-#include "rpmsg_internal.h"
+#include "rpmsg_char.h"
 
-#define RPMSG_DEV_MAX	(MINORMASK + 1)
+#define RPMSG_CHAR_DEVNAME "rpmsg-raw"
 
 static dev_t rpmsg_major;
 static struct class *rpmsg_class;
 
-static DEFINE_IDA(rpmsg_ctrl_ida);
 static DEFINE_IDA(rpmsg_ept_ida);
 static DEFINE_IDA(rpmsg_minor_ida);
 
 #define dev_to_eptdev(dev) container_of(dev, struct rpmsg_eptdev, dev)
 #define cdev_to_eptdev(i_cdev) container_of(i_cdev, struct rpmsg_eptdev, cdev)
 
-#define dev_to_ctrldev(dev) container_of(dev, struct rpmsg_ctrldev, dev)
-#define cdev_to_ctrldev(i_cdev) container_of(i_cdev, struct rpmsg_ctrldev, cdev)
-
-/**
- * struct rpmsg_ctrldev - control device for instantiating endpoint devices
- * @rpdev:	underlaying rpmsg device
- * @cdev:	cdev for the ctrl device
- * @dev:	device for the ctrl device
- */
-struct rpmsg_ctrldev {
-	struct rpmsg_device *rpdev;
-	struct cdev cdev;
-	struct device dev;
-};
-
 /**
  * struct rpmsg_eptdev - endpoint device context
  * @dev:	endpoint device
@@ -62,6 +47,8 @@ struct rpmsg_ctrldev {
  * @queue_lock:	synchronization of @queue operations
  * @queue:	incoming message queue
  * @readq:	wait object for incoming queue
+ * @static_ept: specify if the endpoint has to be created at each device opening or
+ *              if the default endpoint should be used.
  */
 struct rpmsg_eptdev {
 	struct device dev;
@@ -76,9 +63,11 @@ struct rpmsg_eptdev {
 	spinlock_t queue_lock;
 	struct sk_buff_head queue;
 	wait_queue_head_t readq;
+
+	bool static_ept;
 };
 
-static int rpmsg_eptdev_destroy(struct device *dev, void *data)
+int rpmsg_chrdev_eptdev_destroy(struct device *dev, void *data)
 {
 	struct rpmsg_eptdev *eptdev = dev_to_eptdev(dev);
 
@@ -97,6 +86,7 @@ static int rpmsg_eptdev_destroy(struct device *dev, void *data)
 
 	return 0;
 }
+EXPORT_SYMBOL(rpmsg_chrdev_eptdev_destroy);
 
 static int rpmsg_ept_cb(struct rpmsg_device *rpdev, void *buf, int len,
 			void *priv, u32 addr)
@@ -127,17 +117,33 @@ static int rpmsg_eptdev_open(struct inode *inode, struct file *filp)
 	struct rpmsg_device *rpdev = eptdev->rpdev;
 	struct device *dev = &eptdev->dev;
 
+	mutex_lock(&eptdev->ept_lock);
+	if (eptdev->ept) {
+		mutex_unlock(&eptdev->ept_lock);
+		return -EBUSY;
+	}
+
 	get_device(dev);
 
-	ept = rpmsg_create_ept(rpdev, rpmsg_ept_cb, eptdev, eptdev->chinfo);
+	/*
+	 * If the static_ept is set to true, the rpmsg device default endpoint is used.
+	 * Else a new endpoint is created on open that will be destroyed on release.
+	 */
+	if (eptdev->static_ept)
+		ept = rpdev->ept;
+	else
+		ept = rpmsg_create_ept(rpdev, rpmsg_ept_cb, eptdev, eptdev->chinfo);
+
 	if (!ept) {
 		dev_err(dev, "failed to open %s\n", eptdev->chinfo.name);
 		put_device(dev);
+		mutex_unlock(&eptdev->ept_lock);
 		return -EINVAL;
 	}
 
 	eptdev->ept = ept;
 	filp->private_data = eptdev;
+	mutex_unlock(&eptdev->ept_lock);
 
 	return 0;
 }
@@ -150,7 +156,8 @@ static int rpmsg_eptdev_release(struct inode *inode, struct file *filp)
 	/* Close the endpoint, if it's not already destroyed by the parent */
 	mutex_lock(&eptdev->ept_lock);
 	if (eptdev->ept) {
-		rpmsg_destroy_ept(eptdev->ept);
+		if (!eptdev->static_ept)
+			rpmsg_destroy_ept(eptdev->ept);
 		eptdev->ept = NULL;
 	}
 	mutex_unlock(&eptdev->ept_lock);
@@ -239,9 +246,9 @@ static ssize_t rpmsg_eptdev_write_iter(struct kiocb *iocb,
 	}
 
 	if (filp->f_flags & O_NONBLOCK)
-		ret = rpmsg_trysend(eptdev->ept, kbuf, len);
+		ret = rpmsg_trysendto(eptdev->ept, kbuf, len, eptdev->chinfo.dst);
 	else
-		ret = rpmsg_send(eptdev->ept, kbuf, len);
+		ret = rpmsg_sendto(eptdev->ept, kbuf, len, eptdev->chinfo.dst);
 
 unlock_eptdev:
 	mutex_unlock(&eptdev->ept_lock);
@@ -277,7 +284,11 @@ static long rpmsg_eptdev_ioctl(struct file *fp, unsigned int cmd,
 	if (cmd != RPMSG_DESTROY_EPT_IOCTL)
 		return -EINVAL;
 
-	return rpmsg_eptdev_destroy(&eptdev->dev, NULL);
+	/* Don't allow to destroy a default endpoint. */
+	if (!eptdev->rpdev || eptdev->ept == eptdev->rpdev->ept)
+		return -EPERM;
+
+	return rpmsg_chrdev_eptdev_destroy(&eptdev->dev, NULL);
 }
 
 static const struct file_operations rpmsg_eptdev_fops = {
@@ -335,17 +346,17 @@ static void rpmsg_eptdev_release_device(struct device *dev)
 	kfree(eptdev);
 }
 
-static int rpmsg_eptdev_create(struct rpmsg_ctrldev *ctrldev,
-			       struct rpmsg_channel_info chinfo)
+static struct rpmsg_eptdev *__rpmsg_chrdev_eptdev_create(struct rpmsg_device *rpdev,
+							 struct device *parent,
+							 struct rpmsg_channel_info chinfo)
 {
-	struct rpmsg_device *rpdev = ctrldev->rpdev;
 	struct rpmsg_eptdev *eptdev;
 	struct device *dev;
 	int ret;
 
 	eptdev = kzalloc(sizeof(*eptdev), GFP_KERNEL);
 	if (!eptdev)
-		return -ENOMEM;
+		return ERR_PTR(-ENOMEM);
 
 	dev = &eptdev->dev;
 	eptdev->rpdev = rpdev;
@@ -358,7 +369,7 @@ static int rpmsg_eptdev_create(struct rpmsg_ctrldev *ctrldev,
 
 	device_initialize(dev);
 	dev->class = rpmsg_class;
-	dev->parent = &ctrldev->dev;
+	dev->parent = parent;
 	dev->groups = rpmsg_eptdev_groups;
 	dev_set_drvdata(dev, eptdev);
 
@@ -383,7 +394,14 @@ static int rpmsg_eptdev_create(struct rpmsg_ctrldev *ctrldev,
 	/* We can now rely on the release function for cleanup */
 	dev->release = rpmsg_eptdev_release_device;
 
-	return ret;
+	ret = device_add(dev);
+	if (ret) {
+		dev_err(dev, "device_add failed: %d\n", ret);
+		put_device(dev);
+		return ERR_PTR(ret);
+	}
+
+	return eptdev;
 
 free_ept_ida:
 	ida_simple_remove(&rpmsg_ept_ida, dev->id);
@@ -393,147 +411,82 @@ static int rpmsg_eptdev_create(struct rpmsg_ctrldev *ctrldev,
 	put_device(dev);
 	kfree(eptdev);
 
-	return ret;
-}
-
-static int rpmsg_ctrldev_open(struct inode *inode, struct file *filp)
-{
-	struct rpmsg_ctrldev *ctrldev = cdev_to_ctrldev(inode->i_cdev);
-
-	get_device(&ctrldev->dev);
-	filp->private_data = ctrldev;
-
-	return 0;
+	return ERR_PTR(ret);
 }
 
-static int rpmsg_ctrldev_release(struct inode *inode, struct file *filp)
+int rpmsg_chrdev_eptdev_create(struct rpmsg_device *rpdev, struct device *parent,
+			       struct rpmsg_channel_info chinfo)
 {
-	struct rpmsg_ctrldev *ctrldev = cdev_to_ctrldev(inode->i_cdev);
+	struct rpmsg_eptdev *eptdev;
 
-	put_device(&ctrldev->dev);
+	eptdev = __rpmsg_chrdev_eptdev_create(rpdev, parent, chinfo);
+	if (IS_ERR(eptdev))
+		return PTR_ERR(eptdev);
 
 	return 0;
 }
-
-static long rpmsg_ctrldev_ioctl(struct file *fp, unsigned int cmd,
-				unsigned long arg)
-{
-	struct rpmsg_ctrldev *ctrldev = fp->private_data;
-	void __user *argp = (void __user *)arg;
-	struct rpmsg_endpoint_info eptinfo;
-	struct rpmsg_channel_info chinfo;
-
-	if (cmd != RPMSG_CREATE_EPT_IOCTL)
-		return -EINVAL;
-
-	if (copy_from_user(&eptinfo, argp, sizeof(eptinfo)))
-		return -EFAULT;
-
-	memcpy(chinfo.name, eptinfo.name, RPMSG_NAME_SIZE);
-	chinfo.name[RPMSG_NAME_SIZE-1] = '\0';
-	chinfo.src = eptinfo.src;
-	chinfo.dst = eptinfo.dst;
-
-	return rpmsg_eptdev_create(ctrldev, chinfo);
-};
-
-static const struct file_operations rpmsg_ctrldev_fops = {
-	.owner = THIS_MODULE,
-	.open = rpmsg_ctrldev_open,
-	.release = rpmsg_ctrldev_release,
-	.unlocked_ioctl = rpmsg_ctrldev_ioctl,
-	.compat_ioctl = compat_ptr_ioctl,
-};
-
-static void rpmsg_ctrldev_release_device(struct device *dev)
-{
-	struct rpmsg_ctrldev *ctrldev = dev_to_ctrldev(dev);
-
-	ida_simple_remove(&rpmsg_ctrl_ida, dev->id);
-	ida_simple_remove(&rpmsg_minor_ida, MINOR(dev->devt));
-	kfree(ctrldev);
-}
+EXPORT_SYMBOL(rpmsg_chrdev_eptdev_create);
 
 static int rpmsg_chrdev_probe(struct rpmsg_device *rpdev)
 {
-	struct rpmsg_ctrldev *ctrldev;
-	struct device *dev;
-	int ret;
-
-	ctrldev = kzalloc(sizeof(*ctrldev), GFP_KERNEL);
-	if (!ctrldev)
-		return -ENOMEM;
-
-	ctrldev->rpdev = rpdev;
-
-	dev = &ctrldev->dev;
-	device_initialize(dev);
-	dev->parent = &rpdev->dev;
-	dev->class = rpmsg_class;
-
-	cdev_init(&ctrldev->cdev, &rpmsg_ctrldev_fops);
-	ctrldev->cdev.owner = THIS_MODULE;
-
-	ret = ida_simple_get(&rpmsg_minor_ida, 0, RPMSG_DEV_MAX, GFP_KERNEL);
-	if (ret < 0)
-		goto free_ctrldev;
-	dev->devt = MKDEV(MAJOR(rpmsg_major), ret);
-
-	ret = ida_simple_get(&rpmsg_ctrl_ida, 0, 0, GFP_KERNEL);
-	if (ret < 0)
-		goto free_minor_ida;
-	dev->id = ret;
-	dev_set_name(&ctrldev->dev, "rpmsg_ctrl%d", ret);
+	struct rpmsg_channel_info chinfo;
+	struct rpmsg_eptdev *eptdev;
+	struct rpmsg_endpoint *ept;
 
-	ret = cdev_device_add(&ctrldev->cdev, &ctrldev->dev);
-	if (ret)
-		goto free_ctrl_ida;
+	memcpy(chinfo.name, RPMSG_CHAR_DEVNAME, sizeof(RPMSG_CHAR_DEVNAME));
+	chinfo.src = rpdev->src;
+	chinfo.dst = rpdev->dst;
 
-	/* We can now rely on the release function for cleanup */
-	dev->release = rpmsg_ctrldev_release_device;
+	eptdev =  __rpmsg_chrdev_eptdev_create(rpdev, &rpdev->dev, chinfo);
+	if (IS_ERR(eptdev))
+		return PTR_ERR(eptdev);
 
-	dev_set_drvdata(&rpdev->dev, ctrldev);
+	/*
+	 * Create the default endpoint associated to the rpmsg device and provide rpmsg_eptdev
+	 * structure as callback private data.
+	 */
+	ept = rpmsg_create_default_ept(rpdev, rpmsg_ept_cb, eptdev, eptdev->chinfo);
+	if (!ept) {
+		dev_err(&rpdev->dev, "failed to create %s\n", eptdev->chinfo.name);
+		put_device(&eptdev->dev);
+		return -EINVAL;
+	}
 
-	return ret;
+	/*
+	 * Do not allow the creation and release of an endpoint on /dev/rpmsgX open and close,
+	 * reuse the default endpoint instead
+	 */
+	eptdev->static_ept = true;
 
-free_ctrl_ida:
-	ida_simple_remove(&rpmsg_ctrl_ida, dev->id);
-free_minor_ida:
-	ida_simple_remove(&rpmsg_minor_ida, MINOR(dev->devt));
-free_ctrldev:
-	put_device(dev);
-	kfree(ctrldev);
-
-	return ret;
+	return 0;
 }
 
 static void rpmsg_chrdev_remove(struct rpmsg_device *rpdev)
 {
-	struct rpmsg_ctrldev *ctrldev = dev_get_drvdata(&rpdev->dev);
 	int ret;
 
-	/* Destroy all endpoints */
-	ret = device_for_each_child(&ctrldev->dev, NULL, rpmsg_eptdev_destroy);
+	ret = device_for_each_child(&rpdev->dev, NULL, rpmsg_chrdev_eptdev_destroy);
 	if (ret)
-		dev_warn(&rpdev->dev, "failed to nuke endpoints: %d\n", ret);
-
-	cdev_device_del(&ctrldev->cdev, &ctrldev->dev);
-	put_device(&ctrldev->dev);
+		dev_warn(&rpdev->dev, "failed to destroy endpoints: %d\n", ret);
 }
 
+static struct rpmsg_device_id rpmsg_chrdev_id_table[] = {
+	{ .name	= RPMSG_CHAR_DEVNAME },
+	{ },
+};
+
 static struct rpmsg_driver rpmsg_chrdev_driver = {
 	.probe = rpmsg_chrdev_probe,
 	.remove = rpmsg_chrdev_remove,
-	.drv = {
-		.name = "rpmsg_chrdev",
-	},
+	.id_table = rpmsg_chrdev_id_table,
+	.drv.name = "rpmsg_chrdev",
 };
 
-static int rpmsg_char_init(void)
+static int rpmsg_chrdev_init(void)
 {
 	int ret;
 
-	ret = alloc_chrdev_region(&rpmsg_major, 0, RPMSG_DEV_MAX, "rpmsg");
+	ret = alloc_chrdev_region(&rpmsg_major, 0, RPMSG_DEV_MAX, "rpmsg_char");
 	if (ret < 0) {
 		pr_err("rpmsg: failed to allocate char dev region\n");
 		return ret;
@@ -542,20 +495,26 @@ static int rpmsg_char_init(void)
 	rpmsg_class = class_create(THIS_MODULE, "rpmsg");
 	if (IS_ERR(rpmsg_class)) {
 		pr_err("failed to create rpmsg class\n");
-		unregister_chrdev_region(rpmsg_major, RPMSG_DEV_MAX);
-		return PTR_ERR(rpmsg_class);
+		ret = PTR_ERR(rpmsg_class);
+		goto free_region;
 	}
 
 	ret = register_rpmsg_driver(&rpmsg_chrdev_driver);
 	if (ret < 0) {
-		pr_err("rpmsgchr: failed to register rpmsg driver\n");
-		class_destroy(rpmsg_class);
-		unregister_chrdev_region(rpmsg_major, RPMSG_DEV_MAX);
+		pr_err("rpmsg: failed to register rpmsg raw driver\n");
+		goto free_class;
 	}
 
+	return 0;
+
+free_class:
+	class_destroy(rpmsg_class);
+free_region:
+	unregister_chrdev_region(rpmsg_major, RPMSG_DEV_MAX);
+
 	return ret;
 }
-postcore_initcall(rpmsg_char_init);
+postcore_initcall(rpmsg_chrdev_init);
 
 static void rpmsg_chrdev_exit(void)
 {
diff --git a/drivers/rpmsg/rpmsg_char.h b/drivers/rpmsg/rpmsg_char.h
new file mode 100644
index 000000000000..c328eb250b87
--- /dev/null
+++ b/drivers/rpmsg/rpmsg_char.h
@@ -0,0 +1,51 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+ * Copyright (C) STMicroelectronics 2021.
+ */
+
+#ifndef __RPMSG_CHRDEV_H__
+#define __RPMSG_CHRDEV_H__
+
+#define RPMSG_DEV_MAX	(MINORMASK + 1)
+
+#if IS_REACHABLE(CONFIG_RPMSG_CHAR)
+/**
+ * rpmsg_chrdev_eptdev_create() - register char device based on an endpoint
+ * @rpdev:  prepared rpdev to be used for creating endpoints
+ * @parent: parent device
+ * @chinfo: associated endpoint channel information.
+ *
+ * This function create a new rpmsg char endpoint device to instantiate a new
+ * endpoint based on chinfo information.
+ */
+int rpmsg_chrdev_eptdev_create(struct rpmsg_device *rpdev, struct device *parent,
+			       struct rpmsg_channel_info chinfo);
+
+/**
+ * rpmsg_chrdev_eptdev_destroy() - destroy created char device endpoint.
+ * @data: private data associated to the endpoint device
+ *
+ * This function destroys a rpmsg char endpoint device created by the RPMSG_DESTROY_EPT_IOCTL
+ * control.
+ */
+int rpmsg_chrdev_eptdev_destroy(struct device *dev, void *data);
+
+#else  /*IS_REACHABLE(CONFIG_RPMSG_CHAR) */
+
+static inline int rpmsg_chrdev_eptdev_create(struct rpmsg_device *rpdev, struct device *parent,
+					     struct rpmsg_channel_info chinfo)
+{
+	return -EINVAL;
+}
+
+static inline int rpmsg_chrdev_eptdev_destroy(struct device *dev, void *data)
+{
+	/* This shouldn't be possible */
+	WARN_ON(1);
+
+	return 0;
+}
+
+#endif /*IS_REACHABLE(CONFIG_RPMSG_CHAR) */
+
+#endif /*__RPMSG_CHRDEV_H__ */
diff --git a/drivers/rpmsg/rpmsg_core.c b/drivers/rpmsg/rpmsg_core.c
index 028ca5961bc2..3ec86afb2a30 100644
--- a/drivers/rpmsg/rpmsg_core.c
+++ b/drivers/rpmsg/rpmsg_core.c
@@ -20,6 +20,50 @@
 
 #include "rpmsg_internal.h"
 
+/**
+ * rpmsg_create_channel() - create a new rpmsg channel
+ * using its name and address info.
+ * @rpdev: rpmsg device
+ * @chinfo: channel_info to bind
+ *
+ * Returns a pointer to the new rpmsg device on success, or NULL on error.
+ */
+struct rpmsg_device *rpmsg_create_channel(struct rpmsg_device *rpdev,
+					  struct rpmsg_channel_info *chinfo)
+{
+	if (WARN_ON(!rpdev))
+		return NULL;
+	if (!rpdev->ops || !rpdev->ops->create_channel) {
+		dev_err(&rpdev->dev, "no create_channel ops found\n");
+		return NULL;
+	}
+
+	return rpdev->ops->create_channel(rpdev, chinfo);
+}
+EXPORT_SYMBOL(rpmsg_create_channel);
+
+/**
+ * rpmsg_release_channel() - release a rpmsg channel
+ * using its name and address info.
+ * @rpdev: rpmsg device
+ * @chinfo: channel_info to bind
+ *
+ * Returns 0 on success or an appropriate error value.
+ */
+int rpmsg_release_channel(struct rpmsg_device *rpdev,
+			  struct rpmsg_channel_info *chinfo)
+{
+	if (WARN_ON(!rpdev))
+		return -EINVAL;
+	if (!rpdev->ops || !rpdev->ops->release_channel) {
+		dev_err(&rpdev->dev, "no release_channel ops found\n");
+		return -ENXIO;
+	}
+
+	return rpdev->ops->release_channel(rpdev, chinfo);
+}
+EXPORT_SYMBOL(rpmsg_release_channel);
+
 /**
  * rpmsg_create_ept() - create a new rpmsg_endpoint
  * @rpdev: rpmsg channel device
@@ -71,6 +115,57 @@ struct rpmsg_endpoint *rpmsg_create_ept(struct rpmsg_device *rpdev,
 }
 EXPORT_SYMBOL(rpmsg_create_ept);
 
+/**
+ * rpmsg_create_default_ept() - create a default rpmsg_endpoint for a rpmsg device
+ * @rpdev: rpmsg channel device
+ * @cb: rx callback handler
+ * @priv: private data for the driver's use
+ * @chinfo: channel_info with the local rpmsg address to bind with @cb
+ *
+ * On register_rpmsg_driver if no callback is provided in the rpmsg_driver structure,
+ * no endpoint is created when the device is probed by the rpmsg bus.
+ *
+ * This function returns a pointer to the default endpoint if already created or creates
+ * a endpoint and assign it as the default endpoint of the rpmsg device.
+ *
+ * Drivers should provide their @rpdev channel (so the new endpoint would belong
+ * to the same remote processor their channel belongs to), an rx callback
+ * function, an optional private data (which is provided back when the
+ * rx callback is invoked), and an address they want to bind with the
+ * callback. If @addr is RPMSG_ADDR_ANY, then rpmsg_create_ept will
+ * dynamically assign them an available rpmsg address (drivers should have
+ * a very good reason why not to always use RPMSG_ADDR_ANY here).
+ *
+ * Returns a pointer to the endpoint on success, or NULL on error.
+ */
+struct rpmsg_endpoint *rpmsg_create_default_ept(struct rpmsg_device *rpdev,
+						rpmsg_rx_cb_t cb, void *priv,
+						struct rpmsg_channel_info chinfo)
+{
+	struct rpmsg_endpoint *ept;
+
+	if (WARN_ON(!rpdev))
+		return NULL;
+
+	/* It does not make sense to create a default  endpoint without a callback. */
+	if (!cb)
+		return NULL;
+
+	if (rpdev->ept)
+		return rpdev->ept;
+
+	ept = rpdev->ops->create_ept(rpdev, cb, priv, chinfo);
+	if (!ept)
+		return NULL;
+
+	/* Assign the new endpoint as default endpoint */
+	rpdev->ept = ept;
+	rpdev->src = ept->addr;
+
+	return ept;
+}
+EXPORT_SYMBOL(rpmsg_create_default_ept);
+
 /**
  * rpmsg_destroy_ept() - destroy an existing rpmsg endpoint
  * @ept: endpoing to destroy
diff --git a/drivers/rpmsg/rpmsg_ctrl.c b/drivers/rpmsg/rpmsg_ctrl.c
new file mode 100644
index 000000000000..eeb1708548c1
--- /dev/null
+++ b/drivers/rpmsg/rpmsg_ctrl.c
@@ -0,0 +1,215 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2021, STMicroelectronics
+ * Copyright (c) 2016, Linaro Ltd.
+ * Copyright (c) 2012, Michal Simek <monstr@monstr.eu>
+ * Copyright (c) 2012, PetaLogix
+ * Copyright (c) 2011, Texas Instruments, Inc.
+ * Copyright (c) 2011, Google, Inc.
+ *
+ * Based on rpmsg performance statistics driver by Michal Simek, which in turn
+ * was based on TI & Google OMX rpmsg driver.
+ */
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/idr.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/rpmsg.h>
+#include <linux/skbuff.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <uapi/linux/rpmsg.h>
+
+#include "rpmsg_char.h"
+
+static dev_t rpmsg_major;
+
+static DEFINE_IDA(rpmsg_ctrl_ida);
+static DEFINE_IDA(rpmsg_minor_ida);
+
+#define dev_to_ctrldev(dev) container_of(dev, struct rpmsg_ctrldev, dev)
+#define cdev_to_ctrldev(i_cdev) container_of(i_cdev, struct rpmsg_ctrldev, cdev)
+
+/**
+ * struct rpmsg_ctrldev - control device for instantiating endpoint devices
+ * @rpdev:	underlaying rpmsg device
+ * @cdev:	cdev for the ctrl device
+ * @dev:	device for the ctrl device
+ */
+struct rpmsg_ctrldev {
+	struct rpmsg_device *rpdev;
+	struct cdev cdev;
+	struct device dev;
+};
+
+static int rpmsg_ctrldev_open(struct inode *inode, struct file *filp)
+{
+	struct rpmsg_ctrldev *ctrldev = cdev_to_ctrldev(inode->i_cdev);
+
+	get_device(&ctrldev->dev);
+	filp->private_data = ctrldev;
+
+	return 0;
+}
+
+static int rpmsg_ctrldev_release(struct inode *inode, struct file *filp)
+{
+	struct rpmsg_ctrldev *ctrldev = cdev_to_ctrldev(inode->i_cdev);
+
+	put_device(&ctrldev->dev);
+
+	return 0;
+}
+
+static long rpmsg_ctrldev_ioctl(struct file *fp, unsigned int cmd,
+				unsigned long arg)
+{
+	struct rpmsg_ctrldev *ctrldev = fp->private_data;
+	void __user *argp = (void __user *)arg;
+	struct rpmsg_endpoint_info eptinfo;
+	struct rpmsg_channel_info chinfo;
+
+	if (cmd != RPMSG_CREATE_EPT_IOCTL)
+		return -EINVAL;
+
+	if (copy_from_user(&eptinfo, argp, sizeof(eptinfo)))
+		return -EFAULT;
+
+	memcpy(chinfo.name, eptinfo.name, RPMSG_NAME_SIZE);
+	chinfo.name[RPMSG_NAME_SIZE - 1] = '\0';
+	chinfo.src = eptinfo.src;
+	chinfo.dst = eptinfo.dst;
+
+	return rpmsg_chrdev_eptdev_create(ctrldev->rpdev, &ctrldev->dev, chinfo);
+};
+
+static const struct file_operations rpmsg_ctrldev_fops = {
+	.owner = THIS_MODULE,
+	.open = rpmsg_ctrldev_open,
+	.release = rpmsg_ctrldev_release,
+	.unlocked_ioctl = rpmsg_ctrldev_ioctl,
+	.compat_ioctl = compat_ptr_ioctl,
+};
+
+static void rpmsg_ctrldev_release_device(struct device *dev)
+{
+	struct rpmsg_ctrldev *ctrldev = dev_to_ctrldev(dev);
+
+	ida_simple_remove(&rpmsg_ctrl_ida, dev->id);
+	ida_simple_remove(&rpmsg_minor_ida, MINOR(dev->devt));
+	cdev_del(&ctrldev->cdev);
+	kfree(ctrldev);
+}
+
+static int rpmsg_ctrldev_probe(struct rpmsg_device *rpdev)
+{
+	struct rpmsg_ctrldev *ctrldev;
+	struct device *dev;
+	int ret;
+
+	ctrldev = kzalloc(sizeof(*ctrldev), GFP_KERNEL);
+	if (!ctrldev)
+		return -ENOMEM;
+
+	ctrldev->rpdev = rpdev;
+
+	dev = &ctrldev->dev;
+	device_initialize(dev);
+	dev->parent = &rpdev->dev;
+
+	cdev_init(&ctrldev->cdev, &rpmsg_ctrldev_fops);
+	ctrldev->cdev.owner = THIS_MODULE;
+
+	ret = ida_simple_get(&rpmsg_minor_ida, 0, RPMSG_DEV_MAX, GFP_KERNEL);
+	if (ret < 0)
+		goto free_ctrldev;
+	dev->devt = MKDEV(MAJOR(rpmsg_major), ret);
+
+	ret = ida_simple_get(&rpmsg_ctrl_ida, 0, 0, GFP_KERNEL);
+	if (ret < 0)
+		goto free_minor_ida;
+	dev->id = ret;
+	dev_set_name(&ctrldev->dev, "rpmsg_ctrl%d", ret);
+
+	ret = cdev_add(&ctrldev->cdev, dev->devt, 1);
+	if (ret)
+		goto free_ctrl_ida;
+
+	/* We can now rely on the release function for cleanup */
+	dev->release = rpmsg_ctrldev_release_device;
+
+	ret = device_add(dev);
+	if (ret) {
+		dev_err(&rpdev->dev, "device_add failed: %d\n", ret);
+		put_device(dev);
+	}
+
+	dev_set_drvdata(&rpdev->dev, ctrldev);
+
+	return ret;
+
+free_ctrl_ida:
+	ida_simple_remove(&rpmsg_ctrl_ida, dev->id);
+free_minor_ida:
+	ida_simple_remove(&rpmsg_minor_ida, MINOR(dev->devt));
+free_ctrldev:
+	put_device(dev);
+	kfree(ctrldev);
+
+	return ret;
+}
+
+static void rpmsg_ctrldev_remove(struct rpmsg_device *rpdev)
+{
+	struct rpmsg_ctrldev *ctrldev = dev_get_drvdata(&rpdev->dev);
+	int ret;
+
+	/* Destroy all endpoints */
+	ret = device_for_each_child(&ctrldev->dev, NULL, rpmsg_chrdev_eptdev_destroy);
+	if (ret)
+		dev_warn(&rpdev->dev, "failed to nuke endpoints: %d\n", ret);
+
+	device_del(&ctrldev->dev);
+	put_device(&ctrldev->dev);
+}
+
+static struct rpmsg_driver rpmsg_ctrldev_driver = {
+	.probe = rpmsg_ctrldev_probe,
+	.remove = rpmsg_ctrldev_remove,
+	.drv = {
+		.name = "rpmsg_ctrl",
+	},
+};
+
+static int rpmsg_ctrldev_init(void)
+{
+	int ret;
+
+	ret = alloc_chrdev_region(&rpmsg_major, 0, RPMSG_DEV_MAX, "rpmsg_ctrl");
+	if (ret < 0) {
+		pr_err("rpmsg: failed to allocate char dev region\n");
+		return ret;
+	}
+
+	ret = register_rpmsg_driver(&rpmsg_ctrldev_driver);
+	if (ret < 0) {
+		pr_err("rpmsg ctrl: failed to register rpmsg driver\n");
+		unregister_chrdev_region(rpmsg_major, RPMSG_DEV_MAX);
+	}
+
+	return ret;
+}
+postcore_initcall(rpmsg_ctrldev_init);
+
+static void rpmsg_ctrldev_exit(void)
+{
+	unregister_rpmsg_driver(&rpmsg_ctrldev_driver);
+	unregister_chrdev_region(rpmsg_major, RPMSG_DEV_MAX);
+}
+module_exit(rpmsg_ctrldev_exit);
+
+MODULE_DESCRIPTION("rpmsg control interface");
+MODULE_ALIAS("rpmsg:" KBUILD_MODNAME);
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/rpmsg/rpmsg_internal.h b/drivers/rpmsg/rpmsg_internal.h
index 3fc83cd50e98..ccef9f56c88e 100644
--- a/drivers/rpmsg/rpmsg_internal.h
+++ b/drivers/rpmsg/rpmsg_internal.h
@@ -20,6 +20,8 @@
 
 /**
  * struct rpmsg_device_ops - indirection table for the rpmsg_device operations
+ * @create_channel:	create backend-specific channel, optional
+ * @release_channel:	release backend-specific channel, optional
  * @create_ept:		create backend-specific endpoint, required
  * @announce_create:	announce presence of new channel, optional
  * @announce_destroy:	announce destruction of channel, optional
@@ -29,6 +31,10 @@
  * advertise new channels implicitly by creating the endpoints.
  */
 struct rpmsg_device_ops {
+	struct rpmsg_device *(*create_channel)(struct rpmsg_device *rpdev,
+					       struct rpmsg_channel_info *chinfo);
+	int (*release_channel)(struct rpmsg_device *rpdev,
+			       struct rpmsg_channel_info *chinfo);
 	struct rpmsg_endpoint *(*create_ept)(struct rpmsg_device *rpdev,
 					    rpmsg_rx_cb_t cb, void *priv,
 					    struct rpmsg_channel_info chinfo);
@@ -75,17 +81,21 @@ int rpmsg_unregister_device(struct device *parent,
 struct device *rpmsg_find_device(struct device *parent,
 				 struct rpmsg_channel_info *chinfo);
 
+struct rpmsg_device *rpmsg_create_channel(struct rpmsg_device *rpdev,
+					  struct rpmsg_channel_info *chinfo);
+int rpmsg_release_channel(struct rpmsg_device *rpdev,
+			  struct rpmsg_channel_info *chinfo);
 /**
- * rpmsg_chrdev_register_device() - register chrdev device based on rpdev
+ * rpmsg_ctrldev_register_device() - register a char device for control based on rpdev
  * @rpdev:	prepared rpdev to be used for creating endpoints
  *
  * This function wraps rpmsg_register_device() preparing the rpdev for use as
  * basis for the rpmsg chrdev.
  */
-static inline int rpmsg_chrdev_register_device(struct rpmsg_device *rpdev)
+static inline int rpmsg_ctrldev_register_device(struct rpmsg_device *rpdev)
 {
-	strcpy(rpdev->id.name, "rpmsg_chrdev");
-	rpdev->driver_override = "rpmsg_chrdev";
+	strcpy(rpdev->id.name, "rpmsg_ctrl");
+	rpdev->driver_override = "rpmsg_ctrl";
 
 	return rpmsg_register_device(rpdev);
 }
diff --git a/drivers/rpmsg/rpmsg_ns.c b/drivers/rpmsg/rpmsg_ns.c
new file mode 100644
index 000000000000..762ff1ae279f
--- /dev/null
+++ b/drivers/rpmsg/rpmsg_ns.c
@@ -0,0 +1,126 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) STMicroelectronics 2020 - All Rights Reserved
+ */
+#include <linux/device.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/rpmsg.h>
+#include <linux/rpmsg/ns.h>
+#include <linux/slab.h>
+
+#include "rpmsg_internal.h"
+
+/**
+ * rpmsg_ns_register_device() - register name service device based on rpdev
+ * @rpdev: prepared rpdev to be used for creating endpoints
+ *
+ * This function wraps rpmsg_register_device() preparing the rpdev for use as
+ * basis for the rpmsg name service device.
+ */
+int rpmsg_ns_register_device(struct rpmsg_device *rpdev)
+{
+	strcpy(rpdev->id.name, "rpmsg_ns");
+	rpdev->driver_override = "rpmsg_ns";
+	rpdev->src = RPMSG_NS_ADDR;
+	rpdev->dst = RPMSG_NS_ADDR;
+
+	return rpmsg_register_device(rpdev);
+}
+EXPORT_SYMBOL(rpmsg_ns_register_device);
+
+/* invoked when a name service announcement arrives */
+static int rpmsg_ns_cb(struct rpmsg_device *rpdev, void *data, int len,
+		       void *priv, u32 src)
+{
+	struct rpmsg_ns_msg *msg = data;
+	struct rpmsg_device *newch;
+	struct rpmsg_channel_info chinfo;
+	struct device *dev = rpdev->dev.parent;
+	int ret;
+
+#if defined(CONFIG_DYNAMIC_DEBUG)
+	dynamic_hex_dump("NS announcement: ", DUMP_PREFIX_NONE, 16, 1,
+			 data, len, true);
+#endif
+
+	if (len != sizeof(*msg)) {
+		dev_err(dev, "malformed ns msg (%d)\n", len);
+		return -EINVAL;
+	}
+
+	/* don't trust the remote processor for null terminating the name */
+	msg->name[RPMSG_NAME_SIZE - 1] = '\0';
+
+	strncpy(chinfo.name, msg->name, sizeof(chinfo.name));
+	chinfo.src = RPMSG_ADDR_ANY;
+	chinfo.dst = rpmsg32_to_cpu(rpdev, msg->addr);
+
+	dev_info(dev, "%sing channel %s addr 0x%x\n",
+		 rpmsg32_to_cpu(rpdev, msg->flags) & RPMSG_NS_DESTROY ?
+		 "destroy" : "creat", msg->name, chinfo.dst);
+
+	if (rpmsg32_to_cpu(rpdev, msg->flags) & RPMSG_NS_DESTROY) {
+		ret = rpmsg_release_channel(rpdev, &chinfo);
+		if (ret)
+			dev_err(dev, "rpmsg_destroy_channel failed: %d\n", ret);
+	} else {
+		newch = rpmsg_create_channel(rpdev, &chinfo);
+		if (!newch)
+			dev_err(dev, "rpmsg_create_channel failed\n");
+	}
+
+	return 0;
+}
+
+static int rpmsg_ns_probe(struct rpmsg_device *rpdev)
+{
+	struct rpmsg_endpoint *ns_ept;
+	struct rpmsg_channel_info ns_chinfo = {
+		.src = RPMSG_NS_ADDR,
+		.dst = RPMSG_NS_ADDR,
+		.name = "name_service",
+	};
+
+	/*
+	 * Create the NS announcement service endpoint associated to the RPMsg
+	 * device. The endpoint will be automatically destroyed when the RPMsg
+	 * device will be deleted.
+	 */
+	ns_ept = rpmsg_create_ept(rpdev, rpmsg_ns_cb, NULL, ns_chinfo);
+	if (!ns_ept) {
+		dev_err(&rpdev->dev, "failed to create the ns ept\n");
+		return -ENOMEM;
+	}
+	rpdev->ept = ns_ept;
+
+	return 0;
+}
+
+static struct rpmsg_driver rpmsg_ns_driver = {
+	.drv.name = KBUILD_MODNAME,
+	.probe = rpmsg_ns_probe,
+};
+
+static int rpmsg_ns_init(void)
+{
+	int ret;
+
+	ret = register_rpmsg_driver(&rpmsg_ns_driver);
+	if (ret < 0)
+		pr_err("%s: Failed to register rpmsg driver\n", __func__);
+
+	return ret;
+}
+postcore_initcall(rpmsg_ns_init);
+
+static void rpmsg_ns_exit(void)
+{
+	unregister_rpmsg_driver(&rpmsg_ns_driver);
+}
+module_exit(rpmsg_ns_exit);
+
+MODULE_DESCRIPTION("Name service announcement rpmsg driver");
+MODULE_AUTHOR("Arnaud Pouliquen <arnaud.pouliquen@st.com>");
+MODULE_ALIAS("rpmsg:" KBUILD_MODNAME);
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/rpmsg/virtio_rpmsg_bus.c b/drivers/rpmsg/virtio_rpmsg_bus.c
index 7d7ed4e5cce7..a8d70ba5675d 100644
--- a/drivers/rpmsg/virtio_rpmsg_bus.c
+++ b/drivers/rpmsg/virtio_rpmsg_bus.c
@@ -19,11 +19,12 @@
 #include <linux/mutex.h>
 #include <linux/of_device.h>
 #include <linux/rpmsg.h>
+#include <linux/rpmsg/byteorder.h>
+#include <linux/rpmsg/ns.h>
 #include <linux/scatterlist.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
 #include <linux/virtio.h>
-#include <linux/virtio_byteorder.h>
 #include <linux/virtio_ids.h>
 #include <linux/virtio_config.h>
 #include <linux/wait.h>
@@ -48,7 +49,6 @@
  * @endpoints_lock: lock of the endpoints set
  * @sendq:	wait queue of sending contexts waiting for a tx buffers
  * @sleepers:	number of senders that are waiting for a tx buffer
- * @ns_ept:	the bus's name service endpoint
  *
  * This structure stores the rpmsg state of a given virtio remote processor
  * device (there might be several virtio proc devices for each physical
@@ -67,7 +67,6 @@ struct virtproc_info {
 	struct mutex endpoints_lock;
 	wait_queue_head_t sendq;
 	atomic_t sleepers;
-	struct rpmsg_endpoint *ns_ept;
 };
 
 /* The feature bitmap for virtio rpmsg */
@@ -85,43 +84,14 @@ struct virtproc_info {
  * Every message sent(/received) on the rpmsg bus begins with this header.
  */
 struct rpmsg_hdr {
-	__virtio32 src;
-	__virtio32 dst;
-	__virtio32 reserved;
-	__virtio16 len;
-	__virtio16 flags;
+	__rpmsg32 src;
+	__rpmsg32 dst;
+	__rpmsg32 reserved;
+	__rpmsg16 len;
+	__rpmsg16 flags;
 	u8 data[];
 } __packed;
 
-/**
- * struct rpmsg_ns_msg - dynamic name service announcement message
- * @name: name of remote service that is published
- * @addr: address of remote service that is published
- * @flags: indicates whether service is created or destroyed
- *
- * This message is sent across to publish a new service, or announce
- * about its removal. When we receive these messages, an appropriate
- * rpmsg channel (i.e device) is created/destroyed. In turn, the ->probe()
- * or ->remove() handler of the appropriate rpmsg driver will be invoked
- * (if/as-soon-as one is registered).
- */
-struct rpmsg_ns_msg {
-	char name[RPMSG_NAME_SIZE];
-	__virtio32 addr;
-	__virtio32 flags;
-} __packed;
-
-/**
- * enum rpmsg_ns_flags - dynamic name service announcement flags
- *
- * @RPMSG_NS_CREATE: a new remote service was just created
- * @RPMSG_NS_DESTROY: a known remote service was just destroyed
- */
-enum rpmsg_ns_flags {
-	RPMSG_NS_CREATE		= 0,
-	RPMSG_NS_DESTROY	= 1,
-};
-
 /**
  * struct virtio_rpmsg_channel - rpmsg channel descriptor
  * @rpdev: the rpmsg channel device
@@ -167,9 +137,6 @@ struct virtio_rpmsg_channel {
  */
 #define RPMSG_RESERVED_ADDRESSES	(1024)
 
-/* Address 53 is reserved for advertising remote services */
-#define RPMSG_NS_ADDR			(53)
-
 static void virtio_rpmsg_destroy_ept(struct rpmsg_endpoint *ept);
 static int virtio_rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len);
 static int virtio_rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len,
@@ -181,6 +148,8 @@ static int virtio_rpmsg_trysendto(struct rpmsg_endpoint *ept, void *data,
 				  int len, u32 dst);
 static int virtio_rpmsg_trysend_offchannel(struct rpmsg_endpoint *ept, u32 src,
 					   u32 dst, void *data, int len);
+static struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,
+						   struct rpmsg_channel_info *chinfo);
 
 static const struct rpmsg_endpoint_ops virtio_endpoint_ops = {
 	.destroy_ept = virtio_rpmsg_destroy_ept,
@@ -285,6 +254,24 @@ static struct rpmsg_endpoint *__rpmsg_create_ept(struct virtproc_info *vrp,
 	return NULL;
 }
 
+static struct rpmsg_device *virtio_rpmsg_create_channel(struct rpmsg_device *rpdev,
+							struct rpmsg_channel_info *chinfo)
+{
+	struct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);
+	struct virtproc_info *vrp = vch->vrp;
+
+	return __rpmsg_create_channel(vrp, chinfo);
+}
+
+static int virtio_rpmsg_release_channel(struct rpmsg_device *rpdev,
+					struct rpmsg_channel_info *chinfo)
+{
+	struct virtio_rpmsg_channel *vch = to_virtio_rpmsg_channel(rpdev);
+	struct virtproc_info *vrp = vch->vrp;
+
+	return rpmsg_unregister_device(&vrp->vdev->dev, chinfo);
+}
+
 static struct rpmsg_endpoint *virtio_rpmsg_create_ept(struct rpmsg_device *rpdev,
 						      rpmsg_rx_cb_t cb,
 						      void *priv,
@@ -341,8 +328,8 @@ static int virtio_rpmsg_announce_create(struct rpmsg_device *rpdev)
 		struct rpmsg_ns_msg nsm;
 
 		strncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);
-		nsm.addr = cpu_to_virtio32(vrp->vdev, rpdev->ept->addr);
-		nsm.flags = cpu_to_virtio32(vrp->vdev, RPMSG_NS_CREATE);
+		nsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);
+		nsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_CREATE);
 
 		err = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);
 		if (err)
@@ -365,8 +352,8 @@ static int virtio_rpmsg_announce_destroy(struct rpmsg_device *rpdev)
 		struct rpmsg_ns_msg nsm;
 
 		strncpy(nsm.name, rpdev->id.name, RPMSG_NAME_SIZE);
-		nsm.addr = cpu_to_virtio32(vrp->vdev, rpdev->ept->addr);
-		nsm.flags = cpu_to_virtio32(vrp->vdev, RPMSG_NS_DESTROY);
+		nsm.addr = cpu_to_rpmsg32(rpdev, rpdev->ept->addr);
+		nsm.flags = cpu_to_rpmsg32(rpdev, RPMSG_NS_DESTROY);
 
 		err = rpmsg_sendto(rpdev->ept, &nsm, sizeof(nsm), RPMSG_NS_ADDR);
 		if (err)
@@ -377,6 +364,8 @@ static int virtio_rpmsg_announce_destroy(struct rpmsg_device *rpdev)
 }
 
 static const struct rpmsg_device_ops virtio_rpmsg_ops = {
+	.create_channel = virtio_rpmsg_create_channel,
+	.release_channel = virtio_rpmsg_release_channel,
 	.create_ept = virtio_rpmsg_create_ept,
 	.announce_create = virtio_rpmsg_announce_create,
 	.announce_destroy = virtio_rpmsg_announce_destroy,
@@ -395,8 +384,8 @@ static void virtio_rpmsg_release_device(struct device *dev)
  * this function will be used to create both static and dynamic
  * channels.
  */
-static struct rpmsg_device *rpmsg_create_channel(struct virtproc_info *vrp,
-						 struct rpmsg_channel_info *chinfo)
+static struct rpmsg_device *__rpmsg_create_channel(struct virtproc_info *vrp,
+						   struct rpmsg_channel_info *chinfo)
 {
 	struct virtio_rpmsg_channel *vch;
 	struct rpmsg_device *rpdev;
@@ -425,6 +414,7 @@ static struct rpmsg_device *rpmsg_create_channel(struct virtproc_info *vrp,
 	rpdev->src = chinfo->src;
 	rpdev->dst = chinfo->dst;
 	rpdev->ops = &virtio_rpmsg_ops;
+	rpdev->little_endian = virtio_is_little_endian(vrp->vdev);
 
 	/*
 	 * rpmsg server channels has predefined local address (for now),
@@ -618,10 +608,10 @@ static int rpmsg_send_offchannel_raw(struct rpmsg_device *rpdev,
 		}
 	}
 
-	msg->len = cpu_to_virtio16(vrp->vdev, len);
+	msg->len = cpu_to_rpmsg16(rpdev, len);
 	msg->flags = 0;
-	msg->src = cpu_to_virtio32(vrp->vdev, src);
-	msg->dst = cpu_to_virtio32(vrp->vdev, dst);
+	msg->src = cpu_to_rpmsg32(rpdev, src);
+	msg->dst = cpu_to_rpmsg32(rpdev, dst);
 	msg->reserved = 0;
 	memcpy(msg->data, data, len);
 
@@ -710,14 +700,15 @@ static int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,
 {
 	struct rpmsg_endpoint *ept;
 	struct scatterlist sg;
-	unsigned int msg_len = virtio16_to_cpu(vrp->vdev, msg->len);
+	bool little_endian = virtio_is_little_endian(vrp->vdev);
+	unsigned int msg_len = __rpmsg16_to_cpu(little_endian, msg->len);
 	int err;
 
 	dev_dbg(dev, "From: 0x%x, To: 0x%x, Len: %d, Flags: %d, Reserved: %d\n",
-		virtio32_to_cpu(vrp->vdev, msg->src),
-		virtio32_to_cpu(vrp->vdev, msg->dst), msg_len,
-		virtio16_to_cpu(vrp->vdev, msg->flags),
-		virtio32_to_cpu(vrp->vdev, msg->reserved));
+		__rpmsg32_to_cpu(little_endian, msg->src),
+		__rpmsg32_to_cpu(little_endian, msg->dst), msg_len,
+		__rpmsg16_to_cpu(little_endian, msg->flags),
+		__rpmsg32_to_cpu(little_endian, msg->reserved));
 #if defined(CONFIG_DYNAMIC_DEBUG)
 	dynamic_hex_dump("rpmsg_virtio RX: ", DUMP_PREFIX_NONE, 16, 1,
 			 msg, sizeof(*msg) + msg_len, true);
@@ -736,7 +727,7 @@ static int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,
 	/* use the dst addr to fetch the callback of the appropriate user */
 	mutex_lock(&vrp->endpoints_lock);
 
-	ept = idr_find(&vrp->endpoints, virtio32_to_cpu(vrp->vdev, msg->dst));
+	ept = idr_find(&vrp->endpoints, __rpmsg32_to_cpu(little_endian, msg->dst));
 
 	/* let's make sure no one deallocates ept while we use it */
 	if (ept)
@@ -750,7 +741,7 @@ static int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,
 
 		if (ept->cb)
 			ept->cb(ept->rpdev, msg->data, msg_len, ept->priv,
-				virtio32_to_cpu(vrp->vdev, msg->src));
+				__rpmsg32_to_cpu(little_endian, msg->src));
 
 		mutex_unlock(&ept->cb_lock);
 
@@ -821,60 +812,47 @@ static void rpmsg_xmit_done(struct virtqueue *svq)
 	wake_up_interruptible(&vrp->sendq);
 }
 
-/* invoked when a name service announcement arrives */
-static int rpmsg_ns_cb(struct rpmsg_device *rpdev, void *data, int len,
-		       void *priv, u32 src)
+/*
+ * Called to expose to user a /dev/rpmsg_ctrlX interface allowing to
+ * create endpoint-to-endpoint communication without associated RPMsg channel.
+ * The endpoints are rattached to the ctrldev RPMsg device.
+ */
+static struct rpmsg_device *rpmsg_virtio_add_ctrl_dev(struct virtio_device *vdev)
 {
-	struct rpmsg_ns_msg *msg = data;
-	struct rpmsg_device *newch;
-	struct rpmsg_channel_info chinfo;
-	struct virtproc_info *vrp = priv;
-	struct device *dev = &vrp->vdev->dev;
-	int ret;
-
-#if defined(CONFIG_DYNAMIC_DEBUG)
-	dynamic_hex_dump("NS announcement: ", DUMP_PREFIX_NONE, 16, 1,
-			 data, len, true);
-#endif
-
-	if (len != sizeof(*msg)) {
-		dev_err(dev, "malformed ns msg (%d)\n", len);
-		return -EINVAL;
-	}
+	struct virtproc_info *vrp = vdev->priv;
+	struct virtio_rpmsg_channel *vch;
+	struct rpmsg_device *rpdev_ctrl;
+	int err = 0;
 
-	/*
-	 * the name service ept does _not_ belong to a real rpmsg channel,
-	 * and is handled by the rpmsg bus itself.
-	 * for sanity reasons, make sure a valid rpdev has _not_ sneaked
-	 * in somehow.
-	 */
-	if (rpdev) {
-		dev_err(dev, "anomaly: ns ept has an rpdev handle\n");
-		return -EINVAL;
-	}
+	vch = kzalloc(sizeof(*vch), GFP_KERNEL);
+	if (!vch)
+		return ERR_PTR(-ENOMEM);
 
-	/* don't trust the remote processor for null terminating the name */
-	msg->name[RPMSG_NAME_SIZE - 1] = '\0';
+	/* Link the channel to the vrp */
+	vch->vrp = vrp;
 
-	strncpy(chinfo.name, msg->name, sizeof(chinfo.name));
-	chinfo.src = RPMSG_ADDR_ANY;
-	chinfo.dst = virtio32_to_cpu(vrp->vdev, msg->addr);
+	/* Assign public information to the rpmsg_device */
+	rpdev_ctrl = &vch->rpdev;
+	rpdev_ctrl->ops = &virtio_rpmsg_ops;
 
-	dev_info(dev, "%sing channel %s addr 0x%x\n",
-		 virtio32_to_cpu(vrp->vdev, msg->flags) & RPMSG_NS_DESTROY ?
-		 "destroy" : "creat", msg->name, chinfo.dst);
+	rpdev_ctrl->dev.parent = &vrp->vdev->dev;
+	rpdev_ctrl->dev.release = virtio_rpmsg_release_device;
+	rpdev_ctrl->little_endian = virtio_is_little_endian(vrp->vdev);
 
-	if (virtio32_to_cpu(vrp->vdev, msg->flags) & RPMSG_NS_DESTROY) {
-		ret = rpmsg_unregister_device(&vrp->vdev->dev, &chinfo);
-		if (ret)
-			dev_err(dev, "rpmsg_destroy_channel failed: %d\n", ret);
-	} else {
-		newch = rpmsg_create_channel(vrp, &chinfo);
-		if (!newch)
-			dev_err(dev, "rpmsg_create_channel failed\n");
+	err = rpmsg_ctrldev_register_device(rpdev_ctrl);
+	if (err) {
+		kfree(vch);
+		return ERR_PTR(err);
 	}
 
-	return 0;
+	return rpdev_ctrl;
+}
+
+static void rpmsg_virtio_del_ctrl_dev(struct rpmsg_device *rpdev_ctrl)
+{
+	if (!rpdev_ctrl)
+		return;
+	kfree(to_virtio_rpmsg_channel(rpdev_ctrl));
 }
 
 static int rpmsg_probe(struct virtio_device *vdev)
@@ -883,6 +861,8 @@ static int rpmsg_probe(struct virtio_device *vdev)
 	static const char * const names[] = { "input", "output" };
 	struct virtqueue *vqs[2];
 	struct virtproc_info *vrp;
+	struct virtio_rpmsg_channel *vch = NULL;
+	struct rpmsg_device *rpdev_ns, *rpdev_ctrl;
 	void *bufs_va;
 	int err = 0, i;
 	size_t total_buf_space;
@@ -956,16 +936,34 @@ static int rpmsg_probe(struct virtio_device *vdev)
 
 	vdev->priv = vrp;
 
+	rpdev_ctrl = rpmsg_virtio_add_ctrl_dev(vdev);
+	if (IS_ERR(rpdev_ctrl)) {
+		err = PTR_ERR(rpdev_ctrl);
+		goto free_coherent;
+	}
+
 	/* if supported by the remote processor, enable the name service */
 	if (virtio_has_feature(vdev, VIRTIO_RPMSG_F_NS)) {
-		/* a dedicated endpoint handles the name service msgs */
-		vrp->ns_ept = __rpmsg_create_ept(vrp, NULL, rpmsg_ns_cb,
-						vrp, RPMSG_NS_ADDR);
-		if (!vrp->ns_ept) {
-			dev_err(&vdev->dev, "failed to create the ns ept\n");
+		vch = kzalloc(sizeof(*vch), GFP_KERNEL);
+		if (!vch) {
 			err = -ENOMEM;
-			goto free_coherent;
+			goto free_ctrldev;
 		}
+
+		/* Link the channel to our vrp */
+		vch->vrp = vrp;
+
+		/* Assign public information to the rpmsg_device */
+		rpdev_ns = &vch->rpdev;
+		rpdev_ns->ops = &virtio_rpmsg_ops;
+		rpdev_ns->little_endian = virtio_is_little_endian(vrp->vdev);
+
+		rpdev_ns->dev.parent = &vrp->vdev->dev;
+		rpdev_ns->dev.release = virtio_rpmsg_release_device;
+
+		err = rpmsg_ns_register_device(rpdev_ns);
+		if (err)
+			goto free_vch;
 	}
 
 	/*
@@ -989,6 +987,10 @@ static int rpmsg_probe(struct virtio_device *vdev)
 
 	return 0;
 
+free_vch:
+	kfree(vch);
+free_ctrldev:
+	rpmsg_virtio_del_ctrl_dev(rpdev_ctrl);
 free_coherent:
 	dma_free_coherent(vdev->dev.parent, total_buf_space,
 			  bufs_va, vrp->bufs_dma);
@@ -1018,9 +1020,6 @@ static void rpmsg_remove(struct virtio_device *vdev)
 	if (ret)
 		dev_warn(&vdev->dev, "can't remove rpmsg device: %d\n", ret);
 
-	if (vrp->ns_ept)
-		__rpmsg_destroy_ept(vrp, vrp->ns_ept);
-
 	idr_destroy(&vrp->endpoints);
 
 	vdev->config->del_vqs(vrp->vdev);
diff --git a/include/dt-bindings/firmware/imx/rsrc.h b/include/dt-bindings/firmware/imx/rsrc.h
index 54278d5c1856..b6b7d852426f 100644
--- a/include/dt-bindings/firmware/imx/rsrc.h
+++ b/include/dt-bindings/firmware/imx/rsrc.h
@@ -37,10 +37,14 @@
 #define IMX_SC_R_DC_0_BLIT2		21
 #define IMX_SC_R_DC_0_BLIT_OUT		22
 #define IMX_SC_R_PERF			23
+#define IMX_SC_R_USB_1_PHY		24
 #define IMX_SC_R_DC_0_WARP		25
+#define IMX_SC_R_V2X_MU_0		26
+#define IMX_SC_R_V2X_MU_1		27
 #define IMX_SC_R_DC_0_VIDEO0		28
 #define IMX_SC_R_DC_0_VIDEO1		29
 #define IMX_SC_R_DC_0_FRAC0		30
+#define IMX_SC_R_V2X_MU_2		31
 #define IMX_SC_R_DC_0			32
 #define IMX_SC_R_GPU_2_PID0		33
 #define IMX_SC_R_DC_0_PLL_0		34
@@ -49,7 +53,10 @@
 #define IMX_SC_R_DC_1_BLIT1		37
 #define IMX_SC_R_DC_1_BLIT2		38
 #define IMX_SC_R_DC_1_BLIT_OUT		39
+#define IMX_SC_R_V2X_MU_3		40
+#define IMX_SC_R_V2X_MU_4		41
 #define IMX_SC_R_DC_1_WARP		42
+#define IMX_SC_R_SECVIO			44
 #define IMX_SC_R_DC_1_VIDEO0		45
 #define IMX_SC_R_DC_1_VIDEO1		46
 #define IMX_SC_R_DC_1_FRAC0		47
diff --git a/include/linux/busfreq-imx.h b/include/linux/busfreq-imx.h
new file mode 100644
index 000000000000..39c71a9f55eb
--- /dev/null
+++ b/include/linux/busfreq-imx.h
@@ -0,0 +1,77 @@
+/*
+ * Copyright 2012-2016 Freescale Semiconductor, Inc. All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __ASM_ARCH_MXC_BUSFREQ_H__
+#define __ASM_ARCH_MXC_BUSFREQ_H__
+
+#include <linux/notifier.h>
+#include <linux/regulator/consumer.h>
+
+/*
+ * This enumerates busfreq low power mode entry and exit.
+ */
+enum busfreq_event {
+	LOW_BUSFREQ_ENTER,
+	LOW_BUSFREQ_EXIT,
+};
+
+/*
+ * This enumerates the system bus and ddr frequencies in various modes.
+ * BUS_FREQ_HIGH - DDR @ 528MHz, AHB @ 132MHz.
+ * BUS_FREQ_MED - DDR @ 400MHz, AHB @ 132MHz
+ * BUS_FREQ_AUDIO - DDR @ 50MHz/100MHz, AHB @ 24MHz.
+ * BUS_FREQ_LOW  - DDR @ 24MHz, AHB @ 24MHz.
+ * BUS_FREQ_ULTRA_LOW - DDR @ 1MHz, AHB - 3MHz.
+ *
+ * Drivers need to request/release the bus/ddr frequencies based on
+ * their performance requirements. Drivers cannot request/release
+ * BUS_FREQ_ULTRA_LOW mode as this mode is automatically entered from
+ * either BUS_FREQ_AUDIO or BUS_FREQ_LOW
+ * modes.
+ */
+enum bus_freq_mode {
+	BUS_FREQ_HIGH,
+	BUS_FREQ_MED,
+	BUS_FREQ_AUDIO,
+	BUS_FREQ_LOW,
+	BUS_FREQ_ULTRA_LOW,
+};
+
+#if defined(CONFIG_HAVE_IMX_BUSFREQ) && !defined(CONFIG_ARM64)
+extern struct regulator *arm_reg;
+extern struct regulator *soc_reg;
+void request_bus_freq(enum bus_freq_mode mode);
+void release_bus_freq(enum bus_freq_mode mode);
+int register_busfreq_notifier(struct notifier_block *nb);
+int unregister_busfreq_notifier(struct notifier_block *nb);
+int get_bus_freq_mode(void);
+#elif defined(CONFIG_HAVE_IMX_BUSFREQ)
+void request_bus_freq(enum bus_freq_mode mode);
+void release_bus_freq(enum bus_freq_mode mode);
+int get_bus_freq_mode(void);
+#else
+static inline void request_bus_freq(enum bus_freq_mode mode)
+{
+}
+static inline void release_bus_freq(enum bus_freq_mode mode)
+{
+}
+static inline int register_busfreq_notifier(struct notifier_block *nb)
+{
+	return 0;
+}
+static inline int unregister_busfreq_notifier(struct notifier_block *nb)
+{
+	return 0;
+}
+static inline int get_bus_freq_mode(void)
+{
+	return BUS_FREQ_HIGH;
+}
+#endif
+#endif
diff --git a/include/linux/firmware/imx/dsp.h b/include/linux/firmware/imx/dsp.h
index 7562099c9e46..4f7895a3b73c 100644
--- a/include/linux/firmware/imx/dsp.h
+++ b/include/linux/firmware/imx/dsp.h
@@ -55,6 +55,9 @@ static inline void *imx_dsp_get_data(struct imx_dsp_ipc *ipc)
 
 int imx_dsp_ring_doorbell(struct imx_dsp_ipc *dsp, unsigned int chan_idx);
 
+struct mbox_chan *imx_dsp_request_channel(struct imx_dsp_ipc *ipc, int idx);
+void imx_dsp_free_channel(struct imx_dsp_ipc *ipc, int idx);
+
 #else
 
 static inline int imx_dsp_ring_doorbell(struct imx_dsp_ipc *ipc,
@@ -63,5 +66,12 @@ static inline int imx_dsp_ring_doorbell(struct imx_dsp_ipc *ipc,
 	return -ENOTSUPP;
 }
 
+struct mbox_chan *imx_dsp_request_channel(struct imx_dsp_ipc *ipc, int idx)
+{
+	return ERR_PTR(-EOPNOTSUPP);
+}
+
+void imx_dsp_free_channel(struct imx_dsp_ipc *ipc, int idx) { }
+
 #endif
 #endif /* _IMX_DSP_IPC_H */
diff --git a/include/linux/firmware/imx/ipc.h b/include/linux/firmware/imx/ipc.h
index 891057434858..4689ea576466 100644
--- a/include/linux/firmware/imx/ipc.h
+++ b/include/linux/firmware/imx/ipc.h
@@ -1,6 +1,6 @@
 /* SPDX-License-Identifier: GPL-2.0+ */
 /*
- * Copyright 2018 NXP
+ * Copyright 2018,2020 NXP
  *
  * Header file for the IPC implementation.
  */
@@ -25,6 +25,8 @@ enum imx_sc_rpc_svc {
 	IMX_SC_RPC_SVC_PAD = 6,
 	IMX_SC_RPC_SVC_MISC = 7,
 	IMX_SC_RPC_SVC_IRQ = 8,
+	IMX_SC_RPC_SVC_SECO = 9,
+	IMX_SC_RPC_SVC_ABORT = 10,
 };
 
 struct imx_sc_rpc_msg {
diff --git a/include/linux/firmware/imx/sci.h b/include/linux/firmware/imx/sci.h
index 22c76571a294..4bbc11d16c72 100644
--- a/include/linux/firmware/imx/sci.h
+++ b/include/linux/firmware/imx/sci.h
@@ -1,7 +1,7 @@
 /* SPDX-License-Identifier: GPL-2.0+ */
 /*
  * Copyright (C) 2016 Freescale Semiconductor, Inc.
- * Copyright 2017~2018 NXP
+ * Copyright 2017~2018,2020 NXP
  *
  * Header file containing the public System Controller Interface (SCI)
  * definitions.
@@ -15,10 +15,15 @@
 #include <linux/firmware/imx/svc/misc.h>
 #include <linux/firmware/imx/svc/pm.h>
 #include <linux/firmware/imx/svc/rm.h>
+#include <linux/firmware/imx/svc/seco.h>
+
+#define IMX_SC_IRQ_GROUP_WAKE       3U /* Wakeup interrupts */
+#define IMX_SC_IRQ_SECVIO            BIT(6)    /* Security violation */
 
 int imx_scu_enable_general_irq_channel(struct device *dev);
 int imx_scu_irq_register_notifier(struct notifier_block *nb);
 int imx_scu_irq_unregister_notifier(struct notifier_block *nb);
 int imx_scu_irq_group_enable(u8 group, u32 mask, u8 enable);
+int imx_scu_irq_get_status(u8 group, u32 *irq_status);
 int imx_scu_soc_init(struct device *dev);
 #endif /* _SC_SCI_H */
diff --git a/include/linux/firmware/imx/seco_mu_ioctl.h b/include/linux/firmware/imx/seco_mu_ioctl.h
new file mode 100644
index 000000000000..bd8402b473a4
--- /dev/null
+++ b/include/linux/firmware/imx/seco_mu_ioctl.h
@@ -0,0 +1,50 @@
+/* SPDX-License-Identifier: (GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause*/
+/*
+ * Copyright 2019-2020 NXP
+ */
+
+#ifndef SECO_MU_IOCTL_H
+#define SECO_MU_IOCTL_H
+
+/* IOCTL definitions. */
+struct seco_mu_ioctl_setup_iobuf {
+	u8 *user_buf;
+	u32 length;
+	u32 flags;
+	u64 seco_addr;
+};
+
+struct seco_mu_ioctl_shared_mem_cfg {
+	u32 base_offset;
+	u32 size;
+};
+
+struct seco_mu_ioctl_get_mu_info {
+	u8 seco_mu_idx;
+	u8 interrupt_idx;
+	u8 tz;
+	u8 did;
+};
+
+struct seco_mu_ioctl_signed_message {
+	u8 *message;
+	u32 msg_size;
+	u32 error_code;
+};
+
+#define SECO_MU_IO_FLAGS_IS_INPUT	(0x01u)
+#define SECO_MU_IO_FLAGS_USE_SEC_MEM	(0x02u)
+#define SECO_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+#define SECO_MU_IOCTL			0x0A /* like MISC_MAJOR. */
+#define SECO_MU_IOCTL_ENABLE_CMD_RCV	_IO(SECO_MU_IOCTL, 0x01)
+#define SECO_MU_IOCTL_SHARED_BUF_CFG	_IOW(SECO_MU_IOCTL, 0x02, \
+			struct seco_mu_ioctl_shared_mem_cfg)
+#define SECO_MU_IOCTL_SETUP_IOBUF	_IOWR(SECO_MU_IOCTL, 0x03, \
+			struct seco_mu_ioctl_setup_iobuf)
+#define SECO_MU_IOCTL_GET_MU_INFO	_IOR(SECO_MU_IOCTL, 0x04, \
+			struct seco_mu_ioctl_get_mu_info)
+#define SECO_MU_IOCTL_SIGNED_MESSAGE	_IOWR(SECO_MU_IOCTL, 0x05, \
+			struct seco_mu_ioctl_signed_message)
+
+#endif
diff --git a/include/linux/firmware/imx/sentnl_base_msg.h b/include/linux/firmware/imx/sentnl_base_msg.h
new file mode 100644
index 000000000000..0592fbcf8fd3
--- /dev/null
+++ b/include/linux/firmware/imx/sentnl_base_msg.h
@@ -0,0 +1,36 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2021 NXP
+ */
+
+#ifndef SENTNL_BASE_MSG_H
+#define SENTNL_BASE_MSG_H
+
+#define MAX_RECV_SIZE 31
+#define MAX_RECV_SIZE_BYTES (MAX_RECV_SIZE * sizeof(u32))
+#define MAX_MESSAGE_SIZE 31
+#define MAX_MESSAGE_SIZE_BYTES (MAX_MESSAGE_SIZE * sizeof(u32))
+
+#define MESSAGING_VERSION_6		0x6
+
+#define SENTNL_OEM_CNTN_AUTH_REQ	0x87
+#define SENTNL_VERIFY_IMAGE_REQ		0x88
+#define SENTNL_RELEASE_CONTAINER_REQ	0x89
+#define SENTNL_READ_FUSE_REQ		0x97
+#define OTP_UNIQ_ID			0x01
+#define OTFAD_CONFIG			0x2
+
+#define SENTNL_VERSION			0x6
+#define SENTNL_SUCCESS_IND		0xD6
+#define SENTNL_FAILURE_IND		0x29
+
+#define SENTNL_MSG_DATA_NUM		10
+
+#define SENTNL_OEM_CNTN_AUTH_REQ_SIZE	3
+#define SENTNL_VERIFY_IMAGE_REQ_SIZE	2
+#define SENTNL_REL_CONTAINER_REQ_SIZE	1
+
+
+int read_common_fuse(uint16_t fuse_index, u32 *value);
+
+#endif
diff --git a/include/linux/firmware/imx/sentnl_mu_ioctl.h b/include/linux/firmware/imx/sentnl_mu_ioctl.h
new file mode 100644
index 000000000000..eda727aa81fc
--- /dev/null
+++ b/include/linux/firmware/imx/sentnl_mu_ioctl.h
@@ -0,0 +1,51 @@
+/* SPDX-License-Identifier: (GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause*/
+/*
+ * Copyright 2019-2021 NXP
+ */
+
+#ifndef SENTNL_MU_IOCTL_H
+#define SENTNL_MU_IOCTL_H
+
+/* IOCTL definitions. */
+
+struct sentnl_mu_ioctl_setup_iobuf {
+	u8 *user_buf;
+	u32 length;
+	u32 flags;
+	u64 sentnl_addr;
+};
+
+struct sentnl_mu_ioctl_shared_mem_cfg {
+	u32 base_offset;
+	u32 size;
+};
+
+struct sentnl_mu_ioctl_get_mu_info {
+	u8 sentnl_mu_id;
+	u8 interrupt_idx;
+	u8 tz;
+	u8 did;
+};
+
+struct sentnl_mu_ioctl_signed_message {
+	u8 *message;
+	u32 msg_size;
+	u32 error_code;
+};
+
+#define SENTNL_MU_IO_FLAGS_IS_INTPUT		(0x01u)
+#define SENTNL_MU_IO_FLAGS_USE_SEC_MEM		(0x02u)
+#define SENTNL_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+#define SENTNL_MU_IOCTL			0x0A /* like MISC_MAJOR. */
+#define SENTNL_MU_IOCTL_ENABLE_CMD_RCV	_IO(SENTNL_MU_IOCTL, 0x01)
+#define SENTNL_MU_IOCTL_SHARED_BUF_CFG	_IOW(SENTNL_MU_IOCTL, 0x02, \
+					struct sentnl_mu_ioctl_shared_mem_cfg)
+#define SENTNL_MU_IOCTL_SETUP_IOBUF	_IOWR(SENTNL_MU_IOCTL, 0x03, \
+					struct sentnl_mu_ioctl_setup_iobuf)
+#define SENTNL_MU_IOCTL_GET_MU_INFO	_IOR(SENTNL_MU_IOCTL, 0x04, \
+					struct sentnl_mu_ioctl_get_mu_info)
+#define SENTNL_MU_IOCTL_SIGNED_MESSAGE	_IOWR(SENTNL_MU_IOCTL, 0x05, \
+					struct sentnl_mu_ioctl_signed_message)
+
+#endif
diff --git a/include/linux/firmware/imx/svc/rm.h b/include/linux/firmware/imx/svc/rm.h
index 456b6a59d29b..f7205e141bb1 100644
--- a/include/linux/firmware/imx/svc/rm.h
+++ b/include/linux/firmware/imx/svc/rm.h
@@ -59,11 +59,50 @@ enum imx_sc_rm_func {
 
 #if IS_ENABLED(CONFIG_IMX_SCU)
 bool imx_sc_rm_is_resource_owned(struct imx_sc_ipc *ipc, u16 resource);
+int imx_sc_rm_get_partition(struct imx_sc_ipc *ipc, u8 *pt);
+int imx_sc_rm_find_memreg(struct imx_sc_ipc *ipc, u8 *mr, u64 addr_start,
+			  u64 addr_end);
+int imx_sc_rm_get_resource_owner(struct imx_sc_ipc *ipc, u16 resource, u8 *pt);
+int imx_sc_rm_set_memreg_permissions(struct imx_sc_ipc *ipc, u8 mr,
+				     u8 pt, u8 perm);
+int imx_sc_rm_get_did(struct imx_sc_ipc *ipc, u8 *did);
 #else
 static inline bool
 imx_sc_rm_is_resource_owned(struct imx_sc_ipc *ipc, u16 resource)
 {
 	return true;
 }
+
+static inline int imx_sc_rm_get_partition(struct imx_sc_ipc *ipc, u8 *pt)
+{
+	return -ENOENT;
+}
+
+static inline
+int imx_sc_rm_find_memreg(struct imx_sc_ipc *ipc, u8 *mr, u64 addr_start,
+			  u64 addr_end)
+{
+	return -ENOTSUP;
+}
+
+static inline
+int imx_sc_rm_get_resource_owner(struct imx_sc_ipc *ipc, u16 resource, u8 *pt)
+{
+	return -ENOTSUP;
+}
+
+static inline
+int imx_sc_rm_set_memreg_permissions(struct imx_sc_ipc *ipc, u8 mr,
+				     u8 pt, u8 perm)
+{
+	return -ENOTSUP;
+}
+
+static inline
+int imx_sc_rm_get_did(struct imx_sc_ipc *ipc, u8 *did)
+{
+	return -ENOTSUP;
+}
 #endif
+
 #endif
diff --git a/include/linux/firmware/imx/svc/seco.h b/include/linux/firmware/imx/svc/seco.h
new file mode 100644
index 000000000000..d30f76d874a7
--- /dev/null
+++ b/include/linux/firmware/imx/svc/seco.h
@@ -0,0 +1,77 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2020 NXP
+ *
+ * Header file containing the public API for the System Controller (SC)
+ * Security Controller (SECO) function.
+ *
+ * SECO_SVC (SVC) Security Controller Service
+ *
+ * Module for the Security Controller (SECO) service.
+ */
+
+#ifndef _SC_SECO_API_H
+#define _SC_SECO_API_H
+
+#include <linux/errno.h>
+#include <linux/firmware/imx/sci.h>
+
+/*
+ * This type is used to indicate RPC RM function calls.
+ */
+enum imx_sc_seco_func {
+	IMX_SC_SECO_FUNC_UNKNOWN = 0,
+	IMX_SC_SECO_FUNC_BUILD_INFO = 16,
+	IMX_SC_SECO_FUNC_SAB_MSG = 23,
+	IMX_SC_SECO_FUNC_SECVIO_ENABLE = 25,
+	IMX_SC_SECO_FUNC_SECVIO_CONFIG = 26,
+	IMX_SC_SECO_FUNC_SECVIO_DGO_CONFIG = 27,
+};
+
+#if IS_ENABLED(CONFIG_IMX_SCU)
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit);
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr);
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc);
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size);
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data);
+#else /* IS_ENABLED(CONFIG_IMX_SCU) */
+static inline
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit)
+{
+	return -ENOTSUP;
+}
+
+static inline
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr)
+{
+	return -ENOTSUP;
+}
+
+static inline
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data)
+{
+	return -EOPNOTSUPP;
+}
+#endif /* IS_ENABLED(CONFIG_IMX_SCU) */
+
+#endif /* _SC_SECO_API_H */
diff --git a/include/linux/imx_rpmsg.h b/include/linux/imx_rpmsg.h
new file mode 100644
index 000000000000..e0d5e979a3e7
--- /dev/null
+++ b/include/linux/imx_rpmsg.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2019 NXP.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/*
+ * @file linux/imx_rpmsg.h
+ *
+ * @brief Global header file for iMX RPMSG
+ *
+ * @ingroup RPMSG
+ */
+#ifndef __LINUX_IMX_RPMSG_H__
+#define __LINUX_IMX_RPMSG_H__
+
+/* Category define */
+#define IMX_RMPSG_LIFECYCLE	1
+#define IMX_RPMSG_PMIC		2
+#define IMX_RPMSG_AUDIO		3
+#define IMX_RPMSG_KEY		4
+#define IMX_RPMSG_GPIO		5
+#define IMX_RPMSG_RTC		6
+#define IMX_RPMSG_SENSOR	7
+/* rpmsg version */
+#define IMX_RMPSG_MAJOR		1
+#define IMX_RMPSG_MINOR		0
+
+#define CIRC_ADD(idx, size, value)	(((idx) + (value)) & ((size) - 1))
+
+struct imx_rpmsg_head {
+	u8 cate;
+	u8 major;
+	u8 minor;
+	u8 type;
+	u8 cmd;
+	u8 reserved[5];
+} __packed;
+
+#endif /* __LINUX_IMX_RPMSG_H__ */
diff --git a/include/linux/rpmsg.h b/include/linux/rpmsg.h
index a68972b097b7..62d3e2698860 100644
--- a/include/linux/rpmsg.h
+++ b/include/linux/rpmsg.h
@@ -17,6 +17,7 @@
 #include <linux/kref.h>
 #include <linux/mutex.h>
 #include <linux/poll.h>
+#include <linux/rpmsg/byteorder.h>
 
 #define RPMSG_ADDR_ANY		0xFFFFFFFF
 
@@ -46,6 +47,7 @@ struct rpmsg_channel_info {
  * @dst: destination address
  * @ept: the rpmsg endpoint of this channel
  * @announce: if set, rpmsg will announce the creation/removal of this channel
+ * @little_endian: True if transport is using little endian byte representation
  */
 struct rpmsg_device {
 	struct device dev;
@@ -55,6 +57,7 @@ struct rpmsg_device {
 	u32 dst;
 	struct rpmsg_endpoint *ept;
 	bool announce;
+	bool little_endian;
 
 	const struct rpmsg_device_ops *ops;
 };
@@ -111,6 +114,54 @@ struct rpmsg_driver {
 	int (*callback)(struct rpmsg_device *, void *, int, void *, u32);
 };
 
+static inline u16 rpmsg16_to_cpu(struct rpmsg_device *rpdev, __rpmsg16 val)
+{
+	if (!rpdev)
+		return __rpmsg16_to_cpu(rpmsg_is_little_endian(), val);
+	else
+		return __rpmsg16_to_cpu(rpdev->little_endian, val);
+}
+
+static inline __rpmsg16 cpu_to_rpmsg16(struct rpmsg_device *rpdev, u16 val)
+{
+	if (!rpdev)
+		return __cpu_to_rpmsg16(rpmsg_is_little_endian(), val);
+	else
+		return __cpu_to_rpmsg16(rpdev->little_endian, val);
+}
+
+static inline u32 rpmsg32_to_cpu(struct rpmsg_device *rpdev, __rpmsg32 val)
+{
+	if (!rpdev)
+		return __rpmsg32_to_cpu(rpmsg_is_little_endian(), val);
+	else
+		return __rpmsg32_to_cpu(rpdev->little_endian, val);
+}
+
+static inline __rpmsg32 cpu_to_rpmsg32(struct rpmsg_device *rpdev, u32 val)
+{
+	if (!rpdev)
+		return __cpu_to_rpmsg32(rpmsg_is_little_endian(), val);
+	else
+		return __cpu_to_rpmsg32(rpdev->little_endian, val);
+}
+
+static inline u64 rpmsg64_to_cpu(struct rpmsg_device *rpdev, __rpmsg64 val)
+{
+	if (!rpdev)
+		return __rpmsg64_to_cpu(rpmsg_is_little_endian(), val);
+	else
+		return __rpmsg64_to_cpu(rpdev->little_endian, val);
+}
+
+static inline __rpmsg64 cpu_to_rpmsg64(struct rpmsg_device *rpdev, u64 val)
+{
+	if (!rpdev)
+		return __cpu_to_rpmsg64(rpmsg_is_little_endian(), val);
+	else
+		return __cpu_to_rpmsg64(rpdev->little_endian, val);
+}
+
 #if IS_ENABLED(CONFIG_RPMSG)
 
 int register_rpmsg_device(struct rpmsg_device *dev);
@@ -121,6 +172,9 @@ void rpmsg_destroy_ept(struct rpmsg_endpoint *);
 struct rpmsg_endpoint *rpmsg_create_ept(struct rpmsg_device *,
 					rpmsg_rx_cb_t cb, void *priv,
 					struct rpmsg_channel_info chinfo);
+struct rpmsg_endpoint *rpmsg_create_default_ept(struct rpmsg_device *rpdev,
+						rpmsg_rx_cb_t cb, void *priv,
+						struct rpmsg_channel_info chinfo);
 
 int rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len);
 int rpmsg_sendto(struct rpmsg_endpoint *ept, void *data, int len, u32 dst);
@@ -180,6 +234,16 @@ static inline struct rpmsg_endpoint *rpmsg_create_ept(struct rpmsg_device *rpdev
 	return NULL;
 }
 
+static inline struct rpmsg_endpoint *rpmsg_create_default_ept(struct rpmsg_device *rpdev,
+							      rpmsg_rx_cb_t cb, void *priv,
+							      struct rpmsg_channel_info chinfo)
+{
+	/* This shouldn't be possible */
+	WARN_ON(1);
+
+	return NULL;
+}
+
 static inline int rpmsg_send(struct rpmsg_endpoint *ept, void *data, int len)
 {
 	/* This shouldn't be possible */
diff --git a/include/linux/rpmsg/byteorder.h b/include/linux/rpmsg/byteorder.h
new file mode 100644
index 000000000000..c0f565dbad6d
--- /dev/null
+++ b/include/linux/rpmsg/byteorder.h
@@ -0,0 +1,67 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Follows implementation found in linux/virtio_byteorder.h
+ */
+#ifndef _LINUX_RPMSG_BYTEORDER_H
+#define _LINUX_RPMSG_BYTEORDER_H
+#include <linux/types.h>
+#include <uapi/linux/rpmsg_types.h>
+
+static inline bool rpmsg_is_little_endian(void)
+{
+#ifdef __LITTLE_ENDIAN
+	return true;
+#else
+	return false;
+#endif
+}
+
+static inline u16 __rpmsg16_to_cpu(bool little_endian, __rpmsg16 val)
+{
+	if (little_endian)
+		return le16_to_cpu((__force __le16)val);
+	else
+		return be16_to_cpu((__force __be16)val);
+}
+
+static inline __rpmsg16 __cpu_to_rpmsg16(bool little_endian, u16 val)
+{
+	if (little_endian)
+		return (__force __rpmsg16)cpu_to_le16(val);
+	else
+		return (__force __rpmsg16)cpu_to_be16(val);
+}
+
+static inline u32 __rpmsg32_to_cpu(bool little_endian, __rpmsg32 val)
+{
+	if (little_endian)
+		return le32_to_cpu((__force __le32)val);
+	else
+		return be32_to_cpu((__force __be32)val);
+}
+
+static inline __rpmsg32 __cpu_to_rpmsg32(bool little_endian, u32 val)
+{
+	if (little_endian)
+		return (__force __rpmsg32)cpu_to_le32(val);
+	else
+		return (__force __rpmsg32)cpu_to_be32(val);
+}
+
+static inline u64 __rpmsg64_to_cpu(bool little_endian, __rpmsg64 val)
+{
+	if (little_endian)
+		return le64_to_cpu((__force __le64)val);
+	else
+		return be64_to_cpu((__force __be64)val);
+}
+
+static inline __rpmsg64 __cpu_to_rpmsg64(bool little_endian, u64 val)
+{
+	if (little_endian)
+		return (__force __rpmsg64)cpu_to_le64(val);
+	else
+		return (__force __rpmsg64)cpu_to_be64(val);
+}
+
+#endif /* _LINUX_RPMSG_BYTEORDER_H */
diff --git a/include/linux/rpmsg/ns.h b/include/linux/rpmsg/ns.h
new file mode 100644
index 000000000000..a7804edd6d58
--- /dev/null
+++ b/include/linux/rpmsg/ns.h
@@ -0,0 +1,45 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef _LINUX_RPMSG_NS_H
+#define _LINUX_RPMSG_NS_H
+
+#include <linux/mod_devicetable.h>
+#include <linux/rpmsg.h>
+#include <linux/rpmsg/byteorder.h>
+#include <linux/types.h>
+
+/**
+ * struct rpmsg_ns_msg - dynamic name service announcement message
+ * @name: name of remote service that is published
+ * @addr: address of remote service that is published
+ * @flags: indicates whether service is created or destroyed
+ *
+ * This message is sent across to publish a new service, or announce
+ * about its removal. When we receive these messages, an appropriate
+ * rpmsg channel (i.e device) is created/destroyed. In turn, the ->probe()
+ * or ->remove() handler of the appropriate rpmsg driver will be invoked
+ * (if/as-soon-as one is registered).
+ */
+struct rpmsg_ns_msg {
+	char name[RPMSG_NAME_SIZE];
+	__rpmsg32 addr;
+	__rpmsg32 flags;
+} __packed;
+
+/**
+ * enum rpmsg_ns_flags - dynamic name service announcement flags
+ *
+ * @RPMSG_NS_CREATE: a new remote service was just created
+ * @RPMSG_NS_DESTROY: a known remote service was just destroyed
+ */
+enum rpmsg_ns_flags {
+	RPMSG_NS_CREATE		= 0,
+	RPMSG_NS_DESTROY	= 1,
+};
+
+/* Address 53 is reserved for advertising remote services */
+#define RPMSG_NS_ADDR			(53)
+
+int rpmsg_ns_register_device(struct rpmsg_device *rpdev);
+
+#endif
diff --git a/include/soc/imx/gpc.h b/include/soc/imx/gpc.h
new file mode 100644
index 000000000000..6a976e6aa3fe
--- /dev/null
+++ b/include/soc/imx/gpc.h
@@ -0,0 +1,7 @@
+#ifndef __SOC_IMX_GPC_H
+#define __SOC_IMX_GPC_H
+
+void imx_gpc_hold_m4_in_sleep(void);
+void imx_gpc_release_m4_in_sleep(void);
+
+#endif /* __SOC_IMX_GPC_H */
diff --git a/include/soc/imx/src.h b/include/soc/imx/src.h
new file mode 100644
index 000000000000..c55c34cd2366
--- /dev/null
+++ b/include/soc/imx/src.h
@@ -0,0 +1,6 @@
+#ifndef __SOC_IMX_SRC_H
+#define __SOC_IMX_SRC_H
+
+bool imx_src_is_m4_enabled(void);
+
+#endif /* __SOC_IMX_SRC_H */
diff --git a/include/uapi/linux/rpmsg_types.h b/include/uapi/linux/rpmsg_types.h
new file mode 100644
index 000000000000..36e3b9404391
--- /dev/null
+++ b/include/uapi/linux/rpmsg_types.h
@@ -0,0 +1,11 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+#ifndef _UAPI_LINUX_RPMSG_TYPES_H
+#define _UAPI_LINUX_RPMSG_TYPES_H
+
+#include <linux/types.h>
+
+typedef __u16 __bitwise __rpmsg16;
+typedef __u32 __bitwise __rpmsg32;
+typedef __u64 __bitwise __rpmsg64;
+
+#endif /* _UAPI_LINUX_RPMSG_TYPES_H */
-- 
2.39.0

